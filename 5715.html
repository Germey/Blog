<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
  <meta name="theme-color" content="#222">
  <meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>
  <script id="hexo-configurations">
    var NexT = window.NexT ||
    {};
    var CONFIG = {
      "hostname": "cuiqingcai.com",
      "root": "/",
      "scheme": "Pisces",
      "version": "7.8.0",
      "exturl": false,
      "sidebar":
      {
        "position": "right",
        "width": 360,
        "display": "post",
        "padding": 18,
        "offset": 12,
        "onmobile": false,
        "widgets": [
          {
            "type": "image",
            "name": "阿布云",
            "enable": false,
            "url": "https://www.abuyun.com/http-proxy/introduce.html",
            "src": "https://cdn.cuiqingcai.com/88au8.jpg",
            "width": "100%"
      },
          {
            "type": "image",
            "name": "爬虫书",
            "url": "https://item.jd.com/13527222.html",
            "src": "https://cdn.cuiqingcai.com/ei5og.jpg",
            "width": "100%",
            "enable": true
      },
          {
            "type": "categories",
            "name": "分类",
            "enable": true
      },
          {
            "type": "image",
            "name": "IPIDEA",
            "url": "http://www.ipidea.net/?utm-source=cqc&utm-keyword=?cqc",
            "src": "https://cdn.cuiqingcai.com/0ywun.png",
            "width": "100%",
            "enable": false
      },
          {
            "type": "image",
            "name": "Storm Proxies",
            "src": "https://cdn.cuiqingcai.com/a2zad8.png",
            "url": "https://www.stormproxies.cn/?keyword=jingmi",
            "width": "100%",
            "enable": false
      },
          {
            "type": "friends",
            "name": "友情链接",
            "enable": true
      },
          {
            "type": "hot",
            "name": "猜你喜欢",
            "enable": true
      },
          {
            "type": "tags",
            "name": "标签云",
            "enable": true
      }]
      },
      "copycode":
      {
        "enable": true,
        "show_result": true,
        "style": "mac"
      },
      "back2top":
      {
        "enable": true,
        "sidebar": false,
        "scrollpercent": true
      },
      "bookmark":
      {
        "enable": false,
        "color": "#222",
        "save": "auto"
      },
      "fancybox": false,
      "mediumzoom": false,
      "lazyload": false,
      "pangu": true,
      "comments":
      {
        "style": "tabs",
        "active": "gitalk",
        "storage": true,
        "lazyload": false,
        "nav": null,
        "activeClass": "gitalk"
      },
      "algolia":
      {
        "hits":
        {
          "per_page": 10
        },
        "labels":
        {
          "input_placeholder": "Search for Posts",
          "hits_empty": "We didn't find any results for the search: ${query}",
          "hits_stats": "${hits} results found in ${time} ms"
        }
      },
      "localsearch":
      {
        "enable": true,
        "trigger": "auto",
        "top_n_per_article": 10,
        "unescape": false,
        "preload": false
      },
      "motion":
      {
        "enable": false,
        "async": false,
        "transition":
        {
          "post_block": "bounceDownIn",
          "post_header": "slideDownIn",
          "post_body": "slideDownIn",
          "coll_header": "slideLeftIn",
          "sidebar": "slideUpIn"
        }
      },
      "path": "search.xml"
    };

  </script>
  <meta name="keywords" content="">
  <meta name="robots" content="index,follow">
  <meta name="GOOGLEBOT" content="index,follow">
  <meta name="author" content="静觅丨崔庆才的个人站点">
  <meta name="description" content="TensorFlow 中的 layers 模块提供用于深度学习的更高层次封装的 API，利用它我们可以轻松地构建模型，这一节我们就来看下这个模块的 API 的具体用法。 概览 layers 模块的路径写法为 tf.layers，这个模块定义在 tensorflow&#x2F;python&#x2F;layers&#x2F;layers.py，其官方文档地址为：https:&#x2F;&#x2F;www.tensorflow.org&#x2F;api_doc">
  <meta property="og:type" content="article">
  <meta property="og:title" content="TensorFlow layers模块用法">
  <meta property="og:url" content="https://cuiqingcai.com/5715.html">
  <meta property="og:site_name" content="静觅">
  <meta property="og:description" content="TensorFlow 中的 layers 模块提供用于深度学习的更高层次封装的 API，利用它我们可以轻松地构建模型，这一节我们就来看下这个模块的 API 的具体用法。 概览 layers 模块的路径写法为 tf.layers，这个模块定义在 tensorflow&#x2F;python&#x2F;layers&#x2F;layers.py，其官方文档地址为：https:&#x2F;&#x2F;www.tensorflow.org&#x2F;api_doc">
  <meta property="og:locale" content="zh_CN">
  <meta property="article:published_time" content="2018-02-22T19:42:58.000Z">
  <meta property="article:modified_time" content="2025-08-11T15:24:05.286Z">
  <meta property="article:author" content="崔庆才">
  <meta property="article:tag" content="爬虫教程">
  <meta property="article:tag" content="爬虫">
  <meta property="article:tag" content="Python">
  <meta property="article:tag" content="Python爬虫">
  <meta property="article:tag" content="Python爬虫教程">
  <meta property="article:tag" content="爬虫书">
  <meta property="article:tag" content="静觅">
  <meta property="article:tag" content="崔庆才">
  <meta name="twitter:card" content="summary">
  <link rel="canonical" href="https://cuiqingcai.com/5715.html">
  <script id="page-configurations">
    // https://hexo.io/docs/variables.html
    CONFIG.page = {
      sidebar: "",
      isHome: false,
      isPost: true,
      lang: 'zh-CN'
    };

  </script>
  <title>TensorFlow layers模块用法 | 静觅</title>
  <meta name="google-site-verification" content="p_bIcnvirkFzG2dYKuNDivKD8-STet5W7D-01woA2fc" />
  <meta name="sogou_site_verification" content="kBOV53NQqT" />
  <noscript>
    <style>
      .use-motion .brand,
      .use-motion .menu-item,
      .sidebar-inner,
      .use-motion .post-block,
      .use-motion .pagination,
      .use-motion .comments,
      .use-motion .post-header,
      .use-motion .post-body,
      .use-motion .collection-header
      {
        opacity: initial;
      }

      .use-motion .site-title,
      .use-motion .site-subtitle
      {
        opacity: initial;
        top: initial;
      }

      .use-motion .logo-line-before i
      {
        left: initial;
      }

      .use-motion .logo-line-after i
      {
        right: initial;
      }

    </style>
  </noscript>
  <link rel="alternate" href="/atom.xml" title="静觅" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner">
        <div class="site-brand-container">
          <div class="site-nav-toggle">
            <div class="toggle" aria-label="切换导航栏">
              <span class="toggle-line toggle-line-first"></span>
              <span class="toggle-line toggle-line-middle"></span>
              <span class="toggle-line toggle-line-last"></span>
            </div>
          </div>
          <div class="site-meta">
            <a href="/" class="brand" rel="start">
              <span class="logo-line-before"><i></i></span>
              <h1 class="site-title">静觅 <span class="site-subtitle"> 崔庆才的个人站点 - Python爬虫教程 </span>
              </h1>
              <span class="logo-line-after"><i></i></span>
            </a>
          </div>
          <div class="site-nav-right">
            <div class="toggle popup-trigger">
              <i class="fa fa-search fa-fw fa-lg"></i>
            </div>
          </div>
        </div>
        <nav class="site-nav">
          <ul id="menu" class="main-menu menu">
            <li class="menu-item menu-item-home">
              <a href="/" rel="section">首页</a>
            </li>
            <li class="menu-item menu-item-archives">
              <a href="/archives/" rel="section">文章列表</a>
            </li>
            <li class="menu-item menu-item-tags">
              <a href="/tags/" rel="section">文章标签</a>
            </li>
            <li class="menu-item menu-item-categories">
              <a href="/categories/" rel="section">文章分类</a>
            </li>
            <li class="menu-item menu-item-about">
              <a href="/about/" rel="section">关于博主</a>
            </li>
            <li class="menu-item menu-item-message">
              <a href="/message/" rel="section">给我留言</a>
            </li>
            <li class="menu-item menu-item-search">
              <a role="button" class="popup-trigger">搜索 </a>
            </li>
          </ul>
        </nav>
        <div class="search-pop-overlay">
          <div class="popup search-popup">
            <div class="search-header">
              <span class="search-icon">
                <i class="fa fa-search"></i>
              </span>
              <div class="search-input-container">
                <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input">
              </div>
              <span class="popup-btn-close">
                <i class="fa fa-times-circle"></i>
              </span>
            </div>
            <div id="search-result">
              <div id="no-result">
                <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>
    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
      <span>0%</span>
    </div>
    <div class="reading-progress-bar"></div>
    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div class="topbanner">
            <a href="https://item.jd.com/13527222.html" target="_blank">
              <img src="https://cdn.cuiqingcai.com/prwgs.png">
            </a>
          </div>
          <div class="content post posts-expand">
            <article itemscope itemtype="http://schema.org/Article" class="post-block single" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/5715.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h1 class="post-title" itemprop="name headline"> TensorFlow layers模块用法 </h1>
                <div class="post-meta">
                  <span class="post-meta-item">
                    <span class="post-meta-item-icon">
                      <i class="far fa-user"></i>
                    </span>
                    <span class="post-meta-item-text">作者</span>
                    <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                  </span>
                  <span class="post-meta-item">
                    <span class="post-meta-item-icon">
                      <i class="far fa-calendar"></i>
                    </span>
                    <span class="post-meta-item-text">发表于</span>
                    <time title="创建时间：2018-02-23 03:42:58" itemprop="dateCreated datePublished" datetime="2018-02-23T03:42:58+08:00">2018-02-23</time>
                  </span>
                  <span class="post-meta-item">
                    <span class="post-meta-item-icon">
                      <i class="far fa-folder"></i>
                    </span>
                    <span class="post-meta-item-text">分类于</span>
                    <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                      <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                    </span>
                  </span>
                  <span id="/5715.html" class="post-meta-item leancloud_visitors" data-flag-title="TensorFlow layers模块用法" title="阅读次数">
                    <span class="post-meta-item-icon">
                      <i class="fa fa-eye"></i>
                    </span>
                    <span class="post-meta-item-text">阅读次数：</span>
                    <span class="leancloud-visitors-count"></span>
                  </span>
                  <span class="post-meta-item" title="本文字数">
                    <span class="post-meta-item-icon">
                      <i class="far fa-file-word"></i>
                    </span>
                    <span class="post-meta-item-text">本文字数：</span>
                    <span>13k</span>
                  </span>
                  <span class="post-meta-item" title="阅读时长">
                    <span class="post-meta-item-icon">
                      <i class="far fa-clock"></i>
                    </span>
                    <span class="post-meta-item-text">阅读时长 &asymp;</span>
                    <span>12 分钟</span>
                  </span>
                </div>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="advertisements">
                </div>
                <p>TensorFlow 中的 layers 模块提供用于深度学习的更高层次封装的 API，利用它我们可以轻松地构建模型，这一节我们就来看下这个模块的 API 的具体用法。</p>
                <h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2>
                <p>layers 模块的路径写法为 tf.layers，这个模块定义在 tensorflow/python/layers/layers.py，其官方文档地址为：<a href="https://www.tensorflow.org/api_docs/python/tf/layers" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/layers</a>，TensorFlow 版本为 1.5。 这里面提供了多个类和方法以供使用，下面我们分别予以介绍。</p>
                <h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2>
                <p>tf.layers 模块提供的方法有：</p>
                <ul>
                  <li>Input(…): 用于实例化一个输入 Tensor，作为神经网络的输入。</li>
                  <li>average_pooling1d(…): 一维平均池化层</li>
                  <li>average_pooling2d(…): 二维平均池化层</li>
                  <li>average_pooling3d(…): 三维平均池化层</li>
                  <li>batch_normalization(…): 批量标准化层</li>
                  <li>conv1d(…): 一维卷积层</li>
                  <li>conv2d(…): 二维卷积层</li>
                  <li>conv2d_transpose(…): 二维反卷积层</li>
                  <li>conv3d(…): 三维卷积层</li>
                  <li>conv3d_transpose(…): 三维反卷积层</li>
                  <li>dense(…): 全连接层</li>
                  <li>dropout(…): Dropout层</li>
                  <li>flatten(…): Flatten层，即把一个 Tensor 展平</li>
                  <li>max_pooling1d(…): 一维最大池化层</li>
                  <li>max_pooling2d(…): 二维最大池化层</li>
                  <li>max_pooling3d(…): 三维最大池化层</li>
                  <li>separable_conv2d(…): 二维深度可分离卷积层</li>
                </ul>
                <h3 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h3>
                <p>tf.layers.Input() 这个方法是用于输入数据的方法，其实类似于 tf.placeholder，相当于一个占位符的作用，当然也可以通过传入 tensor 参数来进行赋值。</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">Input(</span><br><span class="line">    <span class="attribute">shape</span>=None,</span><br><span class="line">    <span class="attribute">batch_size</span>=None,</span><br><span class="line">    <span class="attribute">name</span>=None,</span><br><span class="line">    <span class="attribute">dtype</span>=tf.float32,</span><br><span class="line">    <span class="attribute">sparse</span>=<span class="literal">False</span>,</span><br><span class="line">    <span class="attribute">tensor</span>=None</span><br><span class="line">)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>参数说明如下：</p>
                <ul>
                  <li>shape：可选，默认 None，是一个数字组成的元组或列表，但是这个 shape 比较特殊，它不包含 batch_size，比如传入的 shape 为 [32]，那么它会将 shape 转化为 [?, 32]，这里一定需要注意。</li>
                  <li>batch_size：可选，默认 None，代表输入数据的 batch size，可以是数字或者 None。</li>
                  <li>name：可选，默认 None，输入层的名称。</li>
                  <li>dtype：可选，默认 tf.float32，元素的类型。</li>
                  <li>sparse：可选，默认 False，指定是否以稀疏矩阵的形式来创建 placeholder。</li>
                  <li>tensor：可选，默认 None，如果指定，那么创建的内容便不再是一个 placeholder，会用此 Tensor 初始化。</li>
                </ul>
                <p>返回值： 返回一个包含历史 Meta Data 的 Tensor。 我们用一个实例来感受一下：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf<span class="selector-class">.layers</span>.Input(shape=[<span class="number">32</span>])</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(x)</span></span></span><br><span class="line">y = tf<span class="selector-class">.layers</span>.dense(x, <span class="number">16</span>, activation=tf<span class="selector-class">.nn</span>.softmax)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(y)</span></span></span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>首先我们用 Input() 方法初始化了一个 placeholder，这时我们没有传入 tensor 参数，然后调用了 dense() 方法构建了一个全连接网络，激活函数使用 softmax，然后将二者输出，结果如下：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"input_layer_1:0"</span>, shape=(?, <span class="number">32</span>)</span></span>, dtype=float32)</span><br><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"dense/Softmax:0"</span>, shape=(?, <span class="number">16</span>)</span></span>, dtype=float32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>这时我们发现，shape 它给我们做了转化，本来是 [32]，结果它给转化成了 [?, 32]，即第一维代表 batch_size，所以我们需要注意，在调用此方法的时候不需要去关心 batch_size 这一维。 如果我们在初始化的时候传入一个已有 Tensor，例如：</p>
                <figure class="highlight haskell">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="class"><span class="keyword">data</span> = tf.constant([1, 2, 3])</span></span><br><span class="line"><span class="title">x</span> = tf.layers.<span class="type">Input</span>(tensor=<span class="class"><span class="keyword">data</span>)</span></span><br><span class="line"><span class="title">print</span>(x)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>结果如下：</p>
                <figure class="highlight reasonml">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="constructor">Tensor(<span class="string">"Const:0"</span>, <span class="params">shape</span>=(3,)</span>, dtype=<span class="built_in">int32</span>)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>可以看到它可以自动计算出其 shape 和 dtype。</p>
                <h3 id="batch-normalization"><a href="#batch-normalization" class="headerlink" title="batch_normalization"></a>batch_normalization</h3>
                <p>此方法是批量标准化的方法，经过处理之后可以加速训练速度，其定义在 tensorflow/python/layers/normalization.py，论文可以参考：<a href="http://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">http://arxiv.org/abs/1502.03167</a> “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”。</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">batch_normalization(</span><br><span class="line">    inputs,</span><br><span class="line">    <span class="attribute">axis</span>=-1,</span><br><span class="line">    <span class="attribute">momentum</span>=0.99,</span><br><span class="line">    <span class="attribute">epsilon</span>=0.001,</span><br><span class="line">    <span class="attribute">center</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">scale</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">beta_initializer</span>=tf.zeros_initializer(),</span><br><span class="line">    <span class="attribute">gamma_initializer</span>=tf.ones_initializer(),</span><br><span class="line">    <span class="attribute">moving_mean_initializer</span>=tf.zeros_initializer(),</span><br><span class="line">    <span class="attribute">moving_variance_initializer</span>=tf.ones_initializer(),</span><br><span class="line">    <span class="attribute">beta_regularizer</span>=None,</span><br><span class="line">    <span class="attribute">gamma_regularizer</span>=None,</span><br><span class="line">    <span class="attribute">beta_constraint</span>=None,</span><br><span class="line">    <span class="attribute">gamma_constraint</span>=None,</span><br><span class="line">    <span class="attribute">training</span>=<span class="literal">False</span>,</span><br><span class="line">    <span class="attribute">trainable</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">name</span>=None,</span><br><span class="line">    <span class="attribute">reuse</span>=None,</span><br><span class="line">    <span class="attribute">renorm</span>=<span class="literal">False</span>,</span><br><span class="line">    <span class="attribute">renorm_clipping</span>=None,</span><br><span class="line">    <span class="attribute">renorm_momentum</span>=0.99,</span><br><span class="line">    <span class="attribute">fused</span>=None,</span><br><span class="line">    <span class="attribute">virtual_batch_size</span>=None,</span><br><span class="line">    <span class="attribute">adjustment</span>=None</span><br><span class="line">)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>参数说明如下：</p>
                <ul>
                  <li>inputs：必需，即输入数据。</li>
                  <li>axis：可选，默认 -1，即进行标注化操作时操作数据的哪个维度。</li>
                  <li>momentum：可选，默认 0.99，即动态均值的动量。</li>
                  <li>epsilon：可选，默认 0.01，大于0的小浮点数，用于防止除0错误。</li>
                  <li>center：可选，默认 True，若设为True，将会将 beta 作为偏置加上去，否则忽略参数 beta</li>
                  <li>scale：可选，默认 True，若设为True，则会乘以gamma，否则不使用gamma。当下一层是线性的时，可以设False，因为scaling的操作将被下一层执行。</li>
                  <li>beta_initializer：可选，默认 zeros_initializer，即 beta 权重的初始方法。</li>
                  <li>gamma_initializer：可选，默认 ones_initializer，即 gamma 的初始化方法。</li>
                  <li>moving_mean_initializer：可选，默认 zeros_initializer，即动态均值的初始化方法。</li>
                  <li>moving_variance_initializer：可选，默认 ones_initializer，即动态方差的初始化方法。</li>
                  <li>beta_regularizer: 可选，默认None，beta 的正则化方法。</li>
                  <li>gamma_regularizer: 可选，默认None，gamma 的正则化方法。</li>
                  <li>beta_constraint: 可选，默认None，加在 beta 上的约束项。</li>
                  <li>gamma_constraint: 可选，默认None，加在 gamma 上的约束项。</li>
                  <li>training：可选，默认 False，返回结果是 training 模式。</li>
                  <li>trainable：可选，默认为 True，布尔类型，如果为 True，则将变量添加 GraphKeys.TRAINABLE_VARIABLES 中。</li>
                  <li>name：可选，默认 None，层名称。</li>
                  <li>reuse：可选，默认 None，根据层名判断是否重复利用。</li>
                  <li>renorm：可选，默认 False，是否要用 Batch Renormalization (<a href="https://arxiv.org/abs/1702.03275" target="_blank" rel="noopener">https://arxiv.org/abs/1702.03275</a>)</li>
                  <li>renorm_clipping：可选，默认 None，是否要用 rmax、rmin、dmax 来 scalar Tensor。</li>
                  <li>renorm_momentum，可选，默认 0.99，用来更新动态均值和标准差的 Momentum 值。</li>
                  <li>fused，可选，默认 None，是否使用一个更快的、融合的实现方法。</li>
                  <li>virtual_batch_size，可选，默认 None，是一个 int 数字，指定一个虚拟 batch size。</li>
                  <li>adjustment，可选，默认 None，对标准化后的结果进行适当调整的方法。</li>
                </ul>
                <p>最后的一些参数说明不够详尽，更详细的用法参考：<a href="https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization</a>。 其用法很简单，在输入数据后面加一层 batch_normalization() 即可：</p>
                <figure class="highlight ini">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="attr">x</span> = tf.layers.Input(shape=[<span class="number">32</span>])</span><br><span class="line"><span class="attr">x</span> = tf.layers.batch_normalization(x)</span><br><span class="line"><span class="attr">y</span> = tf.layers.dense(x, <span class="number">20</span>)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <h3 id="dense"><a href="#dense" class="headerlink" title="dense"></a>dense</h3>
                <p>dense，即全连接网络，layers 模块提供了一个 dense() 方法来实现此操作，定义在 tensorflow/python/layers/core.py 中，下面我们来说明一下它的用法。</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">dense(</span><br><span class="line">    inputs,</span><br><span class="line">    units,</span><br><span class="line">    <span class="attribute">activation</span>=None,</span><br><span class="line">    <span class="attribute">use_bias</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">kernel_initializer</span>=None,</span><br><span class="line">    <span class="attribute">bias_initializer</span>=tf.zeros_initializer(),</span><br><span class="line">    <span class="attribute">kernel_regularizer</span>=None,</span><br><span class="line">    <span class="attribute">bias_regularizer</span>=None,</span><br><span class="line">    <span class="attribute">activity_regularizer</span>=None,</span><br><span class="line">    <span class="attribute">kernel_constraint</span>=None,</span><br><span class="line">    <span class="attribute">bias_constraint</span>=None,</span><br><span class="line">    <span class="attribute">trainable</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">name</span>=None,</span><br><span class="line">    <span class="attribute">reuse</span>=None</span><br><span class="line">)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>参数说明如下：</p>
                <ul>
                  <li>inputs：必需，即需要进行操作的输入数据。</li>
                  <li>units：必须，即神经元的数量。</li>
                  <li>activation：可选，默认为 None，如果为 None 则是线性激活。</li>
                  <li>use_bias：可选，默认为 True，是否使用偏置。</li>
                  <li>kernel_initializer：可选，默认为 None，即权重的初始化方法，如果为 None，则使用默认的 Xavier 初始化方法。</li>
                  <li>bias_initializer：可选，默认为零值初始化，即偏置的初始化方法。</li>
                  <li>kernel_regularizer：可选，默认为 None，施加在权重上的正则项。</li>
                  <li>bias_regularizer：可选，默认为 None，施加在偏置上的正则项。</li>
                  <li>activity_regularizer：可选，默认为 None，施加在输出上的正则项。</li>
                  <li>kernel_constraint，可选，默认为 None，施加在权重上的约束项。</li>
                  <li>bias_constraint，可选，默认为 None，施加在偏置上的约束项。</li>
                  <li>trainable：可选，默认为 True，布尔类型，如果为 True，则将变量添加到 GraphKeys.TRAINABLE_VARIABLES 中。</li>
                  <li>name：可选，默认为 None，卷积层的名称。</li>
                  <li>reuse：可选，默认为 None，布尔类型，如果为 True，那么如果 name 相同时，会重复利用。</li>
                </ul>
                <p>返回值： 全连接网络处理后的 Tensor。 下面我们用一个实例来感受一下它的用法：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf<span class="selector-class">.layers</span>.Input(shape=[<span class="number">32</span>])</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(x)</span></span></span><br><span class="line">y1 = tf<span class="selector-class">.layers</span>.dense(x, <span class="number">16</span>, activation=tf<span class="selector-class">.nn</span>.relu)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(y1)</span></span></span><br><span class="line">y2 = tf<span class="selector-class">.layers</span>.dense(y1, <span class="number">5</span>, activation=tf<span class="selector-class">.nn</span>.sigmoid)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(y2)</span></span></span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>首先我们用 Input 定义了 [?, 32] 的输入数据，然后经过第一层全连接网络，此时指定了神经元个数为 16，激活函数为 relu，接着输出结果经过第二层全连接网络，此时指定了神经元个数为 5，激活函数为 sigmoid，最后输出，结果如下：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"input_layer_1:0"</span>, shape=(?, <span class="number">32</span>)</span></span>, dtype=float32)</span><br><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"dense/Relu:0"</span>, shape=(?, <span class="number">16</span>)</span></span>, dtype=float32)</span><br><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"dense_2/Sigmoid:0"</span>, shape=(?, <span class="number">5</span>)</span></span>, dtype=float32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>可以看到输出结果的最后一维度就等于神经元的个数，这是非常容易理解的。</p>
                <h3 id="convolution"><a href="#convolution" class="headerlink" title="convolution"></a>convolution</h3>
                <p>convolution，即卷积，这里提供了多个卷积方法，如 conv1d()、conv2d()、conv3d()，分别代表一维、二维、三维卷积，另外还有 conv2d_transpose()、conv3d_transpose()，分别代表二维和三维反卷积，还有 separable_conv2d() 方法代表二维深度可分离卷积。它们定义在 tensorflow/python/layers/convolutional.py 中，其用法都是类似的，在这里以 conv2d() 方法为例进行说明。</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">conv2d(</span><br><span class="line">    inputs,</span><br><span class="line">    filters,</span><br><span class="line">    kernel_size,</span><br><span class="line">    strides=(1, 1),</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'valid'</span>,</span><br><span class="line">    <span class="attribute">data_format</span>=<span class="string">'channels_last'</span>,</span><br><span class="line">    dilation_rate=(1, 1),</span><br><span class="line">    <span class="attribute">activation</span>=None,</span><br><span class="line">    <span class="attribute">use_bias</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">kernel_initializer</span>=None,</span><br><span class="line">    <span class="attribute">bias_initializer</span>=tf.zeros_initializer(),</span><br><span class="line">    <span class="attribute">kernel_regularizer</span>=None,</span><br><span class="line">    <span class="attribute">bias_regularizer</span>=None,</span><br><span class="line">    <span class="attribute">activity_regularizer</span>=None,</span><br><span class="line">    <span class="attribute">kernel_constraint</span>=None,</span><br><span class="line">    <span class="attribute">bias_constraint</span>=None,</span><br><span class="line">    <span class="attribute">trainable</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">name</span>=None,</span><br><span class="line">    <span class="attribute">reuse</span>=None</span><br><span class="line">)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>参数说明如下：</p>
                <ul>
                  <li>inputs：必需，即需要进行操作的输入数据。</li>
                  <li>filters：必需，是一个数字，代表了输出通道的个数，即 output_channels。</li>
                  <li>kernel_size：必需，卷积核大小，必须是一个数字（高和宽都是此数字）或者长度为 2 的列表（分别代表高、宽）。</li>
                  <li>strides：可选，默认为 (1, 1)，卷积步长，必须是一个数字（高和宽都是此数字）或者长度为 2 的列表（分别代表高、宽）。</li>
                  <li>padding：可选，默认为 valid，padding 的模式，有 valid 和 same 两种，大小写不区分。</li>
                  <li>data_format：可选，默认 channels_last，分为 channels_last 和 channels_first 两种模式，代表了输入数据的维度类型，如果是 channels_last，那么输入数据的 shape 为 (batch, height, width, channels)，如果是 channels_first，那么输入数据的 shape 为 (batch, channels, height, width)。</li>
                  <li>dilation_rate：可选，默认为 (1, 1)，卷积的扩张率，如当扩张率为 2 时，卷积核内部就会有边距，3x3 的卷积核就会变成 5x5。</li>
                  <li>activation：可选，默认为 None，如果为 None 则是线性激活。</li>
                  <li>use_bias：可选，默认为 True，是否使用偏置。</li>
                  <li>kernel_initializer：可选，默认为 None，即权重的初始化方法，如果为 None，则使用默认的 Xavier 初始化方法。</li>
                  <li>bias_initializer：可选，默认为零值初始化，即偏置的初始化方法。</li>
                  <li>kernel_regularizer：可选，默认为 None，施加在权重上的正则项。</li>
                  <li>bias_regularizer：可选，默认为 None，施加在偏置上的正则项。</li>
                  <li>activity_regularizer：可选，默认为 None，施加在输出上的正则项。</li>
                  <li>kernel_constraint，可选，默认为 None，施加在权重上的约束项。</li>
                  <li>bias_constraint，可选，默认为 None，施加在偏置上的约束项。</li>
                  <li>trainable：可选，默认为 True，布尔类型，如果为 True，则将变量添加到 GraphKeys.TRAINABLE_VARIABLES 中。</li>
                  <li>name：可选，默认为 None，卷积层的名称。</li>
                  <li>reuse：可选，默认为 None，布尔类型，如果为 True，那么如果 name 相同时，会重复利用。</li>
                </ul>
                <p>返回值： 卷积后的 Tensor。 下面我们用实例感受一下它的用法：</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.layers.Input(shape=[20, 20, 3])</span><br><span class="line">y = tf.layers.conv2d(x, <span class="attribute">filters</span>=6, <span class="attribute">kernel_size</span>=2, <span class="attribute">padding</span>=<span class="string">'same'</span>)</span><br><span class="line"><span class="builtin-name">print</span>(y)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>这里我们首先声明了一个 [?, 20, 20, 3] 的输入 x，然后将其传给 conv2d() 方法，filters 设定为 6，即输出通道为 6，kernel_size 为 2，即卷积核大小为 2 x 2，padding 方式设置为 same，那么输出结果的宽高和原来一定是相同的，但是输出通道就变成了 6，结果如下：</p>
                <figure class="highlight angelscript">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">Tensor(<span class="string">"conv2d/BiasAdd:0"</span>, shape=(?, <span class="number">20</span>, <span class="number">20</span>, <span class="number">6</span>), dtype=<span class="built_in">float</span>32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>但如果我们将 padding 方式不传入，使用默认的 valid 模式，代码改写如下：</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.layers.Input(shape=[20, 20, 3])</span><br><span class="line">y = tf.layers.conv2d(x, <span class="attribute">filters</span>=6, <span class="attribute">kernel_size</span>=2)</span><br><span class="line"><span class="builtin-name">print</span>(y)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>结果如下：</p>
                <figure class="highlight angelscript">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">Tensor(<span class="string">"conv2d/BiasAdd:0"</span>, shape=(?, <span class="number">19</span>, <span class="number">19</span>, <span class="number">6</span>), dtype=<span class="built_in">float</span>32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>结果就变成了 [?, 19, 19, 6]，这是因为步长默认为 1，卷积核大小为 2 x 2，所以得到的结果的高宽即为 (20 - (2 - 1)) x (20 - (2 - 1)) = 19 x 19。 当然卷积核我们也可以变换大小，传入一个列表形式：</p>
                <figure class="highlight angelscript">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.layers.Input(shape=[<span class="number">20</span>, <span class="number">20</span>, <span class="number">3</span>])</span><br><span class="line">y = tf.layers.conv2d(x, filters=<span class="number">6</span>, kernel_size=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">print(y)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>这时我们的卷积核大小变成了 2 x 3，即高为 2，宽为 3，结果就变成了 [?, 19, 18, 6]，这是因为步长默认为 1，卷积核大小为 2 x 2，所以得到的结果的高宽即为 (20 - (2 - 1)) x (20 - (3 - 1)) = 19 x 18。 如果我们将步长也设置一下，也传入列表形式：</p>
                <figure class="highlight angelscript">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.layers.Input(shape=[<span class="number">20</span>, <span class="number">20</span>, <span class="number">3</span>])</span><br><span class="line">y = tf.layers.conv2d(x, filters=<span class="number">6</span>, kernel_size=[<span class="number">2</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">print(y)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>这时卷积核大小变成了 2 x 3，步长变成了 2 x 2，所以结果的高宽为 ceil(20 - (2- 1)) / 2 x ceil(20 - (3- 1)) / 2 = 10 x 9，得到的结果即为 [?, 10, 9, 6]。 运行结果如下：</p>
                <figure class="highlight angelscript">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">Tensor(<span class="string">"conv2d_4/BiasAdd:0"</span>, shape=(?, <span class="number">10</span>, <span class="number">9</span>, <span class="number">6</span>), dtype=<span class="built_in">float</span>32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>另外我们还可以传入激活函数，或者禁用 bias 等操作，实例如下：</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.layers.Input(shape=[20, 20, 3])</span><br><span class="line">y = tf.layers.conv2d(x, <span class="attribute">filters</span>=6, <span class="attribute">kernel_size</span>=2, <span class="attribute">activation</span>=tf.nn.relu, <span class="attribute">use_bias</span>=<span class="literal">False</span>)</span><br><span class="line"><span class="builtin-name">print</span>(y)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>这样我们就将激活函数改成了 relu，同时禁用了 bias，运行结果如下：</p>
                <figure class="highlight angelscript">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">Tensor(<span class="string">"conv2d_5/Relu:0"</span>, shape=(?, <span class="number">19</span>, <span class="number">19</span>, <span class="number">6</span>), dtype=<span class="built_in">float</span>32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>另外还有反卷积操作，反卷积顾名思义即卷积的反向操作，即输入卷积的结果，得到卷积前的结果，其参数用法是完全一样的，例如：</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.layers.Input(shape=[20, 20, 3])</span><br><span class="line">y = tf.layers.conv2d_transpose(x, <span class="attribute">filters</span>=6, <span class="attribute">kernel_size</span>=2, <span class="attribute">strides</span>=2)</span><br><span class="line"><span class="builtin-name">print</span>(y)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>例如此处输入的图像高宽为 20 x 20，经过卷积核为 2，步长为 2 的反卷积处理，得到的结果高宽就变为了 40 x 40，结果如下：</p>
                <figure class="highlight angelscript">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">Tensor(<span class="string">"conv2d_transpose/BiasAdd:0"</span>, shape=(?, <span class="number">40</span>, <span class="number">40</span>, <span class="number">6</span>), dtype=<span class="built_in">float</span>32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <h3 id="pooling"><a href="#pooling" class="headerlink" title="pooling"></a>pooling</h3>
                <p>pooling，即池化，layers 模块提供了多个池化方法，这几个池化方法都是类似的，包括 max_pooling1d()、max_pooling2d()、max_pooling3d()、average_pooling1d()、average_pooling2d()、average_pooling3d()，分别代表一维二维三维最大和平均池化方法，它们都定义在 tensorflow/python/layers/pooling.py 中，这里以 max_pooling2d() 方法为例进行介绍。</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">max_pooling2d(</span><br><span class="line">    inputs,</span><br><span class="line">    pool_size,</span><br><span class="line">    strides,</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'valid'</span>,</span><br><span class="line">    <span class="attribute">data_format</span>=<span class="string">'channels_last'</span>,</span><br><span class="line">    <span class="attribute">name</span>=None</span><br><span class="line">)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>参数说明如下：</p>
                <ul>
                  <li>inputs: 必需，即需要池化的输入对象，必须是 4 维的。</li>
                  <li>pool_size：必需，池化窗口大小，必须是一个数字（高和宽都是此数字）或者长度为 2 的列表（分别代表高、宽）。</li>
                  <li>strides：必需，池化步长，必须是一个数字（高和宽都是此数字）或者长度为 2 的列表（分别代表高、宽）。</li>
                  <li>padding：可选，默认 valid，padding 的方法，valid 或者 same，大小写不区分。</li>
                  <li>data_format：可选，默认 channels_last，分为 channels_last 和 channels_first 两种模式，代表了输入数据的维度类型，如果是 channels_last，那么输入数据的 shape 为 (batch, height, width, channels)，如果是 channels_first，那么输入数据的 shape 为 (batch, channels, height, width)。</li>
                  <li>name：可选，默认 None，池化层的名称。</li>
                </ul>
                <p>返回值： 经过池化处理后的 Tensor。 下面我们用一个实例来感受一下：</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.layers.Input(shape=[20, 20, 3])</span><br><span class="line"><span class="builtin-name">print</span>(x)</span><br><span class="line">y = tf.layers.conv2d(x, <span class="attribute">filters</span>=6, <span class="attribute">kernel_size</span>=3, <span class="attribute">padding</span>=<span class="string">'same'</span>)</span><br><span class="line"><span class="builtin-name">print</span>(y)</span><br><span class="line">p = tf.layers.max_pooling2d(y, <span class="attribute">pool_size</span>=2, <span class="attribute">strides</span>=2)</span><br><span class="line"><span class="builtin-name">print</span>(p)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>在这里我们首先指定了输入 x，shape 为 [20, 20, 3]，然后对其进行了卷积计算，然后池化，最后得到池化后的结果。结果如下：</p>
                <figure class="highlight angelscript">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">Tensor(<span class="string">"input_layer_1:0"</span>, shape=(?, <span class="number">20</span>, <span class="number">20</span>, <span class="number">3</span>), dtype=<span class="built_in">float</span>32)</span><br><span class="line">Tensor(<span class="string">"conv2d/BiasAdd:0"</span>, shape=(?, <span class="number">20</span>, <span class="number">20</span>, <span class="number">6</span>), dtype=<span class="built_in">float</span>32)</span><br><span class="line">Tensor(<span class="string">"max_pooling2d/MaxPool:0"</span>, shape=(?, <span class="number">10</span>, <span class="number">10</span>, <span class="number">6</span>), dtype=<span class="built_in">float</span>32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>可以看到这里池化窗口用的是 2，步长也是 2，所以原本卷积后 shape 为 [?, 20, 20, 6] 的结果就变成了 [?, 10, 10, 6]。</p>
                <h3 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h3>
                <p>dropout 是指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃，可以用来防止过拟合，layers 模块中提供了 dropout() 方法来实现这一操作，定义在 tensorflow/python/layers/core.py。下面我们来说明一下它的用法。</p>
                <figure class="highlight routeros">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">dropout(</span><br><span class="line">    inputs,</span><br><span class="line">    <span class="attribute">rate</span>=0.5,</span><br><span class="line">    <span class="attribute">noise_shape</span>=None,</span><br><span class="line">    <span class="attribute">seed</span>=None,</span><br><span class="line">    <span class="attribute">training</span>=<span class="literal">False</span>,</span><br><span class="line">    <span class="attribute">name</span>=None</span><br><span class="line">)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>参数说明如下：</p>
                <ul>
                  <li>inputs：必须，即输入数据。</li>
                  <li>rate：可选，默认为 0.5，即 dropout rate，如设置为 0.1，则意味着会丢弃 10% 的神经元。</li>
                  <li>noise_shape：可选，默认为 None，int32 类型的一维 Tensor，它代表了 dropout mask 的 shape，dropout mask 会与 inputs 相乘对 inputs 做转换，例如 inputs 的 shape 为 (batch_size, timesteps, features)，但我们想要 droput mask 在所有 timesteps 都是相同的，我们可以设置 noise_shape=[batch_size, 1, features]。</li>
                  <li>seed：可选，默认为 None，即产生随机熟的种子值。</li>
                  <li>training：可选，默认为 False，布尔类型，即代表了是否标志位 training 模式。</li>
                  <li>name：可选，默认为 None，dropout 层的名称。</li>
                </ul>
                <p>返回： 经过 dropout 层之后的 Tensor。 我们用一个实例来感受一下：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf<span class="selector-class">.layers</span>.Input(shape=[<span class="number">32</span>])</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(x)</span></span></span><br><span class="line">y = tf<span class="selector-class">.layers</span>.dense(x, <span class="number">16</span>, activation=tf<span class="selector-class">.nn</span>.softmax)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(y)</span></span></span><br><span class="line">d = tf<span class="selector-class">.layers</span>.dropout(y, rate=<span class="number">0.2</span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(d)</span></span></span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>运行结果：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"input_layer_1:0"</span>, shape=(?, <span class="number">32</span>)</span></span>, dtype=float32)</span><br><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"dense/Softmax:0"</span>, shape=(?, <span class="number">16</span>)</span></span>, dtype=float32)</span><br><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"dropout/Identity:0"</span>, shape=(?, <span class="number">16</span>)</span></span>, dtype=float32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>在这里我们使用 dropout() 方法实现了 droput 操作，并制定 dropout rate 为 0.2，最后输出结果的 shape 和原来是一致的。</p>
                <h3 id="flatten"><a href="#flatten" class="headerlink" title="flatten"></a>flatten</h3>
                <p>flatten() 方法可以对 Tensor 进行展平操作，定义在 tensorflow/python/layers/core.py。</p>
                <figure class="highlight fortran">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">flatten(</span><br><span class="line">    inputs,</span><br><span class="line">    <span class="keyword">name</span>=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>参数说明如下：</p>
                <ul>
                  <li>inputs：必需，即输入数据。</li>
                  <li>name：可选，默认为 None，即该层的名称。</li>
                </ul>
                <p>返回结果： 展平后的 Tensor。 下面我们用一个实例来感受一下：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf<span class="selector-class">.layers</span>.Input(shape=[<span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(x)</span></span></span><br><span class="line">y = tf<span class="selector-class">.layers</span>.flatten(x)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(y)</span></span></span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>运行结果：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"input_layer_1:0"</span>, shape=(?, <span class="number">5</span>, <span class="number">6</span>)</span></span>, dtype=float32)</span><br><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"flatten/Reshape:0"</span>, shape=(?, <span class="number">30</span>)</span></span>, dtype=float32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>这里输入数据的 shape 为 [?, 5, 6]，经过 flatten 层之后，就会变成 [?, 30]，即将除了第一维的数据维度相乘，对原 Tensor 进行展平。 假如第一维是一个已知的数的话，它依然还是同样的处理，示例如下：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.placeholder(shape=[<span class="number">5</span>, <span class="number">6</span>, <span class="number">2</span>], dtype=tf.float32)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(x)</span></span></span><br><span class="line">y = tf<span class="selector-class">.layers</span>.flatten(x)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(y)</span></span></span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>结果如下：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"Placeholder:0"</span>, shape=(<span class="number">5</span>, <span class="number">6</span>, <span class="number">2</span>)</span></span>, dtype=float32)</span><br><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"flatten_2/Reshape:0"</span>, shape=(<span class="number">5</span>, <span class="number">12</span>)</span></span>, dtype=float32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2>
                <p>除了如上的方法，其实我们还可以直接使用类来进行操作，实际上看方法的实现就是实例化了其对应的类，下面我们首先说明一下有哪些类可以使用：</p>
                <ul>
                  <li>class AveragePooling1D: 一维平均池化层类</li>
                  <li>class AveragePooling2D: 二维平均池化层类</li>
                  <li>class AveragePooling3D: 三维平均池化层类</li>
                  <li>class BatchNormalization: 批量标准化层类</li>
                  <li>class Conv1D: 一维卷积层类</li>
                  <li>class Conv2D: 二维卷积层类</li>
                  <li>class Conv2DTranspose: 二维反卷积层类</li>
                  <li>class Conv3D: 三维卷积层类</li>
                  <li>class Conv3DTranspose: 三维反卷积层类</li>
                  <li>class Dense: 全连接层类</li>
                  <li>class Dropout: Dropout 层类</li>
                  <li>class Flatten: Flatten 层类</li>
                  <li>class InputSpec: Input 层类</li>
                  <li>class Layer: 基类、父类</li>
                  <li>class MaxPooling1D: 一维最大池化层类</li>
                  <li>class MaxPooling2D: 二维最大池化层类</li>
                  <li>class MaxPooling3D: 三维最大池化层类</li>
                  <li>class SeparableConv2D: 二维深度可分离卷积层类</li>
                </ul>
                <p>其实类这些类都和上文介绍的方法是一一对应的，关于它的用法我们可以在方法的源码实现里面找到，下面我们以 Dense 类的用法为例来说明一下这些类的具体调用方法：</p>
                <figure class="highlight reasonml">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">x = tf.layers.<span class="constructor">Input(<span class="params">shape</span>=[32])</span></span><br><span class="line">dense = tf.layers.<span class="constructor">Dense(16, <span class="params">activation</span>=<span class="params">tf</span>.<span class="params">nn</span>.<span class="params">relu</span>)</span></span><br><span class="line">y = dense.apply(x)</span><br><span class="line">print(y)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>这里我们初始化了一个 Dense 类，它只接受一个必须参数，那就是 units，相比 dense() 方法来说它没有了 inputs，因此这个实例化的类和 inputs 是无关的，这样就相当于创建了一个 16 个神经元的全连接层。 但创建了不调用是没有用的，我们要将这个层构建到网络之中，需要调用它的 apply() 方法，而 apply() 方法就接收 inputs 这个参数，返回计算结果，运行结果如下：</p>
                <figure class="highlight stylus">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line"><span class="function"><span class="title">Tensor</span><span class="params">(<span class="string">"dense/Relu:0"</span>, shape=(?, <span class="number">16</span>)</span></span>, dtype=float32)</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <p>因此我们可以发现，这些类在初始化的时候实际上是比其对应的方法少了 inputs 参数，其他的参数都是完全一致的，另外需要调用 apply() 方法才可以应用该层并将其构建到模型中。 所以其他的类的用法在此就不一一赘述了，初始化的参数可以类比其对应的方法，实例化类之后，调用 apply() 方法，可以达到同样的构建模型的效果。</p>
                <h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2>
                <p>以上便是 TensorFlow layers 模块的详细用法说明，更加详细的用法可以参考官方文档：<a href="https://www.tensorflow.org/api_docs/python/tf/layers" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/layers</a>。 本节代码地址：<a href="https://github.com/AIDeepLearning/TensorFlowLayers" target="_blank" rel="noopener">https://github.com/AIDeepLearning/TensorFlowLayers</a>。</p>
              </div>
              <div class="reward-container">
                <div></div>
                <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏 </button>
                <div id="qr" style="display: none;">
                  <div style="display: inline-block;">
                    <img src="/images/wechatpay.jpg" alt="崔庆才 微信支付">
                    <p>微信支付</p>
                  </div>
                  <div style="display: inline-block;">
                    <img src="/images/alipay.jpg" alt="崔庆才 支付宝">
                    <p>支付宝</p>
                  </div>
                </div>
              </div>
              <footer class="post-footer">
                <div class="post-nav">
                  <div class="post-nav-item">
                    <a href="/5709.html" rel="prev" title="TensorFlow验证码识别">
                      <i class="fa fa-chevron-left"></i> TensorFlow验证码识别 </a>
                  </div>
                  <div class="post-nav-item">
                    <a href="/5737.html" rel="next" title="[论文笔记] Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation"> [论文笔记] Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation <i class="fa fa-chevron-right"></i>
                    </a>
                  </div>
                </div>
              </footer>
            </article>
          </div>
          <div class="comments" id="gitalk-container"></div>
          <script>
            window.addEventListener('tabs:register', () =>
            {
              let
              {
                activeClass
              } = CONFIG.comments;
              if (CONFIG.comments.storage)
              {
                activeClass = localStorage.getItem('comments_active') || activeClass;
              }
              if (activeClass)
              {
                let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
                if (activeTab)
                {
                  activeTab.click();
                }
              }
            });
            if (CONFIG.comments.storage)
            {
              window.addEventListener('tabs:click', event =>
              {
                if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
                let commentClass = event.target.classList[1];
                localStorage.setItem('comments_active', commentClass);
              });
            }

          </script>
        </div>
        <div class="toggle sidebar-toggle">
          <span class="toggle-line toggle-line-first"></span>
          <span class="toggle-line toggle-line-middle"></span>
          <span class="toggle-line toggle-line-last"></span>
        </div>
        <aside class="sidebar">
          <div class="sidebar-inner">
            <ul class="sidebar-nav motion-element">
              <li class="sidebar-nav-toc"> 文章目录 </li>
              <li class="sidebar-nav-overview"> 站点概览 </li>
            </ul>
            <!--noindex-->
            <div class="post-toc-wrap sidebar-panel">
              <div class="post-toc motion-element">
                <ol class="nav">
                  <li class="nav-item nav-level-2"><a class="nav-link" href="#概览"><span class="nav-number">1.</span> <span class="nav-text">概览</span></a></li>
                  <li class="nav-item nav-level-2"><a class="nav-link" href="#方法"><span class="nav-number">2.</span> <span class="nav-text">方法</span></a>
                    <ol class="nav-child">
                      <li class="nav-item nav-level-3"><a class="nav-link" href="#Input"><span class="nav-number">2.1.</span> <span class="nav-text">Input</span></a></li>
                      <li class="nav-item nav-level-3"><a class="nav-link" href="#batch-normalization"><span class="nav-number">2.2.</span> <span class="nav-text">batch_normalization</span></a></li>
                      <li class="nav-item nav-level-3"><a class="nav-link" href="#dense"><span class="nav-number">2.3.</span> <span class="nav-text">dense</span></a></li>
                      <li class="nav-item nav-level-3"><a class="nav-link" href="#convolution"><span class="nav-number">2.4.</span> <span class="nav-text">convolution</span></a></li>
                      <li class="nav-item nav-level-3"><a class="nav-link" href="#pooling"><span class="nav-number">2.5.</span> <span class="nav-text">pooling</span></a></li>
                      <li class="nav-item nav-level-3"><a class="nav-link" href="#dropout"><span class="nav-number">2.6.</span> <span class="nav-text">dropout</span></a></li>
                      <li class="nav-item nav-level-3"><a class="nav-link" href="#flatten"><span class="nav-number">2.7.</span> <span class="nav-text">flatten</span></a></li>
                    </ol>
                  </li>
                  <li class="nav-item nav-level-2"><a class="nav-link" href="#类"><span class="nav-number">3.</span> <span class="nav-text">类</span></a></li>
                  <li class="nav-item nav-level-2"><a class="nav-link" href="#结语"><span class="nav-number">4.</span> <span class="nav-text">结语</span></a></li>
                </ol>
              </div>
            </div>
            <!--/noindex-->
            <div class="site-overview-wrap sidebar-panel">
              <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
                <img class="site-author-image" itemprop="image" alt="崔庆才" src="/images/avatar.png">
                <p class="site-author-name" itemprop="name">崔庆才</p>
                <div class="site-description" itemprop="description">静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。</div>
              </div>
              <div class="site-state-wrap motion-element">
                <nav class="site-state">
                  <div class="site-state-item site-state-posts">
                    <a href="/archives/">
                      <span class="site-state-item-count">685</span>
                      <span class="site-state-item-name">日志</span>
                    </a>
                  </div>
                  <div class="site-state-item site-state-categories">
                    <a href="/categories/">
                      <span class="site-state-item-count">32</span>
                      <span class="site-state-item-name">分类</span></a>
                  </div>
                  <div class="site-state-item site-state-tags">
                    <a href="/tags/">
                      <span class="site-state-item-count">246</span>
                      <span class="site-state-item-name">标签</span></a>
                  </div>
                </nav>
              </div>
              <div class="links-of-author motion-element">
                <span class="links-of-author-item">
                  <a href="https://github.com/Germey" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Germey" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
                </span>
                <span class="links-of-author-item">
                  <a href="mailto:cqc@cuiqingcai.com.com" title="邮件 → mailto:cqc@cuiqingcai.com.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>邮件</a>
                </span>
                <span class="links-of-author-item">
                  <a href="https://weibo.com/cuiqingcai" title="微博 → https:&#x2F;&#x2F;weibo.com&#x2F;cuiqingcai" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>微博</a>
                </span>
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/Germey" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;Germey" rel="noopener" target="_blank"><i class="fa fa-magic fa-fw"></i>知乎</a>
                </span>
              </div>
            </div>
            <div style=" width: 100%;" class="sidebar-panel sidebar-panel-image sidebar-panel-active">
              <a href="https://item.jd.com/13527222.html" target="_blank" rel="noopener">
                <img src="https://cdn.cuiqingcai.com/ei5og.jpg" style=" width: 100%;">
              </a>
            </div>
            <div class="sidebar-panel sidebar-panel-categories sidebar-panel-active">
              <h4 class="name"> 分类 </h4>
              <div class="content">
                <ul class="category-list">
                  <li class="category-list-item"><a class="category-list-link" href="/categories/API/">API</a><span class="category-list-count">5</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/C-C/">C/C++</a><span class="category-list-count">23</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/HTML/">HTML</a><span class="category-list-count">14</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">5</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a><span class="category-list-count">26</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">14</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Luma/">Luma</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Markdown/">Markdown</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Net/">Net</a><span class="category-list-count">4</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Nexior/">Nexior</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Other/">Other</a><span class="category-list-count">40</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a><span class="category-list-count">27</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">303</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/TypeScript/">TypeScript</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E5%B1%95%E7%A4%BA/">个人展示</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E6%97%A5%E8%AE%B0/">个人日记</a><span class="category-list-count">9</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E8%AE%B0%E5%BD%95/">个人记录</a><span class="category-list-count">6</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E9%9A%8F%E7%AC%94/">个人随笔</a><span class="category-list-count">21</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">5</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/">安装配置</a><span class="category-list-count">59</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/">技术杂谈</a><span class="category-list-count">96</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/">未分类</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a><span class="category-list-count">4</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB%E7%AC%94%E8%AE%B0/">生活笔记</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A6%8F%E5%88%A9%E4%B8%93%E5%8C%BA/">福利专区</a><span class="category-list-count">6</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E8%81%8C%E4%BD%8D%E6%8E%A8%E8%8D%90/">职位推荐</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E8%89%BA%E6%9C%AF%E4%BA%8C%E7%BB%B4%E7%A0%81/">艺术二维码</a><span class="category-list-count">1</span></li>
                </ul>
              </div>
            </div>
            <div class="sidebar-panel sidebar-panel-friends sidebar-panel-active">
              <h4 class="name"> 友情链接 </h4>
              <ul class="friends">
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/j2dub.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.findhao.net/" target="_blank" rel="noopener">FindHao</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/6apxu.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.51dev.com/" target="_blank" rel="noopener">IT技术社区</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/bqlbs.png">
                  </span>
                  <span class="link">
                    <a href="http://www.urselect.com/" target="_blank" rel="noopener">优社电商</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/8s88c.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.yuanrenxue.com/" target="_blank" rel="noopener">猿人学</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/2wgg5.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.yunlifang.cn/" target="_blank" rel="noopener">云立方</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="http://qianxunclub.com/favicon.png">
                  </span>
                  <span class="link">
                    <a href="http://qianxunclub.com/" target="_blank" rel="noopener">千寻啊千寻</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/0044u.jpg">
                  </span>
                  <span class="link">
                    <a href="http://kodcloud.com/" target="_blank" rel="noopener">可道云</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/ygnpn.jpg">
                  </span>
                  <span class="link">
                    <a href="http://www.kunkundashen.cn/" target="_blank" rel="noopener">坤坤大神</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/x714o.jpg">
                  </span>
                  <span class="link">
                    <a href="http://www.hubwiz.com/" target="_blank" rel="noopener">汇智网</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/44hxf.png">
                  </span>
                  <span class="link">
                    <a href="http://redstonewill.com/" target="_blank" rel="noopener">红色石头</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/wkaus.jpg">
                  </span>
                  <span class="link">
                    <a href="https://zhaoshuai.me/" target="_blank" rel="noopener">碎念</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/pgo0r.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.chenwenguan.com/" target="_blank" rel="noopener">陈文管的博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/kk82a.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.lxlinux.net/" target="_blank" rel="noopener">良许Linux教程网</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/lj0t2.jpg">
                  </span>
                  <span class="link">
                    <a href="https://tanqingbo.cn/" target="_blank" rel="noopener">IT码农</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/i8cdr.png">
                  </span>
                  <span class="link">
                    <a href="https://junyiseo.com/" target="_blank" rel="noopener">均益个人博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/chwv2.png">
                  </span>
                  <span class="link">
                    <a href="https://brucedone.com/" target="_blank" rel="noopener">大鱼的鱼塘</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://www.91vps.com/favicon.ico">
                  </span>
                  <span class="link">
                    <a href="http://www.91vps.com/" target="_blank" rel="noopener">91VPS</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://webpage.qidian.qq.com/qidian/chatv3-gray/favicon.ico">
                  </span>
                  <span class="link">
                    <a href="https://www.qg.net/" target="_blank" rel="noopener">青果网络</a>
                  </span>
                </li>
              </ul>
            </div>
            <div class="sidebar-panel sidebar-panel-tags sidebar-panel-active">
              <h4 class="name"> 标签云 </h4>
              <div class="content">
                <a href="/tags/2022/" style="font-size: 20px;">2022</a> <a href="/tags/2048/" style="font-size: 10px;">2048</a> <a href="/tags/ADSL/" style="font-size: 10px;">ADSL</a> <a href="/tags/API/" style="font-size: 16px;">API</a> <a href="/tags/Ajax/" style="font-size: 12px;">Ajax</a> <a href="/tags/Bootstrap/" style="font-size: 11px;">Bootstrap</a> <a href="/tags/Bug/" style="font-size: 10px;">Bug</a> <a href="/tags/CDN/" style="font-size: 10px;">CDN</a> <a href="/tags/CQC/" style="font-size: 10px;">CQC</a> <a href="/tags/CSS/" style="font-size: 10px;">CSS</a> <a href="/tags/CSS-%E5%8F%8D%E7%88%AC%E8%99%AB/" style="font-size: 10px;">CSS 反爬虫</a> <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/ChatGPT/" style="font-size: 10px;">ChatGPT</a> <a href="/tags/Cookie/" style="font-size: 10px;">Cookie</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/Eclipse/" style="font-size: 11px;">Eclipse</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/FTP/" style="font-size: 10px;">FTP</a> <a href="/tags/Flux/" style="font-size: 10px;">Flux</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/GitHub/" style="font-size: 13px;">GitHub</a> <a href="/tags/HTML5/" style="font-size: 10px;">HTML5</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/Hailuo/" style="font-size: 10px;">Hailuo</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/Hook/" style="font-size: 10px;">Hook</a> <a href="/tags/IP/" style="font-size: 10px;">IP</a> <a href="/tags/IT/" style="font-size: 10px;">IT</a> <a href="/tags/JSON/" style="font-size: 10px;">JSON</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/JavaScript/" style="font-size: 14px;">JavaScript</a> <a href="/tags/K8s/" style="font-size: 10px;">K8s</a> <a href="/tags/LOGO/" style="font-size: 10px;">LOGO</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Luma/" style="font-size: 10px;">Luma</a> <a href="/tags/MIUI/" style="font-size: 10px;">MIUI</a> <a href="/tags/Markdown/" style="font-size: 10px;">Markdown</a> <a href="/tags/Midjourney/" style="font-size: 11px;">Midjourney</a> <a href="/tags/MongoDB/" style="font-size: 11px;">MongoDB</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/NBA/" style="font-size: 10px;">NBA</a> <a href="/tags/Nexior/" style="font-size: 10px;">Nexior</a> <a href="/tags/OCR/" style="font-size: 10px;">OCR</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/PHP/" style="font-size: 11px;">PHP</a> <a href="/tags/PPT/" style="font-size: 10px;">PPT</a> <a href="/tags/PS/" style="font-size: 10px;">PS</a> <a href="/tags/Pathlib/" style="font-size: 10px;">Pathlib</a> <a href="/tags/PhantomJS/" style="font-size: 10px;">PhantomJS</a> <a href="/tags/Playwright/" style="font-size: 10px;">Playwright</a> <a href="/tags/Python/" style="font-size: 17px;">Python</a> <a href="/tags/Python-%E7%88%AC%E8%99%AB/" style="font-size: 18px;">Python 爬虫</a> <a href="/tags/Python3/" style="font-size: 11px;">Python3</a> <a href="/tags/Python3%E7%88%AC%E8%99%AB%E6%95%99%E7%A8%8B/" style="font-size: 12px;">Python3爬虫教程</a> <a href="/tags/Pythonic/" style="font-size: 10px;">Pythonic</a> <a href="/tags/Python%E7%88%AC%E8%99%AB/" style="font-size: 19px;">Python爬虫</a> <a href="/tags/Python%E7%88%AC%E8%99%AB%E4%B9%A6/" style="font-size: 12px;">Python爬虫书</a> <a href="/tags/Python%E7%88%AC%E8%99%AB%E6%95%99%E7%A8%8B/" style="font-size: 15px;">Python爬虫教程</a> <a href="/tags/QQ/" style="font-size: 10px;">QQ</a> <a href="/tags/RabbitMQ/" style="font-size: 10px;">RabbitMQ</a> <a href="/tags/ReCAPTCHA/" style="font-size: 10px;">ReCAPTCHA</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Riffusion/" style="font-size: 10px;">Riffusion</a> <a href="/tags/SAE/" style="font-size: 10px;">SAE</a> <a href="/tags/SSH/" style="font-size: 10px;">SSH</a> <a href="/tags/SVG/" style="font-size: 10px;">SVG</a> <a href="/tags/Scrapy-redis/" style="font-size: 10px;">Scrapy-redis</a> <a href="/tags/Scrapy%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 10px;">Scrapy分布式</a> <a href="/tags/Selenium/" style="font-size: 11px;">Selenium</a> <a href="/tags/Session/" style="font-size: 10px;">Session</a> <a href="/tags/Shell/" style="font-size: 10px;">Shell</a> <a href="/tags/Suno/" style="font-size: 10px;">Suno</a> <a href="/tags/TKE/" style="font-size: 10px;">TKE</a> <a href="/tags/TXT/" style="font-size: 10px;">TXT</a> <a href="/tags/Terminal/" style="font-size: 10px;">Terminal</a> <a href="/tags/Ubuntu/" style="font-size: 11px;">Ubuntu</a> <a href="/tags/VS-Code/" style="font-size: 10px;">VS Code</a> <a href="/tags/Veo/" style="font-size: 10px;">Veo</a> <a href="/tags/Vercel/" style="font-size: 10px;">Vercel</a> <a href="/tags/Vs-Code/" style="font-size: 10px;">Vs Code</a> <a href="/tags/Vue/" style="font-size: 11px;">Vue</a> <a href="/tags/Web/" style="font-size: 10px;">Web</a> <a href="/tags/Webpack/" style="font-size: 10px;">Webpack</a> <a href="/tags/Web%E7%BD%91%E9%A1%B5/" style="font-size: 10px;">Web网页</a> <a href="/tags/Windows/" style="font-size: 10px;">Windows</a> <a href="/tags/Winpcap/" style="font-size: 10px;">Winpcap</a> <a href="/tags/WordPress/" style="font-size: 13px;">WordPress</a> <a href="/tags/XPath/" style="font-size: 12px;">XPath</a> <a href="/tags/Youtube/" style="font-size: 11px;">Youtube</a> <a href="/tags/acedata/" style="font-size: 12px;">acedata</a> <a href="/tags/aiohttp/" style="font-size: 10px;">aiohttp</a> <a href="/tags/android/" style="font-size: 10px;">android</a> <a href="/tags/ansible/" style="font-size: 10px;">ansible</a> <a href="/tags/api/" style="font-size: 13px;">api</a> <a href="/tags/chatgpt/" style="font-size: 10px;">chatgpt</a> <a href="/tags/cocos2d-x/" style="font-size: 10px;">cocos2d-x</a> <a href="/tags/dummy-change/" style="font-size: 10px;">dummy change</a> <a href="/tags/e6/" style="font-size: 10px;">e6</a> <a href="/tags/fitvids/" style="font-size: 10px;">fitvids</a>
              </div>
              <script>
                const tagsColors = ['#00a67c', '#5cb85c', '#d9534f', '#567e95', '#b37333', '#f4843d', '#15a287']
                const tagsElements = document.querySelectorAll('.sidebar-panel-tags .content a')
                tagsElements.forEach((item) =>
                {
                  item.style.backgroundColor = tagsColors[Math.floor(Math.random() * tagsColors.length)]
                })

              </script>
            </div>
          </div>
        </aside>
        <div id="sidebar-dimmer"></div>
      </div>
    </main>
    <footer class="footer">
      <div class="footer-inner">
        <div class="copyright">
          <span class="author" itemprop="copyrightHolder">崔庆才丨静觅</span> &copy; <span itemprop="copyrightYear">2025</span>
          <span class="with-love">
            <i class="fa fa-heart"></i>
          </span>
          <a href="https://cuiqingcai.com/sitemap.xml" style="display:none" title="爬虫教程" target="_blank"><strong>爬虫教程</strong></a>
          <a href="https://cuiqingcai.com/sitemap.html" style="display:none" title="爬虫教程" target="_blank"><strong>爬虫教程</strong></a>
          <span class="post-meta-divider">|</span>
          <span class="post-meta-item-icon">
            <i class="fa fa-chart-area"></i>
          </span>
          <span title="站点总字数">3.3m</span>
          <span class="post-meta-divider">|</span>
          <span class="post-meta-item-icon">
            <i class="fa fa-coffee"></i>
          </span>
          <span title="站点阅读时长">49:35</span>
        </div>
        <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动 </div>
        <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">京ICP备18015597号-1 </a>
        </div>
        <script>
          (function ()
          {
            function leancloudSelector(url)
            {
              url = encodeURI(url);
              return document.getElementById(url).querySelector('.leancloud-visitors-count');
            }

            function addCount(Counter)
            {
              var visitors = document.querySelector('.leancloud_visitors');
              var url = decodeURI(visitors.id);
              var title = visitors.dataset.flagTitle;
              Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify(
              {
                url
              }))).then(response => response.json()).then((
              {
                results
              }) =>
              {
                if (results.length > 0)
                {
                  var counter = results[0];
                  leancloudSelector(url).innerText = counter.time + 1;
                  Counter('put', '/classes/Counter/' + counter.objectId,
                  {
                    time:
                    {
                      '__op': 'Increment',
                      'amount': 1
                    }
                  }).catch(error =>
                  {
                    console.error('Failed to save visitor count', error);
                  });
                }
                else
                {
                  Counter('post', '/classes/Counter',
                  {
                    title,
                    url,
                    time: 1
                  }).then(response => response.json()).then(() =>
                  {
                    leancloudSelector(url).innerText = 1;
                  }).catch(error =>
                  {
                    console.error('Failed to create', error);
                  });
                }
              }).catch(error =>
              {
                console.error('LeanCloud Counter Error', error);
              });
            }

            function showTime(Counter)
            {
              var visitors = document.querySelectorAll('.leancloud_visitors');
              var entries = [...visitors].map(element =>
              {
                return decodeURI(element.id);
              });
              Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify(
              {
                url:
                {
                  '$in': entries
                }
              }))).then(response => response.json()).then((
              {
                results
              }) =>
              {
                for (let url of entries)
                {
                  let target = results.find(item => item.url === url);
                  leancloudSelector(url).innerText = target ? target.time : 0;
                }
              }).catch(error =>
              {
                console.error('LeanCloud Counter Error', error);
              });
            }
            let
            {
              app_id,
              app_key,
              server_url
            } = {
              "enable": true,
              "app_id": "6X5dRQ0pnPWJgYy8SXOg0uID-gzGzoHsz",
              "app_key": "ziLDVEy73ne5HtFTiGstzHMS",
              "server_url": "https://6x5drq0p.lc-cn-n1-shared.com",
              "security": false
            };

            function fetchData(api_server)
            {
              var Counter = (method, url, data) =>
              {
                return fetch(`${api_server}/1.1${url}`,
                {
                  method,
                  headers:
                  {
                    'X-LC-Id': app_id,
                    'X-LC-Key': app_key,
                    'Content-Type': 'application/json',
                  },
                  body: JSON.stringify(data)
                });
              };
              if (CONFIG.page.isPost)
              {
                if (CONFIG.hostname !== location.hostname) return;
                addCount(Counter);
              }
              else if (document.querySelectorAll('.post-title-link').length >= 1)
              {
                showTime(Counter);
              }
            }
            let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;
            if (api_server)
            {
              fetchData(api_server);
            }
            else
            {
              fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id).then(response => response.json()).then((
              {
                api_server
              }) =>
              {
                fetchData('https://' + api_server);
              });
            }
          })();

        </script>
      </div>
      <div class="footer-stat">
        <span id="cnzz_stat_icon_1279355174"></span>
        <script type="text/javascript">
          document.write(unescape("%3Cspan id='cnzz_stat_icon_1279355174'%3E%3C/span%3E%3Cscript src='https://v1.cnzz.com/z_stat.php%3Fid%3D1279355174%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));

        </script>
      </div>
    </footer>
  </div>
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/js/utils.js"></script>
  <script src="/.js"></script>
  <script src="/js/schemes/pisces.js"></script>
  <script src="/.js"></script>
  <script src="/js/next-boot.js"></script>
  <script src="/.js"></script>
  <script>
    (function ()
    {
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x = document.getElementsByTagName("link");
      //Find the last canonical URL
      if (x.length > 0)
      {
        for (i = 0; i < x.length; i++)
        {
          if (x[i].rel.toLowerCase() == 'canonical' && x[i].href)
          {
            canonicalURL = x[i].href;
          }
        }
      }
      //Get protocol
      if (!canonicalURL)
      {
        curProtocol = window.location.protocol.split(':')[0];
      }
      else
      {
        curProtocol = canonicalURL.split(':')[0];
      }
      //Get current URL if the canonical URL does not exist
      if (!canonicalURL) canonicalURL = window.location.href;
      //Assign script content. Replace current URL with the canonical URL
      ! function ()
      {
        var e = /([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,
          r = canonicalURL,
          t = document.referrer;
        if (!e.test(r))
        {
          var n = (String(curProtocol).toLowerCase() === 'https') ? "https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif" : "//api.share.baidu.com/s.gif";
          t ? (n += "?r=" + encodeURIComponent(document.referrer), r && (n += "&l=" + r)) : r && (n += "?l=" + r);
          var i = new Image;
          i.src = n
        }
      }(window);
    })();

  </script>
  <script src="/js/local-search.js"></script>
  <script src="/.js"></script>
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">
  <script>
    NexT.utils.loadComments(document.querySelector('#gitalk-container'), () =>
    {
      NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () =>
      {
        var gitalk = new Gitalk(
        {
          perPage: : 100,
          clientID: '4c86ce1d7c4fbb3b277c',
          clientSecret: '4927beb0f90e2c07e66c99d9d2529cf3eb8ac8e4',
          repo: 'Blog',
          owner: 'germey',
          admin: ['germey'],
          id: '779f17cea70fbdb225067fad671333c4',
          language: 'zh-CN',
          distractionFreeMode: true
        });
        gitalk.render('gitalk-container');
      }, window.Gitalk);
    });

  </script>
</body>

</html>
